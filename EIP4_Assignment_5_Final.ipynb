{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EIP4 - Assignment 5 - Final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aswinjayan94/EIP/blob/master/EIP4_Assignment_5_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gyq8CE4ug5BK",
        "colab_type": "code",
        "outputId": "a2848b4e-1bfe-47c0-a0ff-1a3e891aa78a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# mount gdrive and unzip data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ckfbvYKzpyY",
        "colab_type": "code",
        "outputId": "83687f0e-2194-4295-84b1-5b3ec23bc206",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import os\n",
        "os.listdir(\".\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config', 'resized', 'hvc_annotations.csv', 'gdrive', 'sample_data']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRUJNJnjmwwP",
        "colab_type": "code",
        "outputId": "c7453c3c-5668-4299-d092-d09e77e80897",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!unzip -q \"/content/gdrive/My Drive/EIP4 - Assignment5/hvc_data.zip\"\n",
        "# look for `hvc_annotations.csv` file and `resized` dir\n",
        "%ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mgdrive\u001b[0m/  hvc_annotations.csv  \u001b[01;34mresized\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYbNQzK6kj94",
        "colab_type": "code",
        "outputId": "013e7854-8a82-46f0-9ea5-b7497b853ca3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "source": [
        "import cv2\n",
        "import json\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from functools import partial\n",
        "from pathlib import Path \n",
        "from tqdm import tqdm\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.applications import VGG16\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers import Input, Conv2D, MaxPool2D\n",
        "from keras.layers import AveragePooling2D, Input, Flatten, Activation, Flatten, Dropout, SeparableConv2D, GlobalAveragePooling2D\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from keras.regularizers import l2\n",
        "\n",
        "\n",
        "from albumentations import (\n",
        "    Compose, HorizontalFlip, ToFloat, ShiftScaleRotate,\n",
        "    Normalize, Rotate, Cutout\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQkbSpLK4sTP",
        "colab_type": "code",
        "outputId": "1c651b23-fdde-4fae-b76a-4d200697a3bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# load annotations\n",
        "df = pd.read_csv(\"hvc_annotations.csv\")\n",
        "del df[\"filename\"] # remove unwanted column\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>imagequality</th>\n",
              "      <th>age</th>\n",
              "      <th>weight</th>\n",
              "      <th>carryingbag</th>\n",
              "      <th>footwear</th>\n",
              "      <th>emotion</th>\n",
              "      <th>bodypose</th>\n",
              "      <th>image_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>male</td>\n",
              "      <td>Average</td>\n",
              "      <td>35-45</td>\n",
              "      <td>normal-healthy</td>\n",
              "      <td>Grocery/Home/Plastic Bag</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Front-Frontish</td>\n",
              "      <td>resized/1.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>female</td>\n",
              "      <td>Average</td>\n",
              "      <td>35-45</td>\n",
              "      <td>over-weight</td>\n",
              "      <td>None</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Angry/Serious</td>\n",
              "      <td>Front-Frontish</td>\n",
              "      <td>resized/2.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>male</td>\n",
              "      <td>Good</td>\n",
              "      <td>45-55</td>\n",
              "      <td>normal-healthy</td>\n",
              "      <td>Grocery/Home/Plastic Bag</td>\n",
              "      <td>CantSee</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Front-Frontish</td>\n",
              "      <td>resized/3.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>male</td>\n",
              "      <td>Good</td>\n",
              "      <td>45-55</td>\n",
              "      <td>normal-healthy</td>\n",
              "      <td>Daily/Office/Work Bag</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Front-Frontish</td>\n",
              "      <td>resized/4.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>female</td>\n",
              "      <td>Good</td>\n",
              "      <td>35-45</td>\n",
              "      <td>slightly-overweight</td>\n",
              "      <td>None</td>\n",
              "      <td>CantSee</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Front-Frontish</td>\n",
              "      <td>resized/5.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   gender imagequality    age  ...        emotion        bodypose     image_path\n",
              "0    male      Average  35-45  ...        Neutral  Front-Frontish  resized/1.jpg\n",
              "1  female      Average  35-45  ...  Angry/Serious  Front-Frontish  resized/2.jpg\n",
              "2    male         Good  45-55  ...        Neutral  Front-Frontish  resized/3.jpg\n",
              "3    male         Good  45-55  ...        Neutral  Front-Frontish  resized/4.jpg\n",
              "4  female         Good  35-45  ...        Neutral  Front-Frontish  resized/5.jpg\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dX3dShdZIFQU",
        "colab_type": "code",
        "outputId": "e6384ddb-ded5-46c3-8399-a1096e343336",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(df.groupby(\"gender\")[\"gender\"].count())\n",
        "print(\"Baseline gender accuracy: \"+str(max(df.groupby(\"gender\")[\"gender\"].count())/sum(df.groupby(\"gender\")[\"gender\"].count())))\n",
        "print(\"\\n\")\n",
        "\n",
        "print(df.groupby(\"imagequality\")[\"imagequality\"].count())\n",
        "print(\"Baseline imagequality accuracy: \"+str(max(df.groupby(\"imagequality\")[\"imagequality\"].count())/sum(df.groupby(\"imagequality\")[\"imagequality\"].count())))\n",
        "print(\"\\n\")\n",
        "\n",
        "print(df.groupby(\"age\")[\"age\"].count())\n",
        "print(\"Baseline age accuracy: \"+str(max(df.groupby(\"age\")[\"age\"].count())/sum(df.groupby(\"age\")[\"age\"].count())))\n",
        "print(\"\\n\")\n",
        "\n",
        "print(df.groupby(\"weight\")[\"weight\"].count())\n",
        "print(\"Baseline weight accuracy: \"+str(max(df.groupby(\"weight\")[\"weight\"].count())/sum(df.groupby(\"weight\")[\"weight\"].count())))\n",
        "print(\"\\n\")\n",
        "\n",
        "print(df.groupby(\"carryingbag\")[\"carryingbag\"].count())\n",
        "print(\"Baseline carryingbag accuracy: \"+str(max(df.groupby(\"carryingbag\")[\"carryingbag\"].count())/sum(df.groupby(\"carryingbag\")[\"carryingbag\"].count())))\n",
        "print(\"\\n\")\n",
        "\n",
        "print(df.groupby(\"footwear\")[\"footwear\"].count())\n",
        "print(\"Baseline footwear accuracy: \"+str(max(df.groupby(\"footwear\")[\"footwear\"].count())/sum(df.groupby(\"footwear\")[\"footwear\"].count())))\n",
        "print(\"\\n\")\n",
        "\n",
        "print(df.groupby(\"emotion\")[\"emotion\"].count())\n",
        "print(\"Baseline emotion accuracy: \"+str(max(df.groupby(\"emotion\")[\"emotion\"].count())/sum(df.groupby(\"emotion\")[\"emotion\"].count())))\n",
        "print(\"\\n\")\n",
        "\n",
        "print(df.groupby(\"bodypose\")[\"bodypose\"].count())\n",
        "print(\"Baseline bodypose accuracy: \"+str(max(df.groupby(\"bodypose\")[\"bodypose\"].count())/sum(df.groupby(\"bodypose\")[\"bodypose\"].count())))\n",
        "print(\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gender\n",
            "female    5937\n",
            "male      7636\n",
            "Name: gender, dtype: int64\n",
            "Baseline gender accuracy: 0.5625874898695941\n",
            "\n",
            "\n",
            "imagequality\n",
            "Average    7509\n",
            "Bad        2240\n",
            "Good       3824\n",
            "Name: imagequality, dtype: int64\n",
            "Baseline imagequality accuracy: 0.5532306785530097\n",
            "\n",
            "\n",
            "age\n",
            "15-25    2494\n",
            "25-35    5411\n",
            "35-45    3435\n",
            "45-55    1490\n",
            "55+       743\n",
            "Name: age, dtype: int64\n",
            "Baseline age accuracy: 0.39865910263022175\n",
            "\n",
            "\n",
            "weight\n",
            "normal-healthy         8628\n",
            "over-weight             891\n",
            "slightly-overweight    3196\n",
            "underweight             858\n",
            "Name: weight, dtype: int64\n",
            "Baseline weight accuracy: 0.6356737640904737\n",
            "\n",
            "\n",
            "carryingbag\n",
            "Daily/Office/Work Bag       4603\n",
            "Grocery/Home/Plastic Bag    1321\n",
            "None                        7649\n",
            "Name: carryingbag, dtype: int64\n",
            "Baseline carryingbag accuracy: 0.56354527370515\n",
            "\n",
            "\n",
            "footwear\n",
            "CantSee    5028\n",
            "Fancy      2507\n",
            "Normal     6038\n",
            "Name: footwear, dtype: int64\n",
            "Baseline footwear accuracy: 0.4448537537758786\n",
            "\n",
            "\n",
            "emotion\n",
            "Angry/Serious    1500\n",
            "Happy            1609\n",
            "Neutral          9660\n",
            "Sad               804\n",
            "Name: emotion, dtype: int64\n",
            "Baseline emotion accuracy: 0.7117070654976793\n",
            "\n",
            "\n",
            "bodypose\n",
            "Back              2207\n",
            "Front-Frontish    8383\n",
            "Side              2983\n",
            "Name: bodypose, dtype: int64\n",
            "Baseline bodypose accuracy: 0.6176232225742282\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "202OJva345WA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# one hot encoding of labels\n",
        "\n",
        "one_hot_df = pd.concat([\n",
        "    df[[\"image_path\"]],\n",
        "    pd.get_dummies(df.gender, prefix=\"gender\"),\n",
        "    pd.get_dummies(df.imagequality, prefix=\"imagequality\"),\n",
        "    pd.get_dummies(df.age, prefix=\"age\"),\n",
        "    pd.get_dummies(df.weight, prefix=\"weight\"),\n",
        "    pd.get_dummies(df.carryingbag, prefix=\"carryingbag\"),\n",
        "    pd.get_dummies(df.footwear, prefix=\"footwear\"),\n",
        "    pd.get_dummies(df.emotion, prefix=\"emotion\"),\n",
        "    pd.get_dummies(df.bodypose, prefix=\"bodypose\")\n",
        "    ], axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGiiepX97Y00",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_gender_cols_ = [col for col in one_hot_df.columns if col.startswith(\"gender\")]\n",
        "_imagequality_cols_ = [col for col in one_hot_df.columns if col.startswith(\"imagequality\")]\n",
        "_age_cols_ = [col for col in one_hot_df.columns if col.startswith(\"age\")]\n",
        "_weight_cols_ = [col for col in one_hot_df.columns if col.startswith(\"weight\")]\n",
        "_carryingbag_cols_ = [col for col in one_hot_df.columns if col.startswith(\"carryingbag\")]\n",
        "_footwear_cols_ = [col for col in one_hot_df.columns if col.startswith(\"footwear\")]\n",
        "_emotion_cols_ = [col for col in one_hot_df.columns if col.startswith(\"emotion\")]\n",
        "_bodypose_cols_ = [col for col in one_hot_df.columns if col.startswith(\"bodypose\")]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpVh0qZaIq-v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PersonImageDataGenerator(keras.utils.Sequence):\n",
        "\n",
        "  def __init__(self, data_df, image_size=(224, 224, 3), batch_size=32, shuffle=True, augment=None):\n",
        "    self.data_df = data_df\n",
        "    self.indices = data_df.index.tolist()\n",
        "    self.output_size = image_size\n",
        "    self.batch_size = batch_size\n",
        "    self.shuffle = shuffle\n",
        "    self.augment = augment\n",
        "    self.on_epoch_end()\n",
        "\n",
        "  def __len__(self):\n",
        "    # return number of batches (truncated)\n",
        "    return int(np.floor(len(self.data_df)/self.batch_size))\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    batch_df = self.data_df.iloc[idx*self.batch_size:(idx+1)*self.batch_size, :].copy()\n",
        "    indices = batch_df.index.tolist()\n",
        "    images = np.stack([cv2.resize(cv2.imread(batch_df.loc[rownum, \"image_path\"]), (self.output_size[0], self.output_size[1])) for rownum in indices])\n",
        "    _gender_cols_ = [col for col in batch_df.columns if col.startswith(\"gender\")]\n",
        "    target = {\n",
        "            \"gender_output\": batch_df[_gender_cols_].values,\n",
        "            \"image_quality_output\": batch_df[_imagequality_cols_].values,\n",
        "            \"age_output\": batch_df[_age_cols_].values,\n",
        "            \"weight_output\": batch_df[_weight_cols_].values,\n",
        "            \"bag_output\": batch_df[_carryingbag_cols_].values,\n",
        "            \"pose_output\": batch_df[_bodypose_cols_].values,\n",
        "            \"footwear_output\": batch_df[_footwear_cols_].values,\n",
        "            \"emotion_output\": batch_df[_emotion_cols_].values\n",
        "        }\n",
        "    if self.augment==None:\n",
        "      return images, target\n",
        "    else:\n",
        "      return np.stack([self.augment(image=x)[\"image\"] for x in images], axis=0), target\n",
        "\n",
        "  def on_epoch_end(self):\n",
        "    # shuffle dataset at the end of every epoch\n",
        "    if self.shuffle==True:\n",
        "      self.data_df = self.data_df.sample(frac=1).reset_index(drop=True)\n",
        "    else:\n",
        "      self.data_df = self.data_df.reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PpQs99jQh4K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# callbacks\n",
        "\n",
        "class CyclicLR(keras.callbacks.Callback):\n",
        "    \n",
        "    def __init__(self,base_lr, max_lr, step_size, base_m, max_m, cyclical_momentum):\n",
        " \n",
        "        self.base_lr = base_lr\n",
        "        self.max_lr = max_lr\n",
        "        self.base_m = base_m\n",
        "        self.max_m = max_m\n",
        "        self.cyclical_momentum = cyclical_momentum\n",
        "        self.step_size = step_size\n",
        "        \n",
        "        self.clr_iterations = 0.\n",
        "        self.cm_iterations = 0.\n",
        "        self.trn_iterations = 0.\n",
        "        self.history = {}\n",
        "        # self.on_epoch_end()\n",
        "        \n",
        "    def clr(self):\n",
        "        \n",
        "        cycle = np.floor(1+self.clr_iterations/(2*self.step_size))\n",
        "        \n",
        "        if cycle == 2:\n",
        "            x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)          \n",
        "            return self.base_lr-(self.base_lr-self.base_lr/100)*np.maximum(0,(1-x))\n",
        "        \n",
        "        else:\n",
        "            x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)\n",
        "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0,(1-x))\n",
        "    \n",
        "    def cm(self):\n",
        "        \n",
        "        cycle = np.floor(1+self.clr_iterations/(2*self.step_size))\n",
        "        \n",
        "        if cycle == 2:\n",
        "            \n",
        "            x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1) \n",
        "            return self.max_m\n",
        "        \n",
        "        else:\n",
        "            x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)\n",
        "            return self.max_m - (self.max_m-self.base_m)*np.maximum(0,(1-x))\n",
        "        \n",
        "        \n",
        "    def on_train_begin(self, logs={}):\n",
        "        logs = logs or {}\n",
        "\n",
        "        if self.clr_iterations == 0:\n",
        "            K.set_value(self.model.optimizer.lr, self.base_lr)\n",
        "        else:\n",
        "            K.set_value(self.model.optimizer.lr, self.clr())\n",
        "            \n",
        "        if self.cyclical_momentum == True:\n",
        "            if self.clr_iterations == 0:\n",
        "                K.set_value(self.model.optimizer.momentum, self.cm())\n",
        "            else:\n",
        "                K.set_value(self.model.optimizer.momentum, self.cm())\n",
        "            \n",
        "            \n",
        "    def on_batch_begin(self, batch, logs=None):\n",
        "        \n",
        "        logs = logs or {}\n",
        "        self.trn_iterations += 1\n",
        "        self.clr_iterations += 1\n",
        "\n",
        "        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n",
        "        self.history.setdefault('iterations', []).append(self.trn_iterations)\n",
        "        \n",
        "        if self.cyclical_momentum == True:\n",
        "            self.history.setdefault('momentum', []).append(K.get_value(self.model.optimizer.momentum))\n",
        "\n",
        "        for k, v in logs.items():\n",
        "            self.history.setdefault(k, []).append(v)\n",
        "        \n",
        "        K.set_value(self.model.optimizer.lr, self.clr())\n",
        "        \n",
        "        if self.cyclical_momentum == True:\n",
        "            K.set_value(self.model.optimizer.momentum, self.cm())\n",
        "\n",
        "\n",
        "# print LR\n",
        "class printLR(keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        lr = self.model.optimizer.lr\n",
        "        print(K.eval(lr))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jyt-5mn7hh1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# resnet layer definition\n",
        "\n",
        "def resnet_layer(inputs,\n",
        "                 num_filters=16,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 conv_first=True):\n",
        "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
        "\n",
        "    # Arguments\n",
        "        inputs (tensor): input tensor from input image or previous layer\n",
        "        num_filters (int): Conv2D number of filters\n",
        "        kernel_size (int): Conv2D square kernel dimensions\n",
        "        strides (int): Conv2D square stride dimensions\n",
        "        activation (string): activation name\n",
        "        batch_normalization (bool): whether to include batch normalization\n",
        "        conv_first (bool): conv-bn-activation (True) or\n",
        "            bn-activation-conv (False)\n",
        "\n",
        "    # Returns\n",
        "        x (tensor): tensor as input to the next layer\n",
        "    \"\"\"\n",
        "    conv = Conv2D(num_filters,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=strides,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))\n",
        "\n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "        x = conv(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVE8-OaZ8J5q",
        "colab_type": "code",
        "outputId": "9bb1a25b-92de-4aa4-cce8-5e2278a0b071",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, val_df = train_test_split(one_hot_df, test_size=0.15, random_state=42)\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "val_df = val_df.reset_index(drop=True)\n",
        "train_df.shape, val_df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((11537, 28), (2036, 28))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38RVGeoF9g7o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images = [cv2.imread(train_df[\"image_path\"].iloc[x]) for x in range(len(train_df))]\n",
        "train_images = np.stack(train_images)\n",
        "labels = train_df[_gender_cols_].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyOQd4ksB0MU",
        "colab_type": "code",
        "outputId": "05e21d5c-388f-4a08-8f51-8e7c482a5014",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train_images.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11537, 224, 224, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xj5Be112Zlx1",
        "colab_type": "code",
        "outputId": "aea6f223-9150-4d0e-d39d-7c10faff2450",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "labels.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11537, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "F01FKmnVCaQh",
        "colab": {}
      },
      "source": [
        "# train_mean = np.mean(train_images, axis=(0, 1, 2))/255.0\n",
        "train_mean = np.array([0.16198463, 0.1628683 , 0.18274376])\n",
        "# train_std = np.std(train_images, axis=(0, 1, 2))/255.0\n",
        "train_std = np.array([0.25078711, 0.25332862, 0.27367283])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9YTZtm9371X1",
        "colab": {}
      },
      "source": [
        "# Training parameters\n",
        "n = 2 #(number of resnet blocks)\n",
        "depth = n*9+2\n",
        "\n",
        "# Input image dimensions.\n",
        "input_shape = (224, 224, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZ78yYjY6ANX",
        "colab_type": "code",
        "outputId": "e33575e4-fee7-4eb8-904b-37f624f570f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\"\"\"\n",
        "\n",
        "APPROACH:\n",
        "\n",
        "Build backbone of the final model by training on the gender output.\n",
        "Use the first few layers of this model as the backbone, append the tower and head and train for each output to get the final model\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "########################################################################\n",
        "##########################   BACKBONE   ################################\n",
        "########################################################################\n",
        "\n",
        "# Start model definition.\n",
        "num_filters_in = 16\n",
        "num_res_blocks = n\n",
        "\n",
        "inputs = Input(shape=input_shape)   # size 224x224\n",
        "\n",
        "# x = MaxPool2D(pool_size=(2,2))(inputs)   # output 112x112\n",
        "\n",
        "x = Conv2D(16,\n",
        "          kernel_size=(3,3),\n",
        "          kernel_initializer='he_normal',\n",
        "          kernel_regularizer=l2(1e-4),\n",
        "          activation='relu')(inputs)  # output 110x110\n",
        "                                 # output 222x222\n",
        "x = MaxPool2D(pool_size=(2,2))(x)   # output 55x55\n",
        "                                    # output 111x111\n",
        "\n",
        "\n",
        "# v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n",
        "x = resnet_layer(inputs=x,\n",
        "                num_filters=num_filters_in,\n",
        "                conv_first=True)  # output of 54x54\n",
        "                                  # output 111x111\n",
        "\n",
        "# 3 stages - each stage has n residual blocks (each residual block has 3 convolution sets, the first one compresses except in the first stage)\n",
        "# Instantiate the stack of residual units\n",
        "for stage in range(3):\n",
        "    for res_block in range(num_res_blocks):\n",
        "        activation = 'relu'\n",
        "        batch_normalization = True\n",
        "        strides = 1\n",
        "        if stage == 0:\n",
        "            num_filters_out = num_filters_in * 4\n",
        "            if res_block == 0:  # first layer and first stage\n",
        "                activation = None\n",
        "                batch_normalization = False\n",
        "        else:\n",
        "            num_filters_out = num_filters_in * 2\n",
        "            if res_block == 0:  # first layer but not first stage\n",
        "                strides = 2    # downsample\n",
        "\n",
        "        # bottleneck residual unit\n",
        "        y = resnet_layer(inputs=x,\n",
        "                          num_filters=num_filters_in,\n",
        "                          kernel_size=1,\n",
        "                          strides=strides,\n",
        "                          activation=activation,\n",
        "                          batch_normalization=batch_normalization,\n",
        "                          conv_first=False)\n",
        "        # y = Dropout(0.2)(y)\n",
        "        y = resnet_layer(inputs=y,\n",
        "                          num_filters=num_filters_in,\n",
        "                          conv_first=False)\n",
        "        y = resnet_layer(inputs=y,\n",
        "                          num_filters=num_filters_out,\n",
        "                          kernel_size=1,\n",
        "                          conv_first=False)\n",
        "        # y = Dropout(0.2)(y)\n",
        "\n",
        "        if res_block == 0:\n",
        "            # linear projection residual shortcut connection to match\n",
        "            # changed dims\n",
        "            x = resnet_layer(inputs=x,\n",
        "                              num_filters=num_filters_out,\n",
        "                              kernel_size=1,\n",
        "                              strides=strides,\n",
        "                              activation=None,\n",
        "                              batch_normalization=False)\n",
        "        x = keras.layers.add([x, y])\n",
        "\n",
        "    num_filters_in = num_filters_out\n",
        "# output from resnet layers of 14x14\n",
        "                              #  28x28\n",
        "x = Conv2D(128,\n",
        "           kernel_size=1)(x) # output of 14x14\n",
        "                                        #  28x28\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "x = MaxPool2D(pool_size=(2,2))(x)  #  14x14\n",
        "\n",
        "x = SeparableConv2D(filters = 160, kernel_size=3, activation = 'relu')(x) # 12x12\n",
        "\n",
        "x = SeparableConv2D(filters = 192, kernel_size=3, activation = 'relu')(x) # 10x10\n",
        "\n",
        "x = Conv2D(208,\n",
        "           kernel_size=(3,3), activation='relu')(x)   # output of 8x8\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "x = Conv2D(224,\n",
        "           kernel_size=(3,3), activation='relu')(x)   # output of 6x6\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "x = Conv2D(240,\n",
        "           kernel_size=(3,3), activation='relu')(x)   # output of 4x4\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "output = Dense(2, activation=\"softmax\", name=\"gender_output\")(x)\n",
        "\n",
        "\n",
        "# define model\n",
        "model = Model(\n",
        "    inputs=inputs, \n",
        "    outputs=output\n",
        ")\n",
        "\n",
        "opt = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
        "model.compile(\n",
        "    optimizer=opt,\n",
        "    loss=\"categorical_crossentropy\", \n",
        "    # loss_weights=loss_weights, \n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 222, 222, 16) 448         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 111, 111, 16) 0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 111, 111, 16) 2320        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 111, 111, 16) 64          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 111, 111, 16) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 111, 111, 16) 272         activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 111, 111, 16) 64          conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 111, 111, 16) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 111, 111, 16) 2320        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 111, 111, 16) 64          conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 111, 111, 16) 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 111, 111, 64) 1088        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 111, 111, 64) 1088        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 111, 111, 64) 0           conv2d_6[0][0]                   \n",
            "                                                                 conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 111, 111, 64) 256         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 111, 111, 64) 0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 111, 111, 16) 1040        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 111, 111, 16) 64          conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 111, 111, 16) 0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 111, 111, 16) 2320        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 111, 111, 16) 64          conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 111, 111, 16) 0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 111, 111, 64) 1088        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 111, 111, 64) 0           add_1[0][0]                      \n",
            "                                                                 conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 111, 111, 64) 256         add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 111, 111, 64) 0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 56, 56, 64)   4160        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 56, 56, 64)   256         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 56, 56, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 56, 56, 64)   256         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 56, 56, 64)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 56, 56, 128)  8320        add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 56, 56, 128)  8320        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 56, 56, 128)  0           conv2d_13[0][0]                  \n",
            "                                                                 conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 56, 56, 128)  512         add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 56, 56, 128)  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 56, 56, 64)   8256        activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 56, 56, 64)   256         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 56, 56, 64)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 56, 56, 64)   36928       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 56, 56, 64)   256         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 56, 56, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 56, 56, 128)  8320        activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 56, 56, 128)  0           add_3[0][0]                      \n",
            "                                                                 conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 56, 56, 128)  512         add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 56, 56, 128)  0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 28, 28, 128)  16512       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 28, 28, 128)  512         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 28, 28, 128)  0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 28, 28, 128)  512         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 28, 28, 128)  0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 28, 28, 256)  33024       add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 28, 28, 256)  33024       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 28, 28, 256)  0           conv2d_20[0][0]                  \n",
            "                                                                 conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 28, 28, 256)  1024        add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 28, 28, 256)  0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 28, 28, 128)  32896       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 28, 28, 128)  512         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 28, 28, 128)  0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 28, 28, 128)  512         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 28, 28, 128)  0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 28, 28, 256)  33024       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 28, 28, 256)  0           add_5[0][0]                      \n",
            "                                                                 conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 28, 28, 128)  32896       add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 28, 28, 128)  0           conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 14, 14, 128)  0           dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_1 (SeparableCo (None, 12, 12, 160)  21792       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_2 (SeparableCo (None, 10, 10, 192)  32352       separable_conv2d_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 8, 8, 208)    359632      separable_conv2d_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 8, 8, 208)    832         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 8, 8, 208)    0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 6, 6, 224)    419552      dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 6, 6, 224)    896         conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 6, 6, 224)    0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 4, 4, 240)    484080      dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 4, 4, 240)    960         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 240)          0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "gender_output (Dense)           (None, 2)            482         global_average_pooling2d_1[0][0] \n",
            "==================================================================================================\n",
            "Total params: 1,926,290\n",
            "Trainable params: 1,921,970\n",
            "Non-trainable params: 4,320\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WTteySE8_zI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set up training parameters\n",
        "training_batch_size=32\n",
        "epochs=50\n",
        "\n",
        "\n",
        "AUGMENTATIONS_TRAIN = Compose([\n",
        "    HorizontalFlip(p=0.5),\n",
        "    # Cutout(num_holes=1, max_h_size = int(input_shape[0]/5), max_w_size=int(input_shape[0]/5), p=1),\n",
        "    # Normalize(mean=tuple(train_mean), std=tuple(train_std), max_pixel_value=255.0, p=1),\n",
        "    Normalize(mean=(0, 0, 0), std=(1, 1, 1), max_pixel_value=255.0, p=1),\n",
        "    ShiftScaleRotate(\n",
        "        shift_limit=0.0625, scale_limit=0.1, \n",
        "        rotate_limit=15, border_mode=cv2.BORDER_REFLECT_101, p=0.3)\n",
        "])\n",
        "\n",
        "AUGMENTATIONS_VAL = Compose([\n",
        "    # CLAHE(p=1.0, clip_limit=2.0),\n",
        "    # Normalize(mean=tuple(train_mean), std=tuple(train_std), max_pixel_value=255.0, p=1.0)\n",
        "    # , \n",
        "    Normalize(mean=(0, 0, 0), std=(1, 1, 1), max_pixel_value=255.0, p=1)\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTiOi5tVBnhS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create train and validation data generators\n",
        "train_genr = PersonImageDataGenerator(train_df, batch_size=training_batch_size, shuffle=True, augment=AUGMENTATIONS_TRAIN)\n",
        "valid_genr = PersonImageDataGenerator(val_df, batch_size=64, shuffle=False, augment=AUGMENTATIONS_VAL)\n",
        "num_units = { k.split(\"_output\")[0]:v.shape[1] for k, v in targets.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oZaCeDC-9p4",
        "colab_type": "code",
        "outputId": "12f84e58-dec0-4a91-acbc-39390895117d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "num_units"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'age': 5,\n",
              " 'bag': 3,\n",
              " 'emotion': 4,\n",
              " 'footwear': 3,\n",
              " 'gender': 2,\n",
              " 'image_quality': 3,\n",
              " 'pose': 3,\n",
              " 'weight': 4}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pMDGat-Ghow",
        "colab_type": "code",
        "outputId": "5c6a50be-e4db-4c05-8f18-873e2d3261ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        }
      },
      "source": [
        "# get number of output units from data\n",
        "images, targets = next(iter(train_genr))\n",
        "i=9\n",
        "cv2_imshow(images[i]*255)\n",
        "print(_gender_cols_)\n",
        "print(targets[\"gender_output\"][i])\n",
        "print(_imagequality_cols_)\n",
        "print(targets[\"image_quality_output\"][i])\n",
        "print(_age_cols_)\n",
        "print(targets[\"age_output\"][i])\n",
        "print(_weight_cols_)\n",
        "print(targets[\"weight_output\"][i])\n",
        "print(_carryingbag_cols_)\n",
        "print(targets[\"bag_output\"][i])\n",
        "print(_footwear_cols_)\n",
        "print(targets[\"footwear_output\"][i])\n",
        "print(_emotion_cols_)\n",
        "print(targets[\"emotion_output\"][i])\n",
        "print(_bodypose_cols_)\n",
        "print(targets[\"pose_output\"][i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOAAAADgCAIAAACVT/22AACOPUlEQVR4nOz9Wa+lSZYdiO3BzL7h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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=224x224 at 0x7FDAD14A0358>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "['gender_female', 'gender_male']\n",
            "[1 0]\n",
            "['imagequality_Average', 'imagequality_Bad', 'imagequality_Good']\n",
            "[1 0 0]\n",
            "['age_15-25', 'age_25-35', 'age_35-45', 'age_45-55', 'age_55+']\n",
            "[0 1 0 0 0]\n",
            "['weight_normal-healthy', 'weight_over-weight', 'weight_slightly-overweight', 'weight_underweight']\n",
            "[0 0 1 0]\n",
            "['carryingbag_Daily/Office/Work Bag', 'carryingbag_Grocery/Home/Plastic Bag', 'carryingbag_None']\n",
            "[0 0 1]\n",
            "['footwear_CantSee', 'footwear_Fancy', 'footwear_Normal']\n",
            "[1 0 0]\n",
            "['emotion_Angry/Serious', 'emotion_Happy', 'emotion_Neutral', 'emotion_Sad']\n",
            "[0 1 0 0]\n",
            "['bodypose_Back', 'bodypose_Front-Frontish', 'bodypose_Side']\n",
            "[0 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZ-Km1Xea9l9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import keras_contrib\n",
        "# from data_science_utils.vision.keras import LRFinder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fs-0s-OV6r_",
        "colab_type": "code",
        "outputId": "a778fe37-a56f-4daa-9825-ed78fbccc7b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        }
      },
      "source": [
        "# lrf = LRFinder(model)\n",
        "# lrf.find_generator(train_genr, 0.0000001, 10, valid_genr, epochs=4)\n",
        "# lrf.plot_loss()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Stop Training at 201, loss = 10.891\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtEAAAGHCAYAAAB29g5wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nOzdd3xb9bnH8e/jHa8kjp29N9lABgEC\ngbChhFJmWS3ccuG2hbZ095aWjgu07DJaRlkFyqaMECAQIOwMsuPsHe+9bUm/+4dkYSe2IwUrluPP\n+/XyK9bR0TmPTmTpOT89v+eYc04AAAAAQhfT0QEAAAAAnQ1JNAAAABAmkmgAAAAgTCTRAAAAQJhI\nogEAAIAwkUQDAAAAYSKJBgBEJTPbZmYndXQcANASkmgAaEVrSZyZzTYzn5lVmlmFma03s+8ehHje\nN7P/ivR+Wtl3mpndETgmVWa2w8xeMLMZHREPAHQ0kmgAODB7nHOpktIl/VjSQ2Y2poNjiggzS5T0\nnqSJks6S/zkfJunfkk5v5TFxBy1AAOgAJNEA8DU4v3mSiiVNamkdM3vTzH6w17IVZnau+d1pZvlm\nVm5mq8xsQrhxmNnZZrbGzEoDI9aHNbnvF2a2u8mo+ZzA8ulmtiSw3zwzu6OVzV8maaCkc5xzq51z\nXudclXPuBefc75vsx5nZ981so6SNgWV3m9nOwD6WmtmsJuv/PjCa/WwgtmVmNnmvfU8xs5VmVhZY\nLyncYwMAkUASDQBfg5nFmNnZkjIlbWpltWckXdzkMeMkDZH0hqRTJB0nabSk7pIukFQUZgyjA/v4\nkaQsSfMkvWZmCYHR8R9ImuacS5N0qqRtgYfeLelu51y6pBGSnmtlFydJess5VxVCOOdImiFpXOD2\nYklTJGVIelrS83slwnMlPd/k/lfMLL7J/RdIOk3SMPlPUr4TQgwAEHEk0QBwYPqbWamkGkkvS/qJ\nc+7LVtZ9Wf4R1SGB25dIesk5VyepQVKapLGSzDm3zjmXE2YsF0p6wzn3jnOuQdJtkrpJOlqSV1Ki\npHFmFu+c2+ac2xx4XIOkkWaW6ZyrdM591sr2MyXlNt4wsymBEe9yM1u/17o3O+eKnXM1kuSc+5dz\nrsg553HO3R6IpWnZy9LAiHaDpDskJUk6qsn99zjn9jjniiW9Jn9CDgAdjiQaAA7MHudcD/nrg++R\ndGJrKzrnKuQfdb4osOhiSU8F7ntP0r2S7pOUb2YPmll6mLH0l7S9yf58knZKGuCc2yT/CPXvA9v/\nt5n1D6x6lfwj4NlmttjMzmpl+0WS+jXZ/vLAcz9X/qS4qZ1Nb5jZT81sXaAco1T+0fbMltYPxL0r\n8Hwa5Tb5vVpSaisxAsBBRRINAF9DYDT5F5Immtk5baz6jKSLzWym/KOtC5ts4x7n3JHyl0CMlvSz\nMMPYI395iCTJzEzSIEm7A9t/2jl3bGAdJ+nWwPKNzrmLJfUOLHvBzFJa2P67kk5p5b69uSZxzJL0\nc/lLMnoGEu8ySdZk/UFN1o+Rv/Z6Twj7AYAORRINAG2LN7OkJj/7dJ1wztVLul3SjW1sZ578Sewf\nJD0bGHWVmU0zsxmBOuAqSbWSfG1sJ26veOLlr2U+08zmBG7fIKlO0idmNsbMTgx02KiVv/ykcd+X\nmllWIJbSwPZb2vcTknIkvWxmE8wsNlDXPLWNOCV/mYpHUkEg7hvlH7lv6sjABMs4+UfM6yS1VlYC\nAFGDJBoA2jZP/sSz8ef3raz3T0mDzewbLd0ZGLF+Sf5Jek83uStd0kOSSuQvySiS9Nc24nlgr3ge\ndc6tl3SppL9JKpT0DUnfCCT3iZJuCSzPlX/U+VeBbZ0maY2ZVco/yfCixlrmvWKvlXSCpLXyl6WU\nS1ovaZr8o8yteUvSfEkbAs+tVnuVe0j6j/w13SXydwE5N1AfDQBRzZxz+18LAIB2Zma/lzTSOXdp\nR8cCAOFiJBoAAAAIE0k0AAAAECbKOQAAAIAwMRINAAAAhIkkGgAAAAjTPv1Oo11mZqYbOnRoR4cB\nAACAQ9zSpUsLnXNZLd3X6ZLooUOHasmSJR0dBgAAAA5xZra9tfso5wAAAADCRBINAAAAhIkkGgAA\nAAgTSTQAAAAQJpJoAAAAIEwk0QAAAECYSKIBAACAMJFEAwAAAGEiiQYAAADCRBINAAAAhIkkGgAA\nAAgTSTQAAACiUk29V4WVdfL6XEeHsg+SaAAAAESl11bs0dQ/LVBOWU1Hh7IPkmgAAABEpTqPV5KU\nGBfbwZHsiyQaAAAAUanO45MkJcRFX8oafREBAAAAkuq9/iQ6kSQaAAAACE1dQ2AkOjb6UtboiwgA\nAACQfyQ6PtYUE2MdHco+SKIBAAAQleoafFE5qVAiiQYAAECUqvd6o3JSoUQSDQAAgChV7/FFZT20\nRBINAACAKFXn8SkxPjrT1eiMCgAAAF0eI9EAAABAmBiJBgAAAMLESDQAAAAQpnqPj+4cAAAAQDjq\nPF76RAMAAADhqGMkGgAAAAhPvcenRJJoAAAAIHSMRAMAAABhqvcyEg0AAACEpa6BiYUAAABAWOq9\nlHMAAAAAIXPO+a9YSBINAAAAhMbjc3JOXLEQAAAACFW9xydJlHMAAAAAoaoLJNGUcwAAAAAh+mok\nmu4cAAAAQEgo5wAAAADCVOfxSqKcAwAAAAhZHSPRAAAAQHiYWAgAAACEiZpoAAAAIEz1XkaiAQAA\ngLDUNTROLKTFHQAAABCSxpFoyjkAAACAENU2+JPoJEaiAQAAgNDUBso5kuKjM12NzqgAAADQpQWT\n6ARGogEAAICQNCbR3eJJogEAAICQ1DR4FRtjio+NznQ1OqMCAABAl1bb4IvaUWiJJBoAAABRqKbB\nG7WTCiWSaAAAAESh2nqvkhiJBgAAAEJX6+miSbSZJZnZF2a2wszWmNlNLayTaGbPmtkmM/vczIZG\nKh4AAAB0HjX13i5bE10n6UTn3GRJUySdZmZH7bXOVZJKnHMjJd0p6dYIxgMAAIBOorbB1zVrop1f\nZeBmfODH7bXaXEmPB35/QdIcM7NIxQQAAIDOwT+xsGuORMvMYs1suaR8Se845z7fa5UBknZKknPO\nI6lMUq9IxgQAAIDoV9uVk2jnnNc5N0XSQEnTzWzCgWzHzK42syVmtqSgoKB9gwQAAEDUqW3oujXR\nQc65UkkLJZ221127JQ2SJDOLk9RdUlELj3/QOTfVOTc1Kysr0uECAACgg3XZmmgzyzKzHoHfu0k6\nWVL2Xqu9KumKwO/nSXrPObd33TQAAAC6mJooH4mOi+C2+0l63Mxi5U/Wn3POvW5mf5C0xDn3qqRH\nJD1pZpskFUu6KILxAAAAoJOI9proiCXRzrmVkg5vYfmNTX6vlXR+pGIAAABA5+PzOdV5fFGdREdv\noQkAAAC6pDqPT5JIogEAAIBQ1TR4JUnduuLEQgAAAOBA1AaSaEaiAQAAgBAFR6ITSKIBAACAkDSO\nRCfGkUQDAAAAIallJBoAAAAIT22DvztHNF9shSQaAAAAUeWrco7oTVWjNzIAAAB0SV6fkyTFxlgH\nR9I6kmgAAABElUAOrRgjiQYAAABC4pw/i46J4kw1ikMDAABAV8RINAAAABAmX+NIdPTm0CTRAAAA\niC6NSbQxEg0AAACExlHOAQAAAISHcg4AAAAgTEwsBAAAAML0VU10BwfSBpJoAAAARJVgn+gozqJJ\nogEAABBVKOcAAAAAwsTEQgAAACBMjSPR9IkGAAAAQuQYiQYAAADC4/MxsRAAAAAICxMLAQAAgDAF\n+0RHcaYaxaEBAACgK3KMRAMAAADhocUdAAAAECZqogEAAIAwBWuiozeHJokGAABAdPmqT3T0ZtEk\n0QAAAIgqlHMAAAAAYWJiIQAAABCmxpFoYyQaAAAACI1zLqpHoSWSaAAAAEQZn3NRPQotkUQDAAAg\nyvhcdNdDSyTRAAAAiDKMRAMAAADhYiQaAAAACI/PuajuES2RRAMAACDK+GuiSaIBAACAkPlrojs6\niraRRAMAACCqOEaiAQAAgPD4uNgKAAAAEB4mFgIAAABh8jnRJxoAAAAIh6OcAwAAAAiPz8fEQgAA\nACAsTCwEAAAAwkRNNAAAABAm55xiojxLjfLwAAAA0NXQ4g4AAAAIk48rFgIAAADh8TmnKM+hSaIB\nAAAQXRwj0QAAAEB4aHEHAAAAhKlLTyw0s0FmttDM1prZGjO7voV1ZptZmZktD/zcGKl4AAAA0Dl0\nhj7RcRHctkfSDc65ZWaWJmmpmb3jnFu713qLnHNnRTAOAAAAdCKuK5dzOOdynHPLAr9XSFonaUCk\n9gcAAIBDAy3uAsxsqKTDJX3ewt0zzWyFmb1pZuNbefzVZrbEzJYUFBREMFIAAAB0NCYWSjKzVEkv\nSvqRc658r7uXSRrinJss6W+SXmlpG865B51zU51zU7OysiIbMAAAADpUZ6iJjmgSbWbx8ifQTznn\nXtr7fudcuXOuMvD7PEnxZpYZyZgAAAAQ3bp0TbT5Tx8ekbTOOXdHK+v0DawnM5seiKcoUjEBAAAg\n+nWGFneR7M5xjKTLJK0ys+WBZb+WNFiSnHN/l3SepGvNzCOpRtJFzjkXwZgAAAAQ5Xy+6J9YGLEk\n2jn3kaQ2n71z7l5J90YqBgAAAHQ+PucU5Tk0VywEAABAdHG0uAMAAADC43NOMVGepUZ5eAAAAOhq\nOsPEQpJoAAAARBVfJ2gzQRINAACAqOKcU2yUN4omiQYAAEBU8VLOAQAAAITH3ye6o6NoG0k0AAAA\nogoTCwEAAIAwkUQDAAAAYfI5MbEQAAAACIfPx2W/AQAAgLD4aHEHAAAAhIcWdwAAAECY/C3uSKIB\nAACAkPm7c3R0FG0jiQYAAEBUoSYaAAAACJPXJxnlHAAAAEDoHOUcAAAAQHgo5wAAAADC5PXR4g4A\nAAAIi3O0uAMAAADC4qUmGgAAAAgPNdEAAABAmHyHSos7M7vezNLN7xEzW2Zmp0Q6OAAAAHQ9/pHo\njo6ibaGGd6VzrlzSKZJ6SrpM0i0RiwoAAABdlr8m+hAYiZbU+CzOkPSkc25Nk2UAAABAu3DOHVLd\nOZaa2dvyJ9FvmVmaJF/kwgIAAEBX5Jz/32hPouNCXO8qSVMkbXHOVZtZhqTvRi4sAAAAdEXeQBYd\n5c05Qh6JnilpvXOu1MwulfS/ksoiFxYAAAC6Il9jEh3lWXSoSfQDkqrNbLKkGyRtlvRExKICAABA\nl+QLFAxHezlHqEm0xznnJM2VdK9z7j5JaZELCwAAAF1R40h0tLe4C7UmusLMfiV/a7tZZhYjKT5y\nYQEAAKAr+qom+tAYib5QUp38/aJzJQ2U9NeIRQUAAIAuyR1K5RyBxPkpSd3N7CxJtc45aqIBAADQ\nrg6p7hxmdoGkLySdL+kCSZ+b2XmRDAwAAABdz1c10dGdRYdaE/0bSdOcc/mSZGZZkhZIeiFSgQEA\nAKDr8fn8SbQdCuUckmIaE+iAojAeCwAAAITEd4hdsXC+mb0l6ZnA7QslzYtMSAAAAOiqDqkWd865\nn5nZtyQdE1j0oHPu5ciFBQAAgK7I20nKOUIdiZZz7kVJL0YwFgAAAHRxgYFoxXbmJNrMKiS5lu6S\n5Jxz6RGJCgAAAF1SsMVdZy7ncM5xaW8AAAAcNL5D7IqFAAAAQMQ1trgjiQYAAABC1NjiLtovtkIS\nDQAAgKjh9R1Cl/0GAAAADgZqogEAAIAwkUQDAAAAYQpe9jvKs9QoDw8AAABdCSPRAAAAQJhocQcA\nAACEiRZ3AAAAQJgaW9xF+UA0STQAAACihwvURMdGeRZNEg0AAICo4W2cWEg5BwAAABCaYIu7rjoS\nbWaDzGyhma01szVmdn0L65iZ3WNmm8xspZkdEal4AAAAEP18neSy33ER3LZH0g3OuWVmliZpqZm9\n45xb22Sd0yWNCvzMkPRA4F8AAAB0QY19ortsdw7nXI5zblng9wpJ6yQN2Gu1uZKecH6fSephZv0i\nFRMAAACim5c+0V8xs6GSDpf0+V53DZC0s8ntXdo30QYAAEAX0VgTHeU5dOSTaDNLlfSipB8558oP\ncBtXm9kSM1tSUFDQvgECAAAgariuXs4hSWYWL38C/ZRz7qUWVtktaVCT2wMDy5pxzj3onJvqnJua\nlZUVmWABAADQ4YIt7qJ8KDqS3TlM0iOS1jnn7mhltVclXR7o0nGUpDLnXE6kYgIAAEB06ywt7iLZ\nneMYSZdJWmVmywPLfi1psCQ55/4uaZ6kMyRtklQt6bsRjAcAAABRrsu3uHPOfSSpzafv/EUv349U\nDAAAAOhcunyLOwAAACBctLgDAAAAwuQaa6IZiQYAAABC81V3jg4OZD9IogEAABA1gjXRlHMAAAAA\noWnszmEk0QAAAEBovuoT3bFx7A9JNAAAAKIGLe4AAACAMHkp5wAAAADC09jijpFoAAAAIES0uAMA\nAADC5HNcsRAAAAAIi4/LfgMAAADh8VETDQAAAITH66MmGgAAAAiLc7S4AwAAAMLidS7qSzkkkmgA\nAABEEZ+L/lIOiSQaAAAAUcTnXNR35pBIogEAABBFfD6SaAAAACAsPhf97e0kkmgAAABEEa/PqRMM\nRJNEAwAAIHo4unMAAAAA4fEysRAAAAAIj7/FHUk0AAAAEDJ/d46OjmL/SKIBAAAQNegTDQAAAITJ\n66PFHQAAABAW52hxBwAAAITFR4s7AAAAIDxeunMAAAAA4fFPLOzoKPaPJBoAAABRw9/iLvqzaJJo\nAAAARA1qogEAAIAweX2SMRINAAAAhM45p9hOkKF2ghABAADQVXi5YiEAAAAQHp+jnAMAAAAIi8/n\nFBv9OTRJNAAAAKKHj3IOAAAAIDwVtR6lJsV1dBj7RRINAACAqFFcVa+MlISODmO/SKIBAAAQNYqq\n6tSLJBoAAAAITXW9R7UNPmWkJHZ0KPtFEg0AAICoUFRZL0mMRAMAAAChKqn2J9E9SaIBAACA0NR7\nfJKkxLjoT1GjP0IAAAB0CT7n/zc2hj7RAAAAQEi8gSy6E1xrhSQaAAAA0cHn/El0bCfIokmiAQAA\nEBUak+gYyjkAAACA0DSWc8QwEg0AAACEJjAQrU4wEE0SDQAAgOjQOBJNdw4AAAAgRMGaaMo5AAAA\ngNCQRAMAAABh4mIrkszsn2aWb2arW7l/tpmVmdnywM+NkYoFAAAA0e+r7hwdHEgI4iK47cck3Svp\niTbWWeScOyuCMQAAAKCToE+0JOfch5KKI7V9AAAAHFqoiQ7dTDNbYWZvmtn4Do4FAAAAHcjr8//b\nGS77Hclyjv1ZJmmIc67SzM6Q9IqkUS2taGZXS7pakgYPHnzwIgQAAMBB0zgS3Qly6I4biXbOlTvn\nKgO/z5MUb2aZraz7oHNuqnNualZW1kGNEwAAAAeHj4ut7J+Z9TXzn2eY2fRALEUdFQ8AAAA6li94\n2e/oT6IjVs5hZs9Imi0p08x2SfqdpHhJcs79XdJ5kq41M4+kGkkXOdd4xXQAAAB0Nd5gd44ODiQE\nEUuinXMX7+f+e+VvgQcAAADI0Z0DAAAACE/jxVY6Q3cOkmgAAABEhc5UE00SDQAAgKjQ2J2jM9RE\nd4IQAQAA0BU09ommxR0AAAAQIi8TCwEAAIDwBMs5SKIBAACA0Hw1sbBj4wgFSTQAAACigpfLfgMA\nAADhabzYilHOAQAAAITG61ynGIWWSKIBAAAQJXyuc9RDSyTRAAAAiBI+n+sUnTkkkmgAAABECZ8j\niQYAAADC4vV1js4cEkk0AAAAooR/JLqjowgNSTQAAACigs85xXSSLJokGgAAAFHB63OKpSYaAAAA\nCJ3PdY4LrUgk0QAAAIgSPp9TbCfJTjtJmAAAADjU0eIOAAAACJOXJBoAAAAIj3NSTCfJTjtJmAAA\nAF+fc04NXl9Hh4FW0J0DAAAgyni8Pp1z/yc69/5POjoUtIKaaAAAgCjz8eYirdhZqlW7y7SloFLO\nOa3dU67T716kN1bmdHR4UOe62EpcRwcAAABwMCxYmxf8/cTbP9Ckgd3VKyVB63LKdev8bJ05qV+z\n9X0+pxeW7dKp4/uqe7f4gx1ul+TzqdNc9pskGgAAdAkb8ip0xOAeWrajVJK0cleZJCklIVY7iqu1\nq6RaVXVe/e7V1UqKj9X76wskSY9/sk3PXzNTyQmkTZHWmbpz8GoAAACHvAfe36zPtxbrzEn9NO+c\niSqprtfnW4qUV16nU8b30VWPL9GukhrdtWCDPttS3Oyxa/aU64y7FykzNVF/OW+ShmeldtCzOPRV\n13sUF0sSDQAA0OEeXrRFt87PliQN7NlN4/qnS5KOGZkpSdqUXyFJyiuvlcmfwN154WSdM2WAGrxO\nzy/dqZteW6ttRdU68fYP9MI1MzV1aEYHPJNDW155rT7dXKTvHTe8o0MJCRMLAQDAIauqzqO7FmyU\nJH3/hBG67sRR+6zTt3s3Sf4R50+3FOmsSf30zcMHysyUEBejS2YM0crfnaL/++ZESdJtb68/eE+g\nC8ktq5XPSdM7yQkKI9EAAOCQ9ezinaqs8+i5/56p6cNaTs5SE+MUY9KDH26RJM0albnPOknxsfr2\njMEqrKzTHe9s0LOLd+jCaYMjGntXU9vgleQ/1p0BSTQAADgkbC+q0n89vkR9uyepW3ysfnbqGG0v\nqlJaUlyrCXSj780arq2FVbr6uOFtlmpcdewwPfX5dj32yXaS6HZW6/FfBCcpvnMUSpBEQ5L/7C8+\nNkaxgb4yzjnlldepb/ck1Xm82llco5G9mUgBAIher6/M0cb8Sm3Mr5QkldU0KL1bvPoHyjXa8qsz\nDgtpHymJcbp0xhDd/s4GlVbXq0dywteKGV9hJBqdTklVvWb9ZaFiTDpzUj+N7Zuu99fna2GgtU+j\np/5rRnASBgAA0ebzrV911RjXL12LtxVrYM9kDctMadf9TBzYXZK0PrdCM4b3anPd4qp6/XvxDp0y\nro9G9k474H3mV9TqmieX6uZzJ2lM3zQ552Rm+s/y3frXZ9v18OXT1D25c/eyJolGp/PhxgJV1nk0\nsGc3PfPFzmb3TRvaU71SEjV/Ta4eWrRFx4zMVFlNg3LLajWm74G/GQAA0N7W7inXuYcP0FmT+yk+\nNkaXPfKFdhRX65iRbSe64Wr8ZnZTQWWbSXRRZZ2+8+hirdpdpr/MX6/JA7tr2tAM/ebMw2Rh9kJ+\neNFWLdtRqj+9sVapiXH6YEOBZgzLCA54Xfjgpzr3iAE678hBykjZ/+i41+dU2+BVSmL0pIIk0Yeo\nZTtK9Ld3NyouNkZ3XjhFqVH0ojtQXp/T7pIa/fWt9cpKS9QHPztB76zN1YJ1+brsqCGaPKhHcN2b\n31ynhz7coi93lOi+hZu0YF2+MlMTNLRXyj49MzflV2rNnjKdPbl/2G8S0cA5J59TsLQFADqTkqp6\nbS6o7FIt2GrqvdpZUq3CyjqNH9BdJ47to8LKuuD9h/VLb9f99e/eTckJsdqQW9Hmer95ebVW7fZ/\nHr66Yo9W7CrTil1lOufwAbprwQb9zwkjdcTgniHt89PNRZKkRRsLlZoYJ+cUTKCnDe2pxdtK9H/z\nsjVvVa4evmKqymsa2uxn/cfX1+qxT7bprR8dp1G9U2UmLd1eogkDuuutNbnKSk3UuP7pB7VcpbYh\nUBMdR030IWNdTrnOe+ATZaQkqKS6Qafd9aHG9k0L68XfEWrqvaqu96hXaqIkacXOUhVW1sk56T8r\n9mjNnjJtKaiSJD1x5XTFxphOm9BPp03ot8+2rjluhF5etlu/eHGlNuRVqlt8rKrqvFqyvUS/emmV\nHv3uNCUnxKm0ul5n3/uRquu92lxQpZ+cPPqgPuevo6ymQbfOz9YLS3YpLtb0x7kTlJmWqBnDMto8\nK/5yR4nyK/xv1nPG9tbnW4s1qk+qyms8WrmrVOdMGaAYEnLgoCmpqldlnUeDMpI7OpSD4p8fbVV8\nrOmymUNVVFmnmbe8p3qPTxMGpOvXZxymo0d07jK8BWvz5HVOp47vu899dR6v8svrdNpdH6qq3j+K\nOWWQv9QiM/DZJ0lTh7TvCUVMjOmIwT33uShLdb1HDR6n9G5xmr86V/PX5Op/Zo/Qz04do6KqOvXv\n3k3PL92ls/72kSSpvMaj566Zud/95VfUas2esuDtK48dpjMn9tM9723UmRP76YyJ/fSz51fo+aW7\ntHxnqab+aYEk6fUfHqtPNxdpa1GVfnHq2GblHo99sk2SdOpdHyohNkb1Xt8++z3psD56+IqpYR+f\nA9XZRqLNOdfRMYRl6tSpbsmSJQd1n845PfPFTp09pb+Wbi/R/Qs3KTu3QknxMfr7pUfq8HZOpOs9\nPhVX1atv9yQVV9WrsLJO76zN07qcct1+wWQlxn314iqtrldtg081DV698uVuXTdnlGJjTO+uy9N/\nPbFEjf+9V8wcosc/3d5sP71SElRUVa9zDx+g2y+YvN9R4yc/3abf/meNEuJi9P5PZyslIU7vrMvT\nz19YoXH903XZUUP0wtJdWrK9RMMzU7S5oEq//8Y4XXH00OC2N+VXanhmSrsnlc457Smr1e1vrdfQ\nzBTllddqY36lbjxrnCYM6N7mYz1en1bsKtXtb2/QJ5uLdMKYrGb14GP7pukv501ScVW97l+4WSP7\npOqGk0ervNajfy/eoX98sCW4bkZKgoqr6tUtPlY1gTcDSfruMUN17fEj1Ds9KeTntDGvQn97b5OG\nZ6Xo+jmjIjqqv7XQfzLV3nWDwMH0n+W79b+vrFZFrUeStOy3JysjJUGVdR7NW5mj844ceMid0NY2\neDX2t/MlSXExJif/t4xNbfjT6UroJCN7TS3Mztet87OVHRjtXf+n05p9/j31+XbdPC9blXWe4LLk\nhFit/v2pwf/n7Nxyfb6lWJfPHNLu76H3v79Jf5m/XstvPFk9khNUXtugE297Xw1ep8EZyVq1u0xp\niXF647pZGtzLf0LX4PXp2FvfU155nYZnpWhLQZXmTumv286frPjYlv+Pquo8uujBz7Q+r0LPXn2U\nnl+6Sz85eXSzkwTJnzvkltXqnPs/VnFV/T7b+fFJo3X9Sf4e2fNX5+qafy2VJJ01qZ9eX5nTbN3+\n3ZN01Ihe+s/yPXr9h8e2+8w0y1wAACAASURBVEh+a+5esFF3Ltigzf93RtR8G2xmS51zLZ5JkEQf\noC93lOjyR75QRZ0neFWj1v5AnXN6fWWO/r14h+64YIr6pPuT4zdW7tF72fk6dXxf9UiO1xGDe2pN\nTrlufdP/pnHmxH56Lzu/WTIWH2s6fnSWLpg6SLExpqseb34szj9yoIqr6vVudr7SkuKCHyaN/u+b\nE+V1TqeM66M+6Uny+VxYHyrbCqtU7/VpdJ+v6qHfy87TD57+UtX1XmWkJOj6OaN0/Ogszb7tfUnS\nDSePVmys6fFPtvkvrzquj66bM0oDe3bTrpIa9U5LVO/0JJVVN4Q1KcI5pwc+2KwHP9yi0uqGZolr\nXIwpJsbUNz1J8380S8kJrX/pcs+7G3XHOxuCsf5wzijdt3CTHvxwi04d30dvrclTWU2DJP/xd07y\n7PUhdfv5k7W9qEqbC6p09MheWrGzVHUen3aV1Gjp9hJJ/mT85nMn6s3VuTp6RC/NHtM7+PhN+ZW6\n972NWrm7TFsLq3TsyEwt2VYSfD5nTeqnP86doJ4h1LmF67UVe/TDZ76UJD151XTNGpXV7vsAIu29\n7Dxd+di+nw3DM1O0JXCSePdFUzptmVlr5q/O0TX/Wha8febEfrri6KHq1z1J1z61VKt3l+vN62cd\ntCSoPdQ2ePWrl1bp5S93N1t++oS+uv6kUdpTWqMb/7NGu0pqNL5/unLLavXTU8eopLpep47vqxEH\n6ZLcjYno6z88VhMGdNeCtf7Bq0Zzp/TXn86ZoLSkfT/Xiirr1C0hVt9/apkWri/QNyb31+3nT5bX\n59Qtofko7G1vrde9Czfp75ce0eI3xXu7ed46/ePDLTphTJamDOqpmSN66ba31mvFrlJ968iBio8x\nPf7pdh3WL12vfP9oJcTG6K01uZo4sIeyc8pVWefRaRP6qrzGozPuWaQGr0/v/Ph4ZaUl7nffX9et\n87P18KIt2vjnMyK+r1CRREdIZZ1H//X4Yn22pViJcTE694gByiuv069OH6sBPbuptsGnRz/eqkc/\n3hY8Ux7VO1VXHD1UN89bF/zqKRTHjOylbx0xUO+vL9CrK/Y0u++MiX01b1Vus2XXzh6ha2eP0I6i\nauWW1WpDfoW6d4vXJTOGfP0n3oK88lqVVjdoVO/UYFK+dHuJ7nxngz7aVNjmY82kfulJ2lNWq0kD\nu6ve49N1c0bp9Al9W/2w211ao/9+colW7y4PLjt5XB/96KRRijFTSkKc9pTV6KIHP9PEAd11/yVH\nNPtqt87j1d0LNuq97HxtzK9Uz+QEXTRtkK4/adQ+owE5ZTV6dfke9UxO0HGjs/Tm6hzd9NpaSdKP\nThqlaUMz2uxaUtvg1SebC3XV4199MxAXY7r1W5O0q6RG2bnlmr8mV3v/KU4d0lN3X3y4Ln7wM+0o\nrlZqYpy+N2u4vn/CCMW1MmLR1NLtxapr8GlQRvI+X2v7fE6FlXXKK6/Ttx/+TMMzU7SnrFb1Hp/m\njO2t48dkae6UAfvdB9DIOaddJTUa2LNbhySpc+/9SCt2lemJK6frmJGZ+sNra/b59k2SvjdrmH5z\n5rh23//63Aq9sny3xvVL17EjMyNywttUWXWDPt1SpBueW66k+Fh98PMT9PGmQp10WJ/gCN6m/Aqd\ndMeH6pWSoCX/e1KnOHmoqfdqyh/eVl2gX/CvTh+rjfmVijHpuSW7mq07tFey3v7x8YqPtQ55bqt3\nl+msv30UTG5vedOfAF42c4ick35/9viQtvP9p5bpnXV5GpGVqnU55RrdJ1Vj+6Yrr7xWfzpngs59\n4BPNGpWp+y85MqTteX1OS7eX6PDBPYKfZwUVdfrj62ub5Q8f/eIEDezZdsnT+twKnXHPIp18WB/d\nf8kREf8m56bX1uiFpbu06venRnQ/4SCJjqCymgZd/sjnWrGrTHExJo/PaWTvVJkU7FM5Z2xvnTGx\nn8yknzy3QpL/a/8fnzRKx4zMVEWtRxvyKrRgXZ5mjcrSqN6pmjo0QwUVdYqLNSXFxyolITb4JpGd\nW64vd5RqXU65Dh/cQ988fKDqPT69uTpHH6wv0DWzRzQbKe5IVXUe/fKlVTJJf/rmBKUnxWvp9hJt\nyKvQHe9skHNOJ47trS0F/hHuNXvKg19FpiXGqVtCrC6aPlgxJg3PStX4/un6xweb9dySXYox6Zen\nj9UFUweppsGrfi30Af3tK6v15Gf+D9LTJ/TVhAHd9fKXu5WSEKsVu/z1ZWdP7q8/zB0f8uQJ55zy\nK+rUOy0xrDfupduLtT63UtOG9tTl//xCOWW1kqSUhFidPaW/rj1+pAqr6hQfE6OVu0t1wdRBio+N\n0c7iai1Yl6dHP96mHcXVuu7EkfrJKWOaxVNQUacrH1+sBo/TFUcPVXltg+54e0Owxq1HcrzuvGCK\nThjbW4WVdbr8kS+0Nsd/AhIfa5p33axgfXujmcN76aErpiq3rEb55XWaMbxX8MPZ4/XprgUb9dyS\nnbpuzigt31mqMyf20/RhGYqLtWZfueLQ9cnmQi3fWarjRmXpjVU5euD9zbrxrHEa0TtVy3eUysnp\n6uOGt/lNUHvIKavRzJvf0y9OG6trZ48ILm8IvP7jY2P017eydd/CzcpMTdBnv5rT7ES0wetTrNkB\nJQjV9R7d+mZ2s4Q9Ky1RD10+VVOaTM5u5PM53fb2eo3tl67x/dM1PDOl2fvI7tIaebw+DenVdmnV\nOfd9rOU7SyVJ/33c8BZ7HDvndPa9H2vV7jIN6ZWs+dcfp6T4mKieOL1sR4nOvf8TXTx9kP4wd0Iw\nCazzeHXmPR9pU+Bz9XffGKezJ/cPzvnpCKXV9Zryh3c0d0p/pSbG6anPd2jKoB565fvHhLWdf3+x\nQ78MvPeePK6P3lmbt886b//4uHb5XP9oY6H+8eFm3X7+5JDLCx/6cIv+PG+dZgzL0PVzRjX7LGhv\nv3pppRasy9fi35wUke0fCJLog6Cm3iuvc/rXZ9t1y5vZweUzhmXo6e8dFXzBLdlWrIS4GI3snRrx\nD5ZoV+/xKTbGmv0x+nxO2bkVmrcqR1uLqrQupzw4+bGpnsnxevS701v8kGrK63P6bEuRrv/3lyqs\n/KpGLCUhVj85ZYwumDqwxa/aIm1DXoUeWbRVF88YrNF9QnstlNU06AdPL9OijYXKSktUg9enHt3i\nVVbToJLqBsXHmtKS4oO1cJMGdtfs0Vn6cGOhdpXUqKS6Xicf1kcrd5WqqKpe1580SmlJ8RqZlaqZ\nI/wtmnaVVMs5BSfpjOydGvzQuvKYYbrxG+N038JN+scHm1W+V6mQJCXExSgjOUF3XjhFM4ZltOuo\nRU29V7tLq/fps9rg9elPr69Verd4De2VomNHZapbQqz/24jSGj20aIvmrcrRmL5puuXcSS1ONssp\nq9HDi7bqwmmD1L1bfLMTpOp6jxICH+RNE6+HF21RXnltREY1o1ltg1fzV+fK43P65Ysr9yltkqQY\nkxoXf+fooSGPyDXlnNMHGwo0ZVCPNk9wq+s9GnfjW5KkF6+dqSPbmEDW9Ov2GcMydNnMIapr8OmW\n+dkqra7XtbNH6icnj1Ztg1df7ijVUcMzWjxRXrytWH9+Y51uOGW0Xl+Ro2eX7FS/7kn6wYkjlZ4U\nr1vnZ2tXSY0umjZIX2wrls/n9M3DB+qIIT102SNfNNvWJTMG68/fnCjJX9N9/b+XKyEuRj8/dYwu\nmzkkeEL6xdZijchKUUZKgl5fmRMswZoztrfuufjwVtuU5VfUavqf35XkHzBYsatUGSkJ+selRyot\nKT5YOlBT79Ubq3K0o7ha/33ccN06P1ufbi7SxdMH64Jpgw5aR6onP9uu376yusVR0toGr0qrG9Qr\nNaHV+uGDyTmnI/74jkqqG4LLLpo2SLd8a1JY29laWKUTbntfCXExWv/H0/Tqij2KMdP8Nbl6Y2WO\nbjp7vK44emg7Rx8655zufW+Tbg+UPTZ6+X+Obvc5YT9+drmWbC/Wop+f2K7b/TpIog8i55zmrcrV\nYf3SNDwrNeyaYzTn8zmV1jQoLta0Ma9S//psu44fnaW5U8Kra3TOadmOEs1fnau5Uwbsd7JhtKqq\n8+jhRVv1zBc7NKBnNyXExujTLUVKS4rT7edP1rShGfp4c6EyUhJ01LBewddeZZ1Hv35plT7ZXKji\nqnr975njdOWxw1rdj9fn9NTn23X/ws3qkRyvUX3S9OaqHP3itLG6+c11Gtk7VT89ZYyGZabonXV5\nGtgzWY99vFX9enTT+9n5qqr36qTDeuv6OaM1cWB3bSusCvYiD7ddUnW9R0u3l+jhRVv1wYYCnX/k\nQPXrnqSS6gZ9vLlQpdUNzSbRDOjRTcVV9eqZHK+8irrgNxuJcTHqmZyg608apXOmDJDP+Xuk/u29\nTcFZ6o3OmtRPHq/TpoLK4EmEJH3z8AG66thh+nJnqX77ympJ0vRhGTp+dJZG90lTj+R4DctM2WfC\nT0fz+pxKq+uVkZJwQF97O+f07OKdWrytRIWVdfpgg3/ibXys6flrjtaGvAoVVtZp9uje+sPra5Sa\nGKdfnDZWDy/aqpeX79ZL1x4d0t9ceW2D3lmTp3ez85SdUxGsZb5i5hD95sxxijFpT2mtnlm8Q9cc\nP0I/eXa53s3ODz4++4+ntTmr3zmnG55foZeW7W51HUlKTYxTZZ1Hj313WrO5C5J//sJZf1sUbMUl\nSUcM7qG7Lzo8eIK2vahKv391jRauL1DvtEQlJ8RqW1H1PvuZNSpTizYW6u0fH6ehvVJ09C3vNjvZ\nP3V8H91y7iR9vrVI1/xrmfp3T9K4/t21YJ1/pDLUC2A55/SDp7/UG6uaTx4b0KOb5hzWW0N7pejF\nZbu0Zo//26nD+qUrO7dcGcn+yedj+6bp+WtmHpQBhxueW6GF6/O1tJOUnzzx6Tbd+J81um7OKJXX\nNOiSGYM16gBGjFfvLlNsjEV17fr76/OVnVsRHCicMCBd5TUefe+44Tp7Uv9mc5oac59PNhdqaK8U\n9e+x/ytGStKF//hUdR5f2KP5kUQSDRxiGv9uD+RDpsHrC3sUp7CyTt964BNtL6pWWlKcPvzZCa3W\nfOaV1+ov89frxWW7FBtjGtSzW7ME4sSxvfWHueM1sGeycspq9OCHW5SdU6GTx/XRiN6pOnpEr2B8\nFbUNuvyfX+jLHaUt7mtcv3R1S4jVJTMGa1dJjYoq6/TU5zs0uFeykhNi1TM5QT88cZRSE+O0eneZ\nfv7iyha3c8bEvjp+dJZW7S7Tvz7bEdIxGdCjmzJSErRqd9k+9w3LTNHRI3rp12ccFhwhzM4tV3ZO\nhc6c1K/Z8fd4fSHVuO9tc0GlNuZVavaYrGDi6PM5vb8hXx9vKtK0oRk6dlSmUhJi9euXV/tPvHp0\n0/wfzVJaUrwq6zz6/lPLVOfx6kcnjdbUIT2DcSxcn6/5q3J1zewRGpaZonmrcvQ/T301eW32mCz9\n5ozD1C0hts2ayp3F1Zp738fKSEnQtKE9tSXQ9rKli1M0neDbkunDMrS7pEa7S2taPh5hzubPK6/V\n2j3levnL3eqTnqgfnzw6OKLdqE96ou668HAdOaSn8spr9ebqHN35zkbFxZj+ftmR+vGzyzVpYHc9\ndPnUff4WnXPalF+pgT2TFRMjTb7pbdU2+DRrVKYuPWqIjh2ZqdoGr44MtCJLS4xTRZ1Hd180RaeO\n76tb52fr0Y+3afaYLG0trNL2vZLwR78zTSeMbZ7gt6W63qOnP9+hY0Zm6u01ebpzQcvH+ojBPbRs\nR6l6pSTozetnadXuMl395FKdf+TAsEdYw1Xv8WnWX97TEYN76oFLQ6v/jQZVdR4lNym5PNRV13v0\ng6e/1HtNTmAl6bTxfTVpUHfll9fp1RV7NLZvmj7ZXKQeyfH67Fdz2jzB/WRzoRaszdc/P96qK2YO\n0U1zJ0T6aYSMJBrA1+bzOX25s0Td4uM0rv/+R0u2Flbp5y+s0JLtJbpo2iAt31mmdTnl+33c8MwU\nPfKdaUpOiNXZ936kgoo6XTJjiOZO6a+MlASt2VOuk8f1UXlNQ4s1fZvyK9QnPWmfUTPnnOavztXG\n/ErdtWBDsNzg6e/NaNZHt6SqXve8t1FnTeqvgT39F1RITohTUWWdlmwv0frcCg3KSNbpE/oqJTFO\ntQ1ePfX5Do3vn67aBq9e/nK3thVVa8XOUg3plazrThyleatygiOmRwzuobMm9dfHmwqVEBejd9fl\na8rgHuqZHK+31uTp1PF9lB5Icg8f3EPLtpdq1e4yHdYvTZsLqgKdgKS7390or88pMS5GF08frHU5\n5c0uedyose1io28dMVB9uydqYXZBsC5e8k9kvfSoIRqWmaK5930syV832ziSPyijm968/jgt216i\nqUN7hlyOdu97G3Xb2xuCJR6zRmXqyatmNFunqLJOM/7vXXl8TseM7KVbzp2kPaU1Gtc/XWlJ8frR\nv7/UK8v3KCEuRvWe5r1sTx7XRyeO7a2Lpw8OKZ625FfUamdxtRJiY5UQF6MLH/xUZTUNOqxvevBY\n9UpJ0M3nTtQpLfQsbsvS7cUqrmrQyeP6NFt+xT+/0AcbCnTU8AxdMmOIzprUT2bmHz1+5ku9EWg9\ndteFUzSqT6peXb5H354xeL8106Eora7XupwKrc8t19h+6ToqcHKztbBKPZPjg98a3fDcCr2zNldL\nf3vyfk/Af/vKavVOS9QP54wKOY75q3P19tpcZedUaG1Oue779hE6c9L+u1Cg49Q2eHXTa2tUWFmv\n0up6DejRTa8s39Pq+ndd6J+Ts2Btns6a3K/ZvJnGEp5G9377cJ01qX9E4w8HSTSADuHzOVXUedS9\nmz+hdc5pR3G17l6wUWtzyjVjWIbOnNRfkwd114bcSj23ZKee/Gy7zKTUBP/I3KVHDdafzpnYrnHl\nl9cqOTFOZTUNGhDi14zhen3lHv3kuRXBpG9Ir2QdPSJTz3zx1Uh3t/hYTR+WoVW7y1Re0xCsL46P\nNTV4235vzkxN1Dcm99Onm4uCfXQl6bKjhuinp47RM1/s0J3vbFDv9ERdNG2w/vu44frzvHV69ONt\nwXV/esponT91kOat+qrjTKNLjxqsdTkVwRaND10+dZ8EMBQ19V7dt3CTZgzP0OJtJfrbext16Ywh\nunCa/9LEK3aW6q9vr9fO4mq9/sNZGtN336/CG7w+rd5dppG9U/XSst06fWJfPf35Do3pk6bTJ0Yu\n2dpTWqPZf31f9V6fYky6/5Ijder4Pu064lhR26BthdWaOHDfcpedxdX6zSurlZIQqzsumLJP67OD\n5YMNBbrin1/ovCMHakL/dA3smayjR/bSq8v3aMKA7urfo5t++eJKvd1kQtx1c0YpPSlOiXExGtwr\nRbllNbpg6qB9jt33nljSbCLdgdQUo+M55/SNez/S6t3leveG45WcEKvHPtmm848cpIse/FTThmao\nqKpeXwRO9KcPzVBFnUcXTh2oxdtK9NaaXD1w6ZHaXlSlK48ZFlVlsCTRADqNTzcXacG6POWW1eqy\nmUM0Y1jLk7s6gz2lNXrko60anpWibx0x0N+KbEOB8sprdc6UAXJywREZ55zqvf6LJSTFx6qitkGf\nbinWoJ7dNKZvmhZvK9HM4b30xKfbNCwzRaeM76vUxDg1eH16dvFOpSXFKT0pXseOymx1tNDj9emZ\nxTuVW1ajvulJumj64OC6pdX1mnXrQlXUeXTb+ZN13pEDJflHnBLjYtrl/6CyzqOrHlu8z4h5SkKs\nHvnOtOBIaDRZHejdfvqEvgdUdnOoOOPuRc2+uThmZC99vKlon/XOmdJfe0pr9cW2fb8V+faMwfrz\nOROCr6VHP96qm15bq+GZKbrxG+NUXuvRqeP70N2nk6pt8GpncfU+NeG/+8/qYPea/t397Wz3dvzo\nLD1+5fSDEme4SKIBAPtVUFGn2BhTRoR7HG/Kr9DPX1ipFbvKNLZvmp68akbE94mvZ2F2vv73ldU6\n6bDewYTo1PF9ZDL17Z6kU8b30aSBPZSaGBeYyF2q5IRY5ZTV6JkvdmpXSY3W5ZTr6uOG6/jRWcG2\nnZKCFyvBoane49NFD36q0poGvfaDY/WDp/0XmLnrwilatbtMj3y0VWdO6qf7vn1ER4faIpJoAADw\ntTnndNNra7V8Z6ke++60sPrr//yFlXp+afMLpjT91gOHrnqPTz7nlBQfq035Fbp1/nrddeEUJcXH\n6q4FG3T6hH4hzbXpCCTRAACgQznndMub2dpWVKWbzp4gr3MRm5MAtJe2kuiufbUPAABwUJhZi1dW\nBDqrrjtLAgAAADhAJNEAAABAmEiiAQAAgDCRRAMAAABhIokGAAAAwkQSDQAAAIQpYkm0mf3TzPLN\nbHUr95uZ3WNmm8xspZlF56VqAAAAgL1EciT6MUmntXH/6ZJGBX6ulvRABGMBAAAA2k3Ekmjn3IeS\nittYZa6kJ5zfZ5J6mFm/SMUDAAAAtJeOrIkeIGlnk9u7Asv2YWZXm9kSM1tSUFBwUIIDAAAAWtMp\nJhY65x50zk11zk3Nysrq6HAAAADQxXVkEr1b0qAmtwcGlgEAAABRrSOT6FclXR7o0nGUpDLnXE4H\nxgMAAACExJxzkdmw2TOSZkvKlJQn6XeS4iXJOfd3MzNJ98rfwaNa0nedc0tC2G6BpO2Suksqa2W1\n1u5rafney/a+nSmpcH9xtYO2nk97PnZ/60bquO69rDMc13AeH8p64R7bA13WGY5tZ3jNclw5rgfy\nWI5rZB77dd5j+ez6eut19c+uIc65lmuJnXOd8kfSg+He19LyvZe1cHtJRz+f9nzs/taN1HHde1ln\nOK7hPD6U9cI9tge6rDMc287wmuW4clw5rp3nuIZ7/EI9rnsv6wzHNZzH89n19X46xcTCVrx2APe1\ntHzvZW1tN5K+zn7Deez+1o3UcQ1l35HwdfcZ6uNDWS/cYxvNx/Xr7rczvGY5ruHfx3HluEbqsV/n\nPZbPrq+3Hp9drYhYOcehwsyWOOemdnQchxqOa+RwbCOD4xoZHNfI4LhGBsc1cjrjse3MI9EHy4Md\nHcAhiuMaORzbyOC4RgbHNTI4rpHBcY2cTndsGYkGAAAAwsRINAAAABAmkmgAAAAgTCTRAAAAQJhI\nor8GM5tlZn83s4fN7JOOjudQYWYxZvZnM/ubmV3R0fEcKsxstpktCrxmZ3d0PIcaM0sxsyVmdlZH\nx3KoMLPDAq/XF8zs2o6O51BhZueY2UNm9qyZndLR8RwqzGy4mT1iZi90dCydXeD99PHA6/SSjo6n\nNV02iTazf5pZvpmt3mv5aWa23sw2mdkv29qGc26Rc+4aSa9LejyS8XYW7XFcJc2VNFBSg6RdkYq1\nM2mn4+okVUpKEsc1qJ2OrST9QtJzkYmy82mn99h1gffYCyQdE8l4O4t2Oq6vOOe+J+kaSRdGMt7O\nop2O6xbn3FWRjbTzCvMYnyvphcDr9OyDHmyIumx3DjM7Tv6E4gnn3ITAslhJGySdLH+SsVjSxZJi\nJd281yaudM7lBx73nKSrnHMVByn8qNUexzXwU+Kc+4eZveCcO+9gxR+t2um4FjrnfGbWR9Idzrmo\nPbs/mNrp2E6W1Ev+E5RC59zrByf66NVe77FmdrakayU96Zx7+mDFH63a+bPrdklPOeeWHaTwo1Y7\nH1c+t1oQ5jGeK+lN59xyM3vaOfftDgq7TXEdHUBHcc59aGZD91o8XdIm59wWSTKzf0ua65y7WVKL\nX9Ga2WBJZSTQfu1xXM1sl6T6wE1v5KLtPNrr9RpQIikxEnF2Ru30mp0tKUXSOEk1ZjbPOeeLZNzR\nrr1es865VyW9amZvSOrySXQ7vV5N0i3yJyldPoGW2v09Fi0I5xjLn1APlLRcUVw10WWT6FYMkLSz\nye1dkmbs5zFXSXo0YhH9f3v3H6tlXcZx/P1RQ0vw2JwyTBstMHLTkqBJaqPNqOXKXzVorqnoylpo\nZLV+/KEuWpZaCcx006bLyVAhRuoEsxjkL46giIL1R/SHpqVkJgK28NMf95d8OHueAzecm8dzzue1\nsXM/3/vXdV/P2dl1Lr7f5wwNdfO6GJgn6TRgZZOBDXK18irpHOBTwOHA/GZDG/Rq5db2DwAkXUDp\n+Dca3eBV93t2KtV/6x4M3NdoZINb3Z+xs4DTgR5J42zf2GRwg1jd79cjgB8BJ0n6Xim2o3+dcjwX\nmC/pDLr358F3K0X0PrJ9RbdjGGpsb6X65SQGkO3FVL+gRENs39rtGIYS2yuAFV0OY8ixPZeqSIkB\nZHsz1Tzz2Ee2Xwcu7HYcu/O2bZF3yfPAsS2vjyljsW+S12Ykr81JbpuRvDYjeW1G8tq8QZ3jFNG7\n6gXGS3qfpBHADGBpl2MaCpLXZiSvzUlum5G8NiN5bUby2rxBneNhW0RLWgA8AnxA0nOSLrL9X+Dr\nwDJgI3Cn7We6Gedgk7w2I3ltTnLbjOS1GclrM5LX5g3FHA/bj7iLiIiIiNhbw7YTHRERERGxt1JE\nR0RERETUlCI6IiIiIqKmFNERERERETWliI6IiIiIqClFdERERERETSmiI2LYkrRlP9zjc5K+2/R9\n+txzqqSP7cV5J0m6pWxfIGn+wEdXn6Sxkp7ezTFHSrp/f8UUEZEiOiJiH0k6sNM+20ttX93APQ/q\nZ/dUoHYRDXwfmLtXAXWZ7ZeAFySd0u1YImJ4SBEdEQFI+rakXklPSbqqZXyJpDWSnpH05ZbxLZKu\nk7QOmCLpr5KukrRW0npJE8px/+/oSrpV0lxJD0v6i6TPl/EDJN0g6VlJD0i6b+e+PjGukPQLSY8D\nl0n6rKTHJD0h6XeSRksaC1wCzJb0pKTTSpd2UXm+3naFpqRRwIm217XZN1bS70tuHpT03jL+fkmP\nlued066zL+lQSfdKWifpaUnTy/jkkod1klZLGlXus6rkcG27brqkAyVd0/JefaVl9xLgvLZvcETE\nAOuvkxERMSxImgaMrJpSqgAAA7ZJREFUBz4KCFgq6eO2VwIzbf9T0juBXkmLbG8GDgUes315uQbA\ny7YnSvoa8C3g4ja3GwOcCkwAlgJ3A+cAY4HjgaOo/vztrzqEO8L2pHLPdwMn27aki4Hv2L5c0o3A\nFtvXluPuAH5u+4+lAF4GfLDPdScBnaZMzANus32bpJlU3eqzgOuB620vkHRJh3M/DfzN9hkllh5J\nI4CFwHTbvZIOA7YB/wA+aXu7pPHAghJXq4uAV21PlnQw8JCk5bY3AY8DczrEERExoFJER0TAtPLv\nifJ6JFVRvRK4VNLZZfzYMr4Z2AEs6nOdxeXrGqrCuJ0ltt8ENkgaXcZOBe4q4y9K+kM/sS5s2T4G\nWChpDDAC2NThnNOB40uhD3CYpJG2WzvHY4CXOpw/peV5fg38tGX8rLJ9B3Btm3PXA9dJ+glwj+1V\nkk4AXrDdC2D731B1rYH5kj5Mld/j2lxvGnBiS6e+h+o92URVhB/d4RkiIgZUiuiIiKr7/GPbN+0y\nKE2lKkCn2N4qaQVwSNm93faOPtd5o3zdQeefr2+0bKvDMf15vWV7HvAz20tLrFd2OOcAqo719n6u\nu423nm3A2P6zpInAZ4A5kh4EftPh8NnA34EPUcXcLl4Bs2wva7PvEKrniIhoXOZER0RU0xtmShoJ\nIOk9ko6i6nK+UgroCcDJDd3/IeDcMjd6NNXCwD3RAzxfts9vGX8NGNXyejkwa+eL0untayMwrsN9\nHgZmlO3zgFVl+1Hg3LI9o+9J5V5HA1tt3w5cA0wE/gSMkTS5HDOqLJTsoepQvwl8CWi3YHMZ8FVJ\n7yjnHlc62FB1rvv9FI+IiIGSIjoihj3by6mmIzwiaT3VPOVRwP3AQZI2AldTFY1NWAQ8B2wAbgfW\nAq/uwXlXAndJWgO83DL+W+DsnQsLgUuBSWUh3gaqhYe7sP0s0FMWGPY1C7hQ0lNUxe1lZfwbwDfL\n+LgOMZ8ArJb0JHAFMMf2f4DpwDxVCzMfoOoi3wCcX8YmsGvXfaebqfK0VtXH3t3EW13/TwD3tjkn\nImLAyXa3Y4iIGPZ2zlGWdASwGjjF9ov7OYbZwGu2b97D498FbCsLG2cAX7R9ZqNB9h/PSuBM2690\nK4aIGD4yJzoi4u3hHkmHUy0Q/OH+LqCLXwJfqHH8R6gWAgr4FzCzkaj2gKQjqeaHp4COiP0ineiI\niIiIiJoyJzoiIiIioqYU0RERERERNaWIjoiIiIioKUV0RERERERNKaIjIiIiImpKER0RERERUdP/\nAEhD0zi7K5GtAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEPeE7It2GVs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = SGD(lr=0.005, momentum=0.9, nesterov=True)\n",
        "model.compile(\n",
        "    optimizer=opt,\n",
        "    loss=\"categorical_crossentropy\", \n",
        "    # loss_weights=loss_weights, \n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sslWWnmdJwI9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_suffix = 'res20'\n",
        "# Prepare model saving directory.\n",
        "save_dir = os.path.join(os.getcwd(), 'gdrive', 'My Drive', 'eip4_assignment5_modelweights', '29dec_earlystart')\n",
        "model_name = 'eip4a5_model_%s.{epoch:03d}.h5' % model_suffix\n",
        "\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)\n",
        "\n",
        "# Prepare callbacks for model saving and for learning rate adjustment.\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_acc',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(monitor='acc',\n",
        "                               mode='auto',\n",
        "                               factor=np.sqrt(0.1),\n",
        "                               cooldown=1,\n",
        "                               patience=3,\n",
        "                               min_delta=0.001,\n",
        "                               min_lr=0.5e-6,\n",
        "                               verbose=1)\n",
        "\n",
        "callbacks = [checkpoint, lr_reducer]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O4JuShTvY2t5",
        "colab": {}
      },
      "source": [
        "# Train the backbone model\n",
        "asdf\n",
        "model.fit_generator(train_genr,\n",
        "                    validation_data = valid_genr,\n",
        "                    use_multiprocessing=True,\n",
        "                    workers=6, \n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    callbacks=callbacks)\n",
        "\n",
        "# Best model saved at 29dec_earlystart/eip4a5_model_res20.046.h5 -  0.87097 on gender"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jckbgTuZN7L_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "model_gender = load_model(\"/content/gdrive/My Drive/eip4_assignment5_modelweights/29dec_earlystart/eip4a5_model_res20.046.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7M_n_CnOTuv",
        "colab_type": "code",
        "outputId": "8bf40574-d68e-4266-cb72-47bb85774593",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_gender.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_9\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_11 (InputLayer)           (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_203 (Conv2D)             (None, 222, 222, 16) 448         input_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_25 (MaxPooling2D) (None, 111, 111, 16) 0           conv2d_203[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_204 (Conv2D)             (None, 111, 111, 16) 2320        max_pooling2d_25[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_153 (BatchN (None, 111, 111, 16) 64          conv2d_204[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 111, 111, 16) 0           batch_normalization_153[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_205 (Conv2D)             (None, 111, 111, 16) 272         activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_154 (BatchN (None, 111, 111, 16) 64          conv2d_205[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 111, 111, 16) 0           batch_normalization_154[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_206 (Conv2D)             (None, 111, 111, 16) 2320        activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_155 (BatchN (None, 111, 111, 16) 64          conv2d_206[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_147 (Activation)     (None, 111, 111, 16) 0           batch_normalization_155[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_208 (Conv2D)             (None, 111, 111, 64) 1088        activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_207 (Conv2D)             (None, 111, 111, 64) 1088        activation_147[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_49 (Add)                    (None, 111, 111, 64) 0           conv2d_208[0][0]                 \n",
            "                                                                 conv2d_207[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_156 (BatchN (None, 111, 111, 64) 256         add_49[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_148 (Activation)     (None, 111, 111, 64) 0           batch_normalization_156[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_209 (Conv2D)             (None, 111, 111, 16) 1040        activation_148[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_157 (BatchN (None, 111, 111, 16) 64          conv2d_209[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_149 (Activation)     (None, 111, 111, 16) 0           batch_normalization_157[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_210 (Conv2D)             (None, 111, 111, 16) 2320        activation_149[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_158 (BatchN (None, 111, 111, 16) 64          conv2d_210[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_150 (Activation)     (None, 111, 111, 16) 0           batch_normalization_158[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_211 (Conv2D)             (None, 111, 111, 64) 1088        activation_150[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_50 (Add)                    (None, 111, 111, 64) 0           add_49[0][0]                     \n",
            "                                                                 conv2d_211[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_159 (BatchN (None, 111, 111, 64) 256         add_50[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_151 (Activation)     (None, 111, 111, 64) 0           batch_normalization_159[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_212 (Conv2D)             (None, 56, 56, 64)   4160        activation_151[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_160 (BatchN (None, 56, 56, 64)   256         conv2d_212[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_152 (Activation)     (None, 56, 56, 64)   0           batch_normalization_160[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_213 (Conv2D)             (None, 56, 56, 64)   36928       activation_152[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_161 (BatchN (None, 56, 56, 64)   256         conv2d_213[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_153 (Activation)     (None, 56, 56, 64)   0           batch_normalization_161[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_215 (Conv2D)             (None, 56, 56, 128)  8320        add_50[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_214 (Conv2D)             (None, 56, 56, 128)  8320        activation_153[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_51 (Add)                    (None, 56, 56, 128)  0           conv2d_215[0][0]                 \n",
            "                                                                 conv2d_214[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_162 (BatchN (None, 56, 56, 128)  512         add_51[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_154 (Activation)     (None, 56, 56, 128)  0           batch_normalization_162[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_216 (Conv2D)             (None, 56, 56, 64)   8256        activation_154[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_163 (BatchN (None, 56, 56, 64)   256         conv2d_216[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_155 (Activation)     (None, 56, 56, 64)   0           batch_normalization_163[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_217 (Conv2D)             (None, 56, 56, 64)   36928       activation_155[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_164 (BatchN (None, 56, 56, 64)   256         conv2d_217[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_156 (Activation)     (None, 56, 56, 64)   0           batch_normalization_164[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_218 (Conv2D)             (None, 56, 56, 128)  8320        activation_156[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_52 (Add)                    (None, 56, 56, 128)  0           add_51[0][0]                     \n",
            "                                                                 conv2d_218[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_165 (BatchN (None, 56, 56, 128)  512         add_52[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_157 (Activation)     (None, 56, 56, 128)  0           batch_normalization_165[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_219 (Conv2D)             (None, 28, 28, 128)  16512       activation_157[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_166 (BatchN (None, 28, 28, 128)  512         conv2d_219[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_158 (Activation)     (None, 28, 28, 128)  0           batch_normalization_166[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_220 (Conv2D)             (None, 28, 28, 128)  147584      activation_158[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_167 (BatchN (None, 28, 28, 128)  512         conv2d_220[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_159 (Activation)     (None, 28, 28, 128)  0           batch_normalization_167[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_222 (Conv2D)             (None, 28, 28, 256)  33024       add_52[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_221 (Conv2D)             (None, 28, 28, 256)  33024       activation_159[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_53 (Add)                    (None, 28, 28, 256)  0           conv2d_222[0][0]                 \n",
            "                                                                 conv2d_221[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_168 (BatchN (None, 28, 28, 256)  1024        add_53[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_160 (Activation)     (None, 28, 28, 256)  0           batch_normalization_168[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_223 (Conv2D)             (None, 28, 28, 128)  32896       activation_160[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_169 (BatchN (None, 28, 28, 128)  512         conv2d_223[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_161 (Activation)     (None, 28, 28, 128)  0           batch_normalization_169[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_224 (Conv2D)             (None, 28, 28, 128)  147584      activation_161[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_170 (BatchN (None, 28, 28, 128)  512         conv2d_224[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_162 (Activation)     (None, 28, 28, 128)  0           batch_normalization_170[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_225 (Conv2D)             (None, 28, 28, 256)  33024       activation_162[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_54 (Add)                    (None, 28, 28, 256)  0           add_53[0][0]                     \n",
            "                                                                 conv2d_225[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_226 (Conv2D)             (None, 28, 28, 128)  32896       add_54[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_27 (Dropout)            (None, 28, 28, 128)  0           conv2d_226[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_26 (MaxPooling2D) (None, 14, 14, 128)  0           dropout_27[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_1 (SeparableCo (None, 12, 12, 160)  21792       max_pooling2d_26[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_2 (SeparableCo (None, 10, 10, 192)  32352       separable_conv2d_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_227 (Conv2D)             (None, 8, 8, 208)    359632      separable_conv2d_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_171 (BatchN (None, 8, 8, 208)    832         conv2d_227[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_28 (Dropout)            (None, 8, 8, 208)    0           batch_normalization_171[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_228 (Conv2D)             (None, 6, 6, 224)    419552      dropout_28[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_172 (BatchN (None, 6, 6, 224)    896         conv2d_228[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_29 (Dropout)            (None, 6, 6, 224)    0           batch_normalization_172[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_229 (Conv2D)             (None, 4, 4, 240)    484080      dropout_29[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_173 (BatchN (None, 4, 4, 240)    960         conv2d_229[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_9 (Glo (None, 240)          0           batch_normalization_173[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "gender_output (Dense)           (None, 2)            482         global_average_pooling2d_9[0][0] \n",
            "==================================================================================================\n",
            "Total params: 1,926,290\n",
            "Trainable params: 1,921,970\n",
            "Non-trainable params: 4,320\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KfpV70G2orD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### USE BACKBONE TRAINED ABOVE FOR OTHER OUTPUTS' ###\n",
        "backbone = model_gender.layers[-16].output\n",
        "model_bb = Model(\n",
        "    inputs=model_gender.layers[0].output, \n",
        "    outputs=backbone)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0C4UrXmnPhKx",
        "colab_type": "code",
        "outputId": "1508afcf-0517-42d1-f480-2683e5e88971",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# CREATE TWO DIFFERENT TOWERS - ONE TOWER STARTS DEEPER IN THE NETWORK, THE OTHER (lowRF version) STARTS AFTER WE'RE 4 LAYERS INTO THE BACKBONE MODEL\n",
        "for layer in model_bb.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "# Tower that starts in the early layers\n",
        "def build_tower_lowRF(in_layer):\n",
        "    x = MaxPool2D(pool_size=(2,2))(in_layer)\n",
        "    num_res_blocks=1\n",
        "    num_filters = 16\n",
        "    depth=6*num_res_blocks+2\n",
        "\n",
        "    # Instantiate the stack of residual units\n",
        "    for stack in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            strides = 1\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                strides = 2  # downsample\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters,\n",
        "                             strides=strides)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters,\n",
        "                             activation=None)\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                # linear projection residual shortcut connection to match\n",
        "                # changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = keras.layers.add([x, y])\n",
        "            x = Activation('relu')(x)\n",
        "        num_filters *= 2\n",
        "      \n",
        "    x = MaxPool2D(pool_size=(2,2))(x)\n",
        "    x = Conv2D(filters=128, kernel_size=3, activation='relu')(x)\n",
        "    y = GlobalAveragePooling2D()(x)\n",
        "\n",
        "    return y\n",
        "\n",
        "# Tower that connects to the later layers\n",
        "def build_tower(in_layer):\n",
        "    x = Conv2D(128,\n",
        "           kernel_size=1)(in_layer) # output of 14x14\n",
        "                                        #  28x28\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    x = MaxPool2D(pool_size=(2,2))(x)  # output of 7x7\n",
        "                                      #  14x14\n",
        "\n",
        "    x = SeparableConv2D(filters = 160, kernel_size=3, activation = 'relu')(x) #12x12\n",
        "    x = Dropout(0.2)(x)\n",
        "    \n",
        "    x = SeparableConv2D(filters = 192, kernel_size=3, activation = 'relu')(x) #10x10\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    x = Conv2D(208,\n",
        "              kernel_size=(3,3), activation='relu')(x)   # output of 8x8\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    x = Conv2D(224,\n",
        "              kernel_size=(3,3), activation='relu')(x)   # output of 6x6\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    x = Conv2D(240,\n",
        "              kernel_size=(3,3), activation='relu')(x)   # output of 4x4\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    y = GlobalAveragePooling2D()(x)\n",
        "\n",
        "    return y\n",
        "\n",
        "\n",
        "def build_head(name, in_layer):\n",
        "    return Dense(\n",
        "        num_units[name], activation=\"softmax\", name=f\"{name}_output\"\n",
        "    )(in_layer)\n",
        "    \n",
        "\n",
        "x = model_bb.layers[-1].output\n",
        "x_lowRF = model_bb.layers[5].output\n",
        "\n",
        "# Following outputs will use the lowRF tower\n",
        "image_quality = build_head(\"image_quality\", build_tower_lowRF(x_lowRF))\n",
        "age = build_head(\"age\", build_tower_lowRF(x_lowRF))\n",
        "bag = build_head(\"bag\", build_tower_lowRF(x_lowRF))\n",
        "footwear = build_head(\"footwear\", build_tower_lowRF(x_lowRF))\n",
        "emotion = build_head(\"emotion\", build_tower_lowRF(x_lowRF))\n",
        "\n",
        "# the following outputs use the normal Tower\n",
        "gender = build_head(\"gender\", build_tower(x))\n",
        "pose = build_head(\"pose\", build_tower(x))\n",
        "weight = build_head(\"weight\", build_tower(x))\n",
        "\n",
        "\n",
        "inputs = model_bb.layers[0].output\n",
        "outputs=[gender, image_quality, age, weight, bag, footwear, pose, emotion]\n",
        "\n",
        "# define model\n",
        "model_final = Model(\n",
        "    inputs=inputs, \n",
        "    outputs=outputs\n",
        ")\n",
        "\n",
        "# configure optimizer and compile model\n",
        "opt = SGD(lr=0.005, momentum=0.9, nesterov=True)\n",
        "model_final.compile(\n",
        "    optimizer=opt,\n",
        "    loss=\"categorical_crossentropy\", \n",
        "    # loss_weights=loss_weights, \n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "model_final.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_17\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_11 (InputLayer)           (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_203 (Conv2D)             (None, 222, 222, 16) 448         input_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_25 (MaxPooling2D) (None, 111, 111, 16) 0           conv2d_203[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_204 (Conv2D)             (None, 111, 111, 16) 2320        max_pooling2d_25[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_153 (BatchN (None, 111, 111, 16) 64          conv2d_204[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 111, 111, 16) 0           batch_normalization_153[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_205 (Conv2D)             (None, 111, 111, 16) 272         activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_154 (BatchN (None, 111, 111, 16) 64          conv2d_205[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 111, 111, 16) 0           batch_normalization_154[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_206 (Conv2D)             (None, 111, 111, 16) 2320        activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_155 (BatchN (None, 111, 111, 16) 64          conv2d_206[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_147 (Activation)     (None, 111, 111, 16) 0           batch_normalization_155[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_208 (Conv2D)             (None, 111, 111, 64) 1088        activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_207 (Conv2D)             (None, 111, 111, 64) 1088        activation_147[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_49 (Add)                    (None, 111, 111, 64) 0           conv2d_208[0][0]                 \n",
            "                                                                 conv2d_207[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_156 (BatchN (None, 111, 111, 64) 256         add_49[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_148 (Activation)     (None, 111, 111, 64) 0           batch_normalization_156[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_209 (Conv2D)             (None, 111, 111, 16) 1040        activation_148[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_157 (BatchN (None, 111, 111, 16) 64          conv2d_209[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_149 (Activation)     (None, 111, 111, 16) 0           batch_normalization_157[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_210 (Conv2D)             (None, 111, 111, 16) 2320        activation_149[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_158 (BatchN (None, 111, 111, 16) 64          conv2d_210[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_150 (Activation)     (None, 111, 111, 16) 0           batch_normalization_158[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_211 (Conv2D)             (None, 111, 111, 64) 1088        activation_150[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_50 (Add)                    (None, 111, 111, 64) 0           add_49[0][0]                     \n",
            "                                                                 conv2d_211[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_159 (BatchN (None, 111, 111, 64) 256         add_50[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_151 (Activation)     (None, 111, 111, 64) 0           batch_normalization_159[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_212 (Conv2D)             (None, 56, 56, 64)   4160        activation_151[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_160 (BatchN (None, 56, 56, 64)   256         conv2d_212[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_152 (Activation)     (None, 56, 56, 64)   0           batch_normalization_160[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_213 (Conv2D)             (None, 56, 56, 64)   36928       activation_152[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_161 (BatchN (None, 56, 56, 64)   256         conv2d_213[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_153 (Activation)     (None, 56, 56, 64)   0           batch_normalization_161[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_215 (Conv2D)             (None, 56, 56, 128)  8320        add_50[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_214 (Conv2D)             (None, 56, 56, 128)  8320        activation_153[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_51 (Add)                    (None, 56, 56, 128)  0           conv2d_215[0][0]                 \n",
            "                                                                 conv2d_214[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_162 (BatchN (None, 56, 56, 128)  512         add_51[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_154 (Activation)     (None, 56, 56, 128)  0           batch_normalization_162[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_216 (Conv2D)             (None, 56, 56, 64)   8256        activation_154[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_163 (BatchN (None, 56, 56, 64)   256         conv2d_216[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_155 (Activation)     (None, 56, 56, 64)   0           batch_normalization_163[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_217 (Conv2D)             (None, 56, 56, 64)   36928       activation_155[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_164 (BatchN (None, 56, 56, 64)   256         conv2d_217[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_156 (Activation)     (None, 56, 56, 64)   0           batch_normalization_164[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_218 (Conv2D)             (None, 56, 56, 128)  8320        activation_156[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_52 (Add)                    (None, 56, 56, 128)  0           add_51[0][0]                     \n",
            "                                                                 conv2d_218[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_165 (BatchN (None, 56, 56, 128)  512         add_52[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_157 (Activation)     (None, 56, 56, 128)  0           batch_normalization_165[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_219 (Conv2D)             (None, 28, 28, 128)  16512       activation_157[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_166 (BatchN (None, 28, 28, 128)  512         conv2d_219[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_158 (Activation)     (None, 28, 28, 128)  0           batch_normalization_166[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_220 (Conv2D)             (None, 28, 28, 128)  147584      activation_158[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_167 (BatchN (None, 28, 28, 128)  512         conv2d_220[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_159 (Activation)     (None, 28, 28, 128)  0           batch_normalization_167[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_222 (Conv2D)             (None, 28, 28, 256)  33024       add_52[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_221 (Conv2D)             (None, 28, 28, 256)  33024       activation_159[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_53 (Add)                    (None, 28, 28, 256)  0           conv2d_222[0][0]                 \n",
            "                                                                 conv2d_221[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_168 (BatchN (None, 28, 28, 256)  1024        add_53[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_160 (Activation)     (None, 28, 28, 256)  0           batch_normalization_168[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_176 (MaxPooling2D (None, 55, 55, 16)   0           activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_178 (MaxPooling2D (None, 55, 55, 16)   0           activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_181 (MaxPooling2D (None, 55, 55, 16)   0           activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_183 (MaxPooling2D (None, 55, 55, 16)   0           activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_185 (MaxPooling2D (None, 55, 55, 16)   0           activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_223 (Conv2D)             (None, 28, 28, 128)  32896       activation_160[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_762 (Conv2D)             (None, 55, 55, 16)   2320        max_pooling2d_176[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_771 (Conv2D)             (None, 55, 55, 16)   2320        max_pooling2d_178[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_784 (Conv2D)             (None, 55, 55, 16)   2320        max_pooling2d_181[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_793 (Conv2D)             (None, 55, 55, 16)   2320        max_pooling2d_183[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_802 (Conv2D)             (None, 55, 55, 16)   2320        max_pooling2d_185[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_169 (BatchN (None, 28, 28, 128)  512         conv2d_223[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_526 (BatchN (None, 55, 55, 16)   64          conv2d_762[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_532 (BatchN (None, 55, 55, 16)   64          conv2d_771[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_541 (BatchN (None, 55, 55, 16)   64          conv2d_784[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_547 (BatchN (None, 55, 55, 16)   64          conv2d_793[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_553 (BatchN (None, 55, 55, 16)   64          conv2d_802[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_161 (Activation)     (None, 28, 28, 128)  0           batch_normalization_169[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_367 (Activation)     (None, 55, 55, 16)   0           batch_normalization_526[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_373 (Activation)     (None, 55, 55, 16)   0           batch_normalization_532[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_379 (Activation)     (None, 55, 55, 16)   0           batch_normalization_541[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_385 (Activation)     (None, 55, 55, 16)   0           batch_normalization_547[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_391 (Activation)     (None, 55, 55, 16)   0           batch_normalization_553[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_224 (Conv2D)             (None, 28, 28, 128)  147584      activation_161[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_763 (Conv2D)             (None, 55, 55, 16)   2320        activation_367[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_772 (Conv2D)             (None, 55, 55, 16)   2320        activation_373[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_785 (Conv2D)             (None, 55, 55, 16)   2320        activation_379[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_794 (Conv2D)             (None, 55, 55, 16)   2320        activation_385[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_803 (Conv2D)             (None, 55, 55, 16)   2320        activation_391[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_170 (BatchN (None, 28, 28, 128)  512         conv2d_224[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_527 (BatchN (None, 55, 55, 16)   64          conv2d_763[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_533 (BatchN (None, 55, 55, 16)   64          conv2d_772[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_542 (BatchN (None, 55, 55, 16)   64          conv2d_785[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_548 (BatchN (None, 55, 55, 16)   64          conv2d_794[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_554 (BatchN (None, 55, 55, 16)   64          conv2d_803[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_162 (Activation)     (None, 28, 28, 128)  0           batch_normalization_170[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_184 (Add)                   (None, 55, 55, 16)   0           max_pooling2d_176[0][0]          \n",
            "                                                                 batch_normalization_527[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_187 (Add)                   (None, 55, 55, 16)   0           max_pooling2d_178[0][0]          \n",
            "                                                                 batch_normalization_533[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_190 (Add)                   (None, 55, 55, 16)   0           max_pooling2d_181[0][0]          \n",
            "                                                                 batch_normalization_542[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_193 (Add)                   (None, 55, 55, 16)   0           max_pooling2d_183[0][0]          \n",
            "                                                                 batch_normalization_548[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_196 (Add)                   (None, 55, 55, 16)   0           max_pooling2d_185[0][0]          \n",
            "                                                                 batch_normalization_554[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_225 (Conv2D)             (None, 28, 28, 256)  33024       activation_162[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_368 (Activation)     (None, 55, 55, 16)   0           add_184[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_374 (Activation)     (None, 55, 55, 16)   0           add_187[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_380 (Activation)     (None, 55, 55, 16)   0           add_190[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_386 (Activation)     (None, 55, 55, 16)   0           add_193[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_392 (Activation)     (None, 55, 55, 16)   0           add_196[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add_54 (Add)                    (None, 28, 28, 256)  0           add_53[0][0]                     \n",
            "                                                                 conv2d_225[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_764 (Conv2D)             (None, 28, 28, 32)   4640        activation_368[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_773 (Conv2D)             (None, 28, 28, 32)   4640        activation_374[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_786 (Conv2D)             (None, 28, 28, 32)   4640        activation_380[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_795 (Conv2D)             (None, 28, 28, 32)   4640        activation_386[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_804 (Conv2D)             (None, 28, 28, 32)   4640        activation_392[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_758 (Conv2D)             (None, 28, 28, 128)  32896       add_54[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_528 (BatchN (None, 28, 28, 32)   128         conv2d_764[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_534 (BatchN (None, 28, 28, 32)   128         conv2d_773[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_780 (Conv2D)             (None, 28, 28, 128)  32896       add_54[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_543 (BatchN (None, 28, 28, 32)   128         conv2d_786[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_549 (BatchN (None, 28, 28, 32)   128         conv2d_795[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_811 (Conv2D)             (None, 28, 28, 128)  32896       add_54[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_555 (BatchN (None, 28, 28, 32)   128         conv2d_804[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_213 (Dropout)           (None, 28, 28, 128)  0           conv2d_758[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_369 (Activation)     (None, 28, 28, 32)   0           batch_normalization_528[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_375 (Activation)     (None, 28, 28, 32)   0           batch_normalization_534[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_218 (Dropout)           (None, 28, 28, 128)  0           conv2d_780[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_381 (Activation)     (None, 28, 28, 32)   0           batch_normalization_543[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_387 (Activation)     (None, 28, 28, 32)   0           batch_normalization_549[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_223 (Dropout)           (None, 28, 28, 128)  0           conv2d_811[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_393 (Activation)     (None, 28, 28, 32)   0           batch_normalization_555[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_175 (MaxPooling2D (None, 14, 14, 128)  0           dropout_213[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_765 (Conv2D)             (None, 28, 28, 32)   9248        activation_369[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_774 (Conv2D)             (None, 28, 28, 32)   9248        activation_375[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_180 (MaxPooling2D (None, 14, 14, 128)  0           dropout_218[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_787 (Conv2D)             (None, 28, 28, 32)   9248        activation_381[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_796 (Conv2D)             (None, 28, 28, 32)   9248        activation_387[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_187 (MaxPooling2D (None, 14, 14, 128)  0           dropout_223[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_805 (Conv2D)             (None, 28, 28, 32)   9248        activation_393[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_105 (Separable (None, 12, 12, 160)  21792       max_pooling2d_175[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_766 (Conv2D)             (None, 28, 28, 32)   544         activation_368[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_529 (BatchN (None, 28, 28, 32)   128         conv2d_765[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_775 (Conv2D)             (None, 28, 28, 32)   544         activation_374[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_535 (BatchN (None, 28, 28, 32)   128         conv2d_774[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_107 (Separable (None, 12, 12, 160)  21792       max_pooling2d_180[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_788 (Conv2D)             (None, 28, 28, 32)   544         activation_380[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_544 (BatchN (None, 28, 28, 32)   128         conv2d_787[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_797 (Conv2D)             (None, 28, 28, 32)   544         activation_386[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_550 (BatchN (None, 28, 28, 32)   128         conv2d_796[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_109 (Separable (None, 12, 12, 160)  21792       max_pooling2d_187[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_806 (Conv2D)             (None, 28, 28, 32)   544         activation_392[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_556 (BatchN (None, 28, 28, 32)   128         conv2d_805[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_214 (Dropout)           (None, 12, 12, 160)  0           separable_conv2d_105[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_185 (Add)                   (None, 28, 28, 32)   0           conv2d_766[0][0]                 \n",
            "                                                                 batch_normalization_529[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_188 (Add)                   (None, 28, 28, 32)   0           conv2d_775[0][0]                 \n",
            "                                                                 batch_normalization_535[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_219 (Dropout)           (None, 12, 12, 160)  0           separable_conv2d_107[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_191 (Add)                   (None, 28, 28, 32)   0           conv2d_788[0][0]                 \n",
            "                                                                 batch_normalization_544[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_194 (Add)                   (None, 28, 28, 32)   0           conv2d_797[0][0]                 \n",
            "                                                                 batch_normalization_550[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_224 (Dropout)           (None, 12, 12, 160)  0           separable_conv2d_109[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_197 (Add)                   (None, 28, 28, 32)   0           conv2d_806[0][0]                 \n",
            "                                                                 batch_normalization_556[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_106 (Separable (None, 10, 10, 192)  32352       dropout_214[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_370 (Activation)     (None, 28, 28, 32)   0           add_185[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_376 (Activation)     (None, 28, 28, 32)   0           add_188[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_108 (Separable (None, 10, 10, 192)  32352       dropout_219[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_382 (Activation)     (None, 28, 28, 32)   0           add_191[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_388 (Activation)     (None, 28, 28, 32)   0           add_194[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_110 (Separable (None, 10, 10, 192)  32352       dropout_224[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_394 (Activation)     (None, 28, 28, 32)   0           add_197[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_215 (Dropout)           (None, 10, 10, 192)  0           separable_conv2d_106[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_767 (Conv2D)             (None, 14, 14, 64)   18496       activation_370[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_776 (Conv2D)             (None, 14, 14, 64)   18496       activation_376[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_220 (Dropout)           (None, 10, 10, 192)  0           separable_conv2d_108[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_789 (Conv2D)             (None, 14, 14, 64)   18496       activation_382[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_798 (Conv2D)             (None, 14, 14, 64)   18496       activation_388[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_225 (Dropout)           (None, 10, 10, 192)  0           separable_conv2d_110[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_807 (Conv2D)             (None, 14, 14, 64)   18496       activation_394[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_759 (Conv2D)             (None, 8, 8, 208)    359632      dropout_215[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_530 (BatchN (None, 14, 14, 64)   256         conv2d_767[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_536 (BatchN (None, 14, 14, 64)   256         conv2d_776[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_781 (Conv2D)             (None, 8, 8, 208)    359632      dropout_220[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_545 (BatchN (None, 14, 14, 64)   256         conv2d_789[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_551 (BatchN (None, 14, 14, 64)   256         conv2d_798[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_812 (Conv2D)             (None, 8, 8, 208)    359632      dropout_225[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_557 (BatchN (None, 14, 14, 64)   256         conv2d_807[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_523 (BatchN (None, 8, 8, 208)    832         conv2d_759[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_371 (Activation)     (None, 14, 14, 64)   0           batch_normalization_530[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_377 (Activation)     (None, 14, 14, 64)   0           batch_normalization_536[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_538 (BatchN (None, 8, 8, 208)    832         conv2d_781[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_383 (Activation)     (None, 14, 14, 64)   0           batch_normalization_545[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_389 (Activation)     (None, 14, 14, 64)   0           batch_normalization_551[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_559 (BatchN (None, 8, 8, 208)    832         conv2d_812[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_395 (Activation)     (None, 14, 14, 64)   0           batch_normalization_557[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_216 (Dropout)           (None, 8, 8, 208)    0           batch_normalization_523[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_768 (Conv2D)             (None, 14, 14, 64)   36928       activation_371[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_777 (Conv2D)             (None, 14, 14, 64)   36928       activation_377[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_221 (Dropout)           (None, 8, 8, 208)    0           batch_normalization_538[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_790 (Conv2D)             (None, 14, 14, 64)   36928       activation_383[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_799 (Conv2D)             (None, 14, 14, 64)   36928       activation_389[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_226 (Dropout)           (None, 8, 8, 208)    0           batch_normalization_559[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_808 (Conv2D)             (None, 14, 14, 64)   36928       activation_395[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_760 (Conv2D)             (None, 6, 6, 224)    419552      dropout_216[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_769 (Conv2D)             (None, 14, 14, 64)   2112        activation_370[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_531 (BatchN (None, 14, 14, 64)   256         conv2d_768[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_778 (Conv2D)             (None, 14, 14, 64)   2112        activation_376[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_537 (BatchN (None, 14, 14, 64)   256         conv2d_777[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_782 (Conv2D)             (None, 6, 6, 224)    419552      dropout_221[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_791 (Conv2D)             (None, 14, 14, 64)   2112        activation_382[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_546 (BatchN (None, 14, 14, 64)   256         conv2d_790[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_800 (Conv2D)             (None, 14, 14, 64)   2112        activation_388[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_552 (BatchN (None, 14, 14, 64)   256         conv2d_799[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_813 (Conv2D)             (None, 6, 6, 224)    419552      dropout_226[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_809 (Conv2D)             (None, 14, 14, 64)   2112        activation_394[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_558 (BatchN (None, 14, 14, 64)   256         conv2d_808[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_524 (BatchN (None, 6, 6, 224)    896         conv2d_760[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_186 (Add)                   (None, 14, 14, 64)   0           conv2d_769[0][0]                 \n",
            "                                                                 batch_normalization_531[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_189 (Add)                   (None, 14, 14, 64)   0           conv2d_778[0][0]                 \n",
            "                                                                 batch_normalization_537[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_539 (BatchN (None, 6, 6, 224)    896         conv2d_782[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_192 (Add)                   (None, 14, 14, 64)   0           conv2d_791[0][0]                 \n",
            "                                                                 batch_normalization_546[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_195 (Add)                   (None, 14, 14, 64)   0           conv2d_800[0][0]                 \n",
            "                                                                 batch_normalization_552[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_560 (BatchN (None, 6, 6, 224)    896         conv2d_813[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_198 (Add)                   (None, 14, 14, 64)   0           conv2d_809[0][0]                 \n",
            "                                                                 batch_normalization_558[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_217 (Dropout)           (None, 6, 6, 224)    0           batch_normalization_524[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_372 (Activation)     (None, 14, 14, 64)   0           add_186[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_378 (Activation)     (None, 14, 14, 64)   0           add_189[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_222 (Dropout)           (None, 6, 6, 224)    0           batch_normalization_539[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_384 (Activation)     (None, 14, 14, 64)   0           add_192[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_390 (Activation)     (None, 14, 14, 64)   0           add_195[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_227 (Dropout)           (None, 6, 6, 224)    0           batch_normalization_560[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_396 (Activation)     (None, 14, 14, 64)   0           add_198[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_761 (Conv2D)             (None, 4, 4, 240)    484080      dropout_217[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_177 (MaxPooling2D (None, 7, 7, 64)     0           activation_372[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_179 (MaxPooling2D (None, 7, 7, 64)     0           activation_378[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_783 (Conv2D)             (None, 4, 4, 240)    484080      dropout_222[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_182 (MaxPooling2D (None, 7, 7, 64)     0           activation_384[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_184 (MaxPooling2D (None, 7, 7, 64)     0           activation_390[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_814 (Conv2D)             (None, 4, 4, 240)    484080      dropout_227[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_186 (MaxPooling2D (None, 7, 7, 64)     0           activation_396[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_525 (BatchN (None, 4, 4, 240)    960         conv2d_761[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_770 (Conv2D)             (None, 5, 5, 128)    73856       max_pooling2d_177[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_779 (Conv2D)             (None, 5, 5, 128)    73856       max_pooling2d_179[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_540 (BatchN (None, 4, 4, 240)    960         conv2d_783[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_792 (Conv2D)             (None, 5, 5, 128)    73856       max_pooling2d_182[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_801 (Conv2D)             (None, 5, 5, 128)    73856       max_pooling2d_184[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_561 (BatchN (None, 4, 4, 240)    960         conv2d_814[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_810 (Conv2D)             (None, 5, 5, 128)    73856       max_pooling2d_186[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_114 (G (None, 240)          0           batch_normalization_525[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_115 (G (None, 128)          0           conv2d_770[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_116 (G (None, 128)          0           conv2d_779[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_117 (G (None, 240)          0           batch_normalization_540[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_118 (G (None, 128)          0           conv2d_792[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_119 (G (None, 128)          0           conv2d_801[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_121 (G (None, 240)          0           batch_normalization_561[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_120 (G (None, 128)          0           conv2d_810[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "gender_output (Dense)           (None, 2)            482         global_average_pooling2d_114[0][0\n",
            "__________________________________________________________________________________________________\n",
            "image_quality_output (Dense)    (None, 3)            387         global_average_pooling2d_115[0][0\n",
            "__________________________________________________________________________________________________\n",
            "age_output (Dense)              (None, 5)            645         global_average_pooling2d_116[0][0\n",
            "__________________________________________________________________________________________________\n",
            "weight_output (Dense)           (None, 4)            964         global_average_pooling2d_117[0][0\n",
            "__________________________________________________________________________________________________\n",
            "bag_output (Dense)              (None, 3)            387         global_average_pooling2d_118[0][0\n",
            "__________________________________________________________________________________________________\n",
            "footwear_output (Dense)         (None, 3)            387         global_average_pooling2d_119[0][0\n",
            "__________________________________________________________________________________________________\n",
            "pose_output (Dense)             (None, 3)            723         global_average_pooling2d_121[0][0\n",
            "__________________________________________________________________________________________________\n",
            "emotion_output (Dense)          (None, 4)            516         global_average_pooling2d_120[0][0\n",
            "==================================================================================================\n",
            "Total params: 5,393,083\n",
            "Trainable params: 4,813,995\n",
            "Non-trainable params: 579,088\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2Yf9b5gALkR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_suffix = 'res20'\n",
        "# Prepare model saving directory.\n",
        "save_dir = os.path.join(os.getcwd(), 'gdrive', 'My Drive', 'eip4_assignment5_modelweights', '29dec_finalmodel_submit')\n",
        "model_name = 'eip4a5_model_%s.{epoch:03d}.h5' % model_suffix\n",
        "\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)\n",
        "\n",
        "callbacks = [checkpoint, lr_reducer]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAyh_L6SAZh2",
        "colab_type": "code",
        "outputId": "61eaf8ff-5bff-4c77-8c96-84c5f58434cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "######################### FINAL MODEL #######################################\n",
        "\n",
        "# Fit the model on the batches generated by datagen.flow().\n",
        "\n",
        "model_final.fit_generator(train_genr,\n",
        "                    validation_data = valid_genr,\n",
        "                    use_multiprocessing=True,\n",
        "                    workers=6, \n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    callbacks=callbacks)\n",
        "\n",
        "\n",
        "# val_gender_output_acc: 0.8674 \n",
        "# val_image_quality_output_acc: 0.5842 \n",
        "# val_age_output_acc: 0.3911\n",
        "# val_weight_output_acc: 0.6114\n",
        "# val_bag_output_acc: 0.6310\n",
        "# val_footwear_output_acc: 0.6547\n",
        "# val_pose_output_acc: 0.7959\n",
        "# val_emotion_output_acc: 0.7061"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "360/360 [==============================] - 88s 243ms/step - loss: 8.4107 - gender_output_loss: 0.4808 - image_quality_output_loss: 0.9663 - age_output_loss: 1.4969 - weight_output_loss: 1.0371 - bag_output_loss: 0.9518 - footwear_output_loss: 1.0252 - pose_output_loss: 0.9102 - emotion_output_loss: 0.9361 - gender_output_acc: 0.7704 - image_quality_output_acc: 0.5413 - age_output_acc: 0.3921 - weight_output_acc: 0.6110 - bag_output_acc: 0.5602 - footwear_output_acc: 0.5327 - pose_output_acc: 0.5973 - emotion_output_acc: 0.7106 - val_loss: 8.4806 - val_gender_output_loss: 0.5500 - val_image_quality_output_loss: 0.9137 - val_age_output_loss: 1.4263 - val_weight_output_loss: 1.3233 - val_bag_output_loss: 0.9178 - val_footwear_output_loss: 0.9768 - val_pose_output_loss: 0.8464 - val_emotion_output_loss: 0.9212 - val_gender_output_acc: 0.7540 - val_image_quality_output_acc: 0.5640 - val_age_output_acc: 0.3836 - val_weight_output_acc: 0.6114 - val_bag_output_acc: 0.5529 - val_footwear_output_acc: 0.5368 - val_pose_output_acc: 0.6709 - val_emotion_output_acc: 0.7061\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 7.41456\n",
            "Epoch 2/50\n",
            "360/360 [==============================] - 52s 144ms/step - loss: 7.8085 - gender_output_loss: 0.3616 - image_quality_output_loss: 0.9328 - age_output_loss: 1.4185 - weight_output_loss: 0.9891 - bag_output_loss: 0.9164 - footwear_output_loss: 0.9234 - pose_output_loss: 0.7564 - emotion_output_loss: 0.9065 - gender_output_acc: 0.8432 - image_quality_output_acc: 0.5535 - age_output_acc: 0.4008 - weight_output_acc: 0.6300 - bag_output_acc: 0.5646 - footwear_output_acc: 0.5768 - pose_output_acc: 0.6721 - emotion_output_acc: 0.7129 - val_loss: 8.0080 - val_gender_output_loss: 0.4298 - val_image_quality_output_loss: 0.9299 - val_age_output_loss: 1.4206 - val_weight_output_loss: 1.0651 - val_bag_output_loss: 0.9185 - val_footwear_output_loss: 0.9610 - val_pose_output_loss: 0.7641 - val_emotion_output_loss: 0.9163 - val_gender_output_acc: 0.8105 - val_image_quality_output_acc: 0.5323 - val_age_output_acc: 0.3851 - val_weight_output_acc: 0.6447 - val_bag_output_acc: 0.5529 - val_footwear_output_acc: 0.5590 - val_pose_output_acc: 0.6941 - val_emotion_output_acc: 0.7061\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 7.41456\n",
            "Epoch 3/50\n",
            "360/360 [==============================] - 53s 146ms/step - loss: 7.6578 - gender_output_loss: 0.3327 - image_quality_output_loss: 0.9276 - age_output_loss: 1.4150 - weight_output_loss: 0.9798 - bag_output_loss: 0.9112 - footwear_output_loss: 0.8886 - pose_output_loss: 0.6960 - emotion_output_loss: 0.9053 - gender_output_acc: 0.8543 - image_quality_output_acc: 0.5555 - age_output_acc: 0.3998 - weight_output_acc: 0.6320 - bag_output_acc: 0.5651 - footwear_output_acc: 0.6004 - pose_output_acc: 0.7063 - emotion_output_acc: 0.7125 - val_loss: 7.7551 - val_gender_output_loss: 0.3883 - val_image_quality_output_loss: 0.9058 - val_age_output_loss: 1.4204 - val_weight_output_loss: 1.0311 - val_bag_output_loss: 0.9066 - val_footwear_output_loss: 0.8820 - val_pose_output_loss: 0.7080 - val_emotion_output_loss: 0.9124 - val_gender_output_acc: 0.8392 - val_image_quality_output_acc: 0.5701 - val_age_output_acc: 0.3856 - val_weight_output_acc: 0.5993 - val_bag_output_acc: 0.5524 - val_footwear_output_acc: 0.5907 - val_pose_output_acc: 0.7107 - val_emotion_output_acc: 0.7061\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 7.41456\n",
            "Epoch 4/50\n",
            "360/360 [==============================] - 53s 146ms/step - loss: 7.5380 - gender_output_loss: 0.3074 - image_quality_output_loss: 0.9206 - age_output_loss: 1.4063 - weight_output_loss: 0.9727 - bag_output_loss: 0.9044 - footwear_output_loss: 0.8643 - pose_output_loss: 0.6634 - emotion_output_loss: 0.8993 - gender_output_acc: 0.8686 - image_quality_output_acc: 0.5595 - age_output_acc: 0.3997 - weight_output_acc: 0.6328 - bag_output_acc: 0.5657 - footwear_output_acc: 0.6173 - pose_output_acc: 0.7215 - emotion_output_acc: 0.7131 - val_loss: 7.7003 - val_gender_output_loss: 0.3966 - val_image_quality_output_loss: 0.9480 - val_age_output_loss: 1.4171 - val_weight_output_loss: 1.0248 - val_bag_output_loss: 0.9030 - val_footwear_output_loss: 0.8530 - val_pose_output_loss: 0.6436 - val_emotion_output_loss: 0.9158 - val_gender_output_acc: 0.8291 - val_image_quality_output_acc: 0.5670 - val_age_output_acc: 0.3810 - val_weight_output_acc: 0.6457 - val_bag_output_acc: 0.5529 - val_footwear_output_acc: 0.6195 - val_pose_output_acc: 0.7414 - val_emotion_output_acc: 0.7061\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 7.41456\n",
            "Epoch 5/50\n",
            "360/360 [==============================] - 53s 146ms/step - loss: 7.4508 - gender_output_loss: 0.2875 - image_quality_output_loss: 0.9161 - age_output_loss: 1.4030 - weight_output_loss: 0.9674 - bag_output_loss: 0.8990 - footwear_output_loss: 0.8453 - pose_output_loss: 0.6362 - emotion_output_loss: 0.8990 - gender_output_acc: 0.8782 - image_quality_output_acc: 0.5572 - age_output_acc: 0.4036 - weight_output_acc: 0.6318 - bag_output_acc: 0.5675 - footwear_output_acc: 0.6237 - pose_output_acc: 0.7359 - emotion_output_acc: 0.7128 - val_loss: 7.7359 - val_gender_output_loss: 0.4029 - val_image_quality_output_loss: 0.9044 - val_age_output_loss: 1.4010 - val_weight_output_loss: 0.9983 - val_bag_output_loss: 0.9162 - val_footwear_output_loss: 0.9942 - val_pose_output_loss: 0.6035 - val_emotion_output_loss: 0.9192 - val_gender_output_acc: 0.8387 - val_image_quality_output_acc: 0.5721 - val_age_output_acc: 0.3891 - val_weight_output_acc: 0.6421 - val_bag_output_acc: 0.5514 - val_footwear_output_acc: 0.4975 - val_pose_output_acc: 0.7429 - val_emotion_output_acc: 0.7061\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 7.41456\n",
            "Epoch 6/50\n",
            "360/360 [==============================] - 52s 145ms/step - loss: 7.4020 - gender_output_loss: 0.2842 - image_quality_output_loss: 0.9138 - age_output_loss: 1.3963 - weight_output_loss: 0.9632 - bag_output_loss: 0.8937 - footwear_output_loss: 0.8384 - pose_output_loss: 0.6213 - emotion_output_loss: 0.8957 - gender_output_acc: 0.8808 - image_quality_output_acc: 0.5595 - age_output_acc: 0.4032 - weight_output_acc: 0.6321 - bag_output_acc: 0.5705 - footwear_output_acc: 0.6313 - pose_output_acc: 0.7446 - emotion_output_acc: 0.7128 - val_loss: 7.5639 - val_gender_output_loss: 0.4041 - val_image_quality_output_loss: 0.9168 - val_age_output_loss: 1.4170 - val_weight_output_loss: 0.9603 - val_bag_output_loss: 0.9010 - val_footwear_output_loss: 0.8625 - val_pose_output_loss: 0.5937 - val_emotion_output_loss: 0.9142 - val_gender_output_acc: 0.8458 - val_image_quality_output_acc: 0.5660 - val_age_output_acc: 0.3871 - val_weight_output_acc: 0.6442 - val_bag_output_acc: 0.5590 - val_footwear_output_acc: 0.6149 - val_pose_output_acc: 0.7621 - val_emotion_output_acc: 0.7061\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 7.41456\n",
            "Epoch 7/50\n",
            "359/360 [============================>.] - ETA: 0s - loss: 7.3421 - gender_output_loss: 0.2770 - image_quality_output_loss: 0.9107 - age_output_loss: 1.3902 - weight_output_loss: 0.9613 - bag_output_loss: 0.8912 - footwear_output_loss: 0.8304 - pose_output_loss: 0.5941 - emotion_output_loss: 0.8939 - gender_output_acc: 0.8849 - image_quality_output_acc: 0.5633 - age_output_acc: 0.4025 - weight_output_acc: 0.6337 - bag_output_acc: 0.5744 - footwear_output_acc: 0.6350 - pose_output_acc: 0.7524 - emotion_output_acc: 0.7126Epoch 7/50\n",
            "360/360 [==============================] - 53s 148ms/step - loss: 7.3414 - gender_output_loss: 0.2767 - image_quality_output_loss: 0.9109 - age_output_loss: 1.3897 - weight_output_loss: 0.9612 - bag_output_loss: 0.8910 - footwear_output_loss: 0.8308 - pose_output_loss: 0.5942 - emotion_output_loss: 0.8937 - gender_output_acc: 0.8851 - image_quality_output_acc: 0.5632 - age_output_acc: 0.4028 - weight_output_acc: 0.6339 - bag_output_acc: 0.5742 - footwear_output_acc: 0.6345 - pose_output_acc: 0.7523 - emotion_output_acc: 0.7127 - val_loss: 7.5475 - val_gender_output_loss: 0.3842 - val_image_quality_output_loss: 0.8939 - val_age_output_loss: 1.4007 - val_weight_output_loss: 0.9978 - val_bag_output_loss: 0.8960 - val_footwear_output_loss: 0.8344 - val_pose_output_loss: 0.6203 - val_emotion_output_loss: 0.9280 - val_gender_output_acc: 0.8417 - val_image_quality_output_acc: 0.5746 - val_age_output_acc: 0.3881 - val_weight_output_acc: 0.6275 - val_bag_output_acc: 0.5711 - val_footwear_output_acc: 0.6275 - val_pose_output_acc: 0.7545 - val_emotion_output_acc: 0.7061\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 7.41456\n",
            "Epoch 8/50\n",
            "360/360 [==============================] - 52s 146ms/step - loss: 7.2913 - gender_output_loss: 0.2649 - image_quality_output_loss: 0.9099 - age_output_loss: 1.3851 - weight_output_loss: 0.9584 - bag_output_loss: 0.8837 - footwear_output_loss: 0.8198 - pose_output_loss: 0.5857 - emotion_output_loss: 0.8927 - gender_output_acc: 0.8887 - image_quality_output_acc: 0.5621 - age_output_acc: 0.4039 - weight_output_acc: 0.6318 - bag_output_acc: 0.5794 - footwear_output_acc: 0.6418 - pose_output_acc: 0.7592 - emotion_output_acc: 0.7128 - val_loss: 7.7655 - val_gender_output_loss: 0.5017 - val_image_quality_output_loss: 0.9010 - val_age_output_loss: 1.3841 - val_weight_output_loss: 0.9944 - val_bag_output_loss: 0.9042 - val_footwear_output_loss: 0.9157 - val_pose_output_loss: 0.6609 - val_emotion_output_loss: 0.9132 - val_gender_output_acc: 0.8211 - val_image_quality_output_acc: 0.5731 - val_age_output_acc: 0.3871 - val_weight_output_acc: 0.6356 - val_bag_output_acc: 0.5509 - val_footwear_output_acc: 0.5988 - val_pose_output_acc: 0.7389 - val_emotion_output_acc: 0.7061\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 7.41456\n",
            "Epoch 9/50\n",
            "359/360 [============================>.] - ETA: 0s - loss: 7.2579 - gender_output_loss: 0.2650 - image_quality_output_loss: 0.9070 - age_output_loss: 1.3820 - weight_output_loss: 0.9577 - bag_output_loss: 0.8819 - footwear_output_loss: 0.8163 - pose_output_loss: 0.5687 - emotion_output_loss: 0.8900 - gender_output_acc: 0.8892 - image_quality_output_acc: 0.5589 - age_output_acc: 0.4029 - weight_output_acc: 0.6327 - bag_output_acc: 0.5769 - footwear_output_acc: 0.6391 - pose_output_acc: 0.7671 - emotion_output_acc: 0.7127\n",
            "Epoch 00008: val_loss did not improve from 7.41456\n",
            "Epoch 9/50\n",
            "360/360 [==============================] - 53s 148ms/step - loss: 7.2587 - gender_output_loss: 0.2649 - image_quality_output_loss: 0.9074 - age_output_loss: 1.3821 - weight_output_loss: 0.9572 - bag_output_loss: 0.8822 - footwear_output_loss: 0.8162 - pose_output_loss: 0.5695 - emotion_output_loss: 0.8901 - gender_output_acc: 0.8893 - image_quality_output_acc: 0.5588 - age_output_acc: 0.4029 - weight_output_acc: 0.6331 - bag_output_acc: 0.5767 - footwear_output_acc: 0.6393 - pose_output_acc: 0.7668 - emotion_output_acc: 0.7126 - val_loss: 7.5200 - val_gender_output_loss: 0.3977 - val_image_quality_output_loss: 0.9238 - val_age_output_loss: 1.3903 - val_weight_output_loss: 0.9948 - val_bag_output_loss: 0.8930 - val_footwear_output_loss: 0.8118 - val_pose_output_loss: 0.6034 - val_emotion_output_loss: 0.9169 - val_gender_output_acc: 0.8432 - val_image_quality_output_acc: 0.5746 - val_age_output_acc: 0.3866 - val_weight_output_acc: 0.5973 - val_bag_output_acc: 0.5756 - val_footwear_output_acc: 0.6447 - val_pose_output_acc: 0.7621 - val_emotion_output_acc: 0.7061\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 7.41456\n",
            "Epoch 10/50\n",
            "360/360 [==============================] - 52s 146ms/step - loss: 7.2017 - gender_output_loss: 0.2496 - image_quality_output_loss: 0.9022 - age_output_loss: 1.3786 - weight_output_loss: 0.9527 - bag_output_loss: 0.8788 - footwear_output_loss: 0.8055 - pose_output_loss: 0.5593 - emotion_output_loss: 0.8877 - gender_output_acc: 0.8955 - image_quality_output_acc: 0.5624 - age_output_acc: 0.4012 - weight_output_acc: 0.6318 - bag_output_acc: 0.5793 - footwear_output_acc: 0.6483 - pose_output_acc: 0.7721 - emotion_output_acc: 0.7129 - val_loss: 7.5429 - val_gender_output_loss: 0.3886 - val_image_quality_output_loss: 0.9387 - val_age_output_loss: 1.3889 - val_weight_output_loss: 0.9887 - val_bag_output_loss: 0.9351 - val_footwear_output_loss: 0.8209 - val_pose_output_loss: 0.5707 - val_emotion_output_loss: 0.9248 - val_gender_output_acc: 0.8543 - val_image_quality_output_acc: 0.5504 - val_age_output_acc: 0.3871 - val_weight_output_acc: 0.6275 - val_bag_output_acc: 0.5640 - val_footwear_output_acc: 0.6396 - val_pose_output_acc: 0.7767 - val_emotion_output_acc: 0.7061\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 7.41456\n",
            "Epoch 11/50\n",
            "359/360 [============================>.] - ETA: 0s - loss: 7.1711 - gender_output_loss: 0.2467 - image_quality_output_loss: 0.9026 - age_output_loss: 1.3725 - weight_output_loss: 0.9511 - bag_output_loss: 0.8728 - footwear_output_loss: 0.8047 - pose_output_loss: 0.5501 - emotion_output_loss: 0.8852 - gender_output_acc: 0.8988 - image_quality_output_acc: 0.5648 - age_output_acc: 0.4063 - weight_output_acc: 0.6328 - bag_output_acc: 0.5906 - footwear_output_acc: 0.6476 - pose_output_acc: 0.7761 - emotion_output_acc: 0.7128Epoch 11/50\n",
            "360/360 [==============================] - 53s 148ms/step - loss: 7.1714 - gender_output_loss: 0.2466 - image_quality_output_loss: 0.9022 - age_output_loss: 1.3728 - weight_output_loss: 0.9508 - bag_output_loss: 0.8727 - footwear_output_loss: 0.8050 - pose_output_loss: 0.5500 - emotion_output_loss: 0.8858 - gender_output_acc: 0.8989 - image_quality_output_acc: 0.5651 - age_output_acc: 0.4059 - weight_output_acc: 0.6331 - bag_output_acc: 0.5908 - footwear_output_acc: 0.6476 - pose_output_acc: 0.7763 - emotion_output_acc: 0.7126 - val_loss: 7.4585 - val_gender_output_loss: 0.4295 - val_image_quality_output_loss: 0.9006 - val_age_output_loss: 1.4078 - val_weight_output_loss: 0.9531 - val_bag_output_loss: 0.9020 - val_footwear_output_loss: 0.8126 - val_pose_output_loss: 0.5580 - val_emotion_output_loss: 0.9104 - val_gender_output_acc: 0.8367 - val_image_quality_output_acc: 0.5832 - val_age_output_acc: 0.3841 - val_weight_output_acc: 0.6457 - val_bag_output_acc: 0.5670 - val_footwear_output_acc: 0.6416 - val_pose_output_acc: 0.7833 - val_emotion_output_acc: 0.7061\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 7.41456\n",
            "Epoch 12/50\n",
            "360/360 [==============================] - 53s 147ms/step - loss: 7.1245 - gender_output_loss: 0.2372 - image_quality_output_loss: 0.9012 - age_output_loss: 1.3690 - weight_output_loss: 0.9481 - bag_output_loss: 0.8697 - footwear_output_loss: 0.7931 - pose_output_loss: 0.5396 - emotion_output_loss: 0.8831 - gender_output_acc: 0.9013 - image_quality_output_acc: 0.5647 - age_output_acc: 0.4077 - weight_output_acc: 0.6323 - bag_output_acc: 0.5953 - footwear_output_acc: 0.6490 - pose_output_acc: 0.7819 - emotion_output_acc: 0.7132 - val_loss: 7.4581 - val_gender_output_loss: 0.4094 - val_image_quality_output_loss: 0.8976 - val_age_output_loss: 1.3882 - val_weight_output_loss: 0.9742 - val_bag_output_loss: 0.8750 - val_footwear_output_loss: 0.8509 - val_pose_output_loss: 0.5660 - val_emotion_output_loss: 0.9142 - val_gender_output_acc: 0.8558 - val_image_quality_output_acc: 0.5817 - val_age_output_acc: 0.3982 - val_weight_output_acc: 0.6310 - val_bag_output_acc: 0.5897 - val_footwear_output_acc: 0.6260 - val_pose_output_acc: 0.7908 - val_emotion_output_acc: 0.7061\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 7.41456\n",
            "Epoch 13/50\n",
            "360/360 [==============================] - 53s 147ms/step - loss: 7.0952 - gender_output_loss: 0.2292 - image_quality_output_loss: 0.8970 - age_output_loss: 1.3664 - weight_output_loss: 0.9484 - bag_output_loss: 0.8657 - footwear_output_loss: 0.7894 - pose_output_loss: 0.5336 - emotion_output_loss: 0.8837 - gender_output_acc: 0.9062 - image_quality_output_acc: 0.5669 - age_output_acc: 0.4044 - weight_output_acc: 0.6348 - bag_output_acc: 0.5922 - footwear_output_acc: 0.6559 - pose_output_acc: 0.7853 - emotion_output_acc: 0.7128 - val_loss: 7.3974 - val_gender_output_loss: 0.3688 - val_image_quality_output_loss: 0.9174 - val_age_output_loss: 1.3858 - val_weight_output_loss: 0.9709 - val_bag_output_loss: 0.8817 - val_footwear_output_loss: 0.8075 - val_pose_output_loss: 0.5703 - val_emotion_output_loss: 0.9139 - val_gender_output_acc: 0.8624 - val_image_quality_output_acc: 0.5449 - val_age_output_acc: 0.3876 - val_weight_output_acc: 0.6371 - val_bag_output_acc: 0.5887 - val_footwear_output_acc: 0.6477 - val_pose_output_acc: 0.7712 - val_emotion_output_acc: 0.7061\n",
            "\n",
            "Epoch 00013: val_loss improved from 7.41456 to 7.39739, saving model to /content/gdrive/My Drive/eip4_assignment5_modelweights/29dec_finalmodel_submit/eip4a5_model_res20.013.h5\n",
            "Epoch 14/50\n",
            "360/360 [==============================] - 52s 145ms/step - loss: 7.0624 - gender_output_loss: 0.2311 - image_quality_output_loss: 0.8953 - age_output_loss: 1.3644 - weight_output_loss: 0.9435 - bag_output_loss: 0.8619 - footwear_output_loss: 0.7845 - pose_output_loss: 0.5220 - emotion_output_loss: 0.8796 - gender_output_acc: 0.9056 - image_quality_output_acc: 0.5668 - age_output_acc: 0.4072 - weight_output_acc: 0.6349 - bag_output_acc: 0.5987 - footwear_output_acc: 0.6544 - pose_output_acc: 0.7928 - emotion_output_acc: 0.7127 - val_loss: 7.3409 - val_gender_output_loss: 0.3816 - val_image_quality_output_loss: 0.8928 - val_age_output_loss: 1.3780 - val_weight_output_loss: 0.9476 - val_bag_output_loss: 0.8753 - val_footwear_output_loss: 0.8140 - val_pose_output_loss: 0.5605 - val_emotion_output_loss: 0.9119 - val_gender_output_acc: 0.8473 - val_image_quality_output_acc: 0.5817 - val_age_output_acc: 0.3926 - val_weight_output_acc: 0.6452 - val_bag_output_acc: 0.5796 - val_footwear_output_acc: 0.6401 - val_pose_output_acc: 0.7772 - val_emotion_output_acc: 0.7061\n",
            "\n",
            "Epoch 00014: val_loss improved from 7.39739 to 7.34091, saving model to /content/gdrive/My Drive/eip4_assignment5_modelweights/29dec_finalmodel_submit/eip4a5_model_res20.014.h5\n",
            "Epoch 15/50\n",
            "360/360 [==============================] - 51s 142ms/step - loss: 7.0133 - gender_output_loss: 0.2188 - image_quality_output_loss: 0.8950 - age_output_loss: 1.3573 - weight_output_loss: 0.9404 - bag_output_loss: 0.8561 - footwear_output_loss: 0.7802 - pose_output_loss: 0.5092 - emotion_output_loss: 0.8780 - gender_output_acc: 0.9109 - image_quality_output_acc: 0.5704 - age_output_acc: 0.4100 - weight_output_acc: 0.6334 - bag_output_acc: 0.6005 - footwear_output_acc: 0.6586 - pose_output_acc: 0.7980 - emotion_output_acc: 0.7130 - val_loss: 7.4504 - val_gender_output_loss: 0.4480 - val_image_quality_output_loss: 0.9030 - val_age_output_loss: 1.3750 - val_weight_output_loss: 0.9492 - val_bag_output_loss: 0.8680 - val_footwear_output_loss: 0.8108 - val_pose_output_loss: 0.6051 - val_emotion_output_loss: 0.9138 - val_gender_output_acc: 0.8473 - val_image_quality_output_acc: 0.5796 - val_age_output_acc: 0.3947 - val_weight_output_acc: 0.6321 - val_bag_output_acc: 0.6023 - val_footwear_output_acc: 0.6316 - val_pose_output_acc: 0.7646 - val_emotion_output_acc: 0.7061\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 7.34091\n",
            "Epoch 16/50\n",
            "359/360 [============================>.] - ETA: 0s - loss: 6.9896 - gender_output_loss: 0.2171 - image_quality_output_loss: 0.8906 - age_output_loss: 1.3548 - weight_output_loss: 0.9374 - bag_output_loss: 0.8540 - footwear_output_loss: 0.7780 - pose_output_loss: 0.5058 - emotion_output_loss: 0.8752 - gender_output_acc: 0.9128 - image_quality_output_acc: 0.5746 - age_output_acc: 0.4113 - weight_output_acc: 0.6368 - bag_output_acc: 0.6027 - footwear_output_acc: 0.6616 - pose_output_acc: 0.7926 - emotion_output_acc: 0.7127\n",
            "Epoch 00015: val_loss did not improve from 7.34091\n",
            "Epoch 16/50\n",
            "360/360 [==============================] - 53s 148ms/step - loss: 6.9889 - gender_output_loss: 0.2167 - image_quality_output_loss: 0.8907 - age_output_loss: 1.3548 - weight_output_loss: 0.9378 - bag_output_loss: 0.8537 - footwear_output_loss: 0.7778 - pose_output_loss: 0.5057 - emotion_output_loss: 0.8751 - gender_output_acc: 0.9130 - image_quality_output_acc: 0.5750 - age_output_acc: 0.4114 - weight_output_acc: 0.6365 - bag_output_acc: 0.6027 - footwear_output_acc: 0.6617 - pose_output_acc: 0.7926 - emotion_output_acc: 0.7128 - val_loss: 7.5429 - val_gender_output_loss: 0.4081 - val_image_quality_output_loss: 1.0085 - val_age_output_loss: 1.3881 - val_weight_output_loss: 0.9896 - val_bag_output_loss: 0.8584 - val_footwear_output_loss: 0.8427 - val_pose_output_loss: 0.5557 - val_emotion_output_loss: 0.9161 - val_gender_output_acc: 0.8493 - val_image_quality_output_acc: 0.5030 - val_age_output_acc: 0.3931 - val_weight_output_acc: 0.5948 - val_bag_output_acc: 0.6114 - val_footwear_output_acc: 0.6255 - val_pose_output_acc: 0.7868 - val_emotion_output_acc: 0.7061\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 7.34091\n",
            "Epoch 17/50\n",
            "359/360 [============================>.] - ETA: 0s - loss: 6.9584 - gender_output_loss: 0.2136 - image_quality_output_loss: 0.8904 - age_output_loss: 1.3543 - weight_output_loss: 0.9326 - bag_output_loss: 0.8465 - footwear_output_loss: 0.7719 - pose_output_loss: 0.5005 - emotion_output_loss: 0.8735 - gender_output_acc: 0.9128 - image_quality_output_acc: 0.5690 - age_output_acc: 0.4138 - weight_output_acc: 0.6366 - bag_output_acc: 0.6051 - footwear_output_acc: 0.6610 - pose_output_acc: 0.7998 - emotion_output_acc: 0.7128Epoch 17/50\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 7.34091\n",
            "360/360 [==============================] - 53s 148ms/step - loss: 6.9583 - gender_output_loss: 0.2136 - image_quality_output_loss: 0.8902 - age_output_loss: 1.3542 - weight_output_loss: 0.9330 - bag_output_loss: 0.8470 - footwear_output_loss: 0.7716 - pose_output_loss: 0.5000 - emotion_output_loss: 0.8737 - gender_output_acc: 0.9127 - image_quality_output_acc: 0.5694 - age_output_acc: 0.4140 - weight_output_acc: 0.6362 - bag_output_acc: 0.6049 - footwear_output_acc: 0.6613 - pose_output_acc: 0.7999 - emotion_output_acc: 0.7128 - val_loss: 7.3589 - val_gender_output_loss: 0.4025 - val_image_quality_output_loss: 0.8993 - val_age_output_loss: 1.3801 - val_weight_output_loss: 1.0023 - val_bag_output_loss: 0.8689 - val_footwear_output_loss: 0.8011 - val_pose_output_loss: 0.5142 - val_emotion_output_loss: 0.9163 - val_gender_output_acc: 0.8609 - val_image_quality_output_acc: 0.5822 - val_age_output_acc: 0.3926 - val_weight_output_acc: 0.5938 - val_bag_output_acc: 0.6028 - val_footwear_output_acc: 0.6492 - val_pose_output_acc: 0.7974 - val_emotion_output_acc: 0.7061\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 7.34091\n",
            "\n",
            "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0015811387947429827.\n",
            "Epoch 18/50\n",
            "360/360 [==============================] - 52s 144ms/step - loss: 6.8242 - gender_output_loss: 0.1938 - image_quality_output_loss: 0.8765 - age_output_loss: 1.3378 - weight_output_loss: 0.9207 - bag_output_loss: 0.8337 - footwear_output_loss: 0.7537 - pose_output_loss: 0.4710 - emotion_output_loss: 0.8633 - gender_output_acc: 0.9199 - image_quality_output_acc: 0.5802 - age_output_acc: 0.4143 - weight_output_acc: 0.6386 - bag_output_acc: 0.6222 - footwear_output_acc: 0.6699 - pose_output_acc: 0.8131 - emotion_output_acc: 0.7128 - val_loss: 7.3450 - val_gender_output_loss: 0.4096 - val_image_quality_output_loss: 0.8897 - val_age_output_loss: 1.3712 - val_weight_output_loss: 0.9582 - val_bag_output_loss: 0.8877 - val_footwear_output_loss: 0.7977 - val_pose_output_loss: 0.5429 - val_emotion_output_loss: 0.9144 - val_gender_output_acc: 0.8639 - val_image_quality_output_acc: 0.5948 - val_age_output_acc: 0.3942 - val_weight_output_acc: 0.6245 - val_bag_output_acc: 0.5932 - val_footwear_output_acc: 0.6492 - val_pose_output_acc: 0.7873 - val_emotion_output_acc: 0.7061\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 7.34091\n",
            "Epoch 19/50\n",
            "360/360 [==============================] - 53s 146ms/step - loss: 6.7851 - gender_output_loss: 0.1860 - image_quality_output_loss: 0.8758 - age_output_loss: 1.3343 - weight_output_loss: 0.9175 - bag_output_loss: 0.8275 - footwear_output_loss: 0.7477 - pose_output_loss: 0.4604 - emotion_output_loss: 0.8625 - gender_output_acc: 0.9253 - image_quality_output_acc: 0.5798 - age_output_acc: 0.4170 - weight_output_acc: 0.6405 - bag_output_acc: 0.6228 - footwear_output_acc: 0.6743 - pose_output_acc: 0.8132 - emotion_output_acc: 0.7128 - val_loss: 7.3088 - val_gender_output_loss: 0.3954 - val_image_quality_output_loss: 0.8847 - val_age_output_loss: 1.3715 - val_weight_output_loss: 0.9688 - val_bag_output_loss: 0.8951 - val_footwear_output_loss: 0.7822 - val_pose_output_loss: 0.5243 - val_emotion_output_loss: 0.9139 - val_gender_output_acc: 0.8705 - val_image_quality_output_acc: 0.5887 - val_age_output_acc: 0.3952 - val_weight_output_acc: 0.6174 - val_bag_output_acc: 0.5887 - val_footwear_output_acc: 0.6502 - val_pose_output_acc: 0.7979 - val_emotion_output_acc: 0.7061\n",
            "\n",
            "Epoch 00019: val_loss improved from 7.34091 to 7.30883, saving model to /content/gdrive/My Drive/eip4_assignment5_modelweights/29dec_finalmodel_submit/eip4a5_model_res20.019.h5\n",
            "Epoch 20/50\n",
            "359/360 [============================>.] - ETA: 0s - loss: 6.7541 - gender_output_loss: 0.1829 - image_quality_output_loss: 0.8732 - age_output_loss: 1.3305 - weight_output_loss: 0.9137 - bag_output_loss: 0.8241 - footwear_output_loss: 0.7402 - pose_output_loss: 0.4576 - emotion_output_loss: 0.8592 - gender_output_acc: 0.9263 - image_quality_output_acc: 0.5775 - age_output_acc: 0.4194 - weight_output_acc: 0.6407 - bag_output_acc: 0.6247 - footwear_output_acc: 0.6783 - pose_output_acc: 0.8159 - emotion_output_acc: 0.7134\n",
            "360/360 [==============================] - 52s 144ms/step - loss: 6.7555 - gender_output_loss: 0.1840 - image_quality_output_loss: 0.8732 - age_output_loss: 1.3308 - weight_output_loss: 0.9144 - bag_output_loss: 0.8240 - footwear_output_loss: 0.7397 - pose_output_loss: 0.4573 - emotion_output_loss: 0.8594 - gender_output_acc: 0.9259 - image_quality_output_acc: 0.5776 - age_output_acc: 0.4194 - weight_output_acc: 0.6404 - bag_output_acc: 0.6246 - footwear_output_acc: 0.6787 - pose_output_acc: 0.8159 - emotion_output_acc: 0.7132 - val_loss: 7.3899 - val_gender_output_loss: 0.3862 - val_image_quality_output_loss: 0.9252 - val_age_output_loss: 1.3704 - val_weight_output_loss: 0.9627 - val_bag_output_loss: 0.8820 - val_footwear_output_loss: 0.8063 - val_pose_output_loss: 0.5778 - val_emotion_output_loss: 0.9069 - val_gender_output_acc: 0.8649 - val_image_quality_output_acc: 0.5675 - val_age_output_acc: 0.3921 - val_weight_output_acc: 0.6174 - val_bag_output_acc: 0.6048 - val_footwear_output_acc: 0.6492 - val_pose_output_acc: 0.7848 - val_emotion_output_acc: 0.7056\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 7.30883\n",
            "Epoch 21/50\n",
            "360/360 [==============================] - 53s 147ms/step - loss: 6.7286 - gender_output_loss: 0.1744 - image_quality_output_loss: 0.8709 - age_output_loss: 1.3297 - weight_output_loss: 0.9141 - bag_output_loss: 0.8218 - footwear_output_loss: 0.7434 - pose_output_loss: 0.4454 - emotion_output_loss: 0.8568 - gender_output_acc: 0.9322 - image_quality_output_acc: 0.5848 - age_output_acc: 0.4223 - weight_output_acc: 0.6368 - bag_output_acc: 0.6273 - footwear_output_acc: 0.6759 - pose_output_acc: 0.8217 - emotion_output_acc: 0.7131 - val_loss: 7.3808 - val_gender_output_loss: 0.4096 - val_image_quality_output_loss: 0.9949 - val_age_output_loss: 1.3695 - val_weight_output_loss: 0.9673 - val_bag_output_loss: 0.8477 - val_footwear_output_loss: 0.7843 - val_pose_output_loss: 0.5283 - val_emotion_output_loss: 0.9074 - val_gender_output_acc: 0.8604 - val_image_quality_output_acc: 0.5091 - val_age_output_acc: 0.3906 - val_weight_output_acc: 0.6159 - val_bag_output_acc: 0.6300 - val_footwear_output_acc: 0.6547 - val_pose_output_acc: 0.8009 - val_emotion_output_acc: 0.7051\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 7.30883\n",
            "Epoch 22/50\n",
            "360/360 [==============================] - 53s 147ms/step - loss: 6.7246 - gender_output_loss: 0.1791 - image_quality_output_loss: 0.8702 - age_output_loss: 1.3260 - weight_output_loss: 0.9096 - bag_output_loss: 0.8190 - footwear_output_loss: 0.7392 - pose_output_loss: 0.4533 - emotion_output_loss: 0.8566 - gender_output_acc: 0.9302 - image_quality_output_acc: 0.5842 - age_output_acc: 0.4220 - weight_output_acc: 0.6407 - bag_output_acc: 0.6323 - footwear_output_acc: 0.6783 - pose_output_acc: 0.8259 - emotion_output_acc: 0.7130 - val_loss: 7.3372 - val_gender_output_loss: 0.4121 - val_image_quality_output_loss: 0.8939 - val_age_output_loss: 1.3688 - val_weight_output_loss: 0.9631 - val_bag_output_loss: 0.8463 - val_footwear_output_loss: 0.8034 - val_pose_output_loss: 0.5658 - val_emotion_output_loss: 0.9126 - val_gender_output_acc: 0.8584 - val_image_quality_output_acc: 0.5711 - val_age_output_acc: 0.3957 - val_weight_output_acc: 0.6144 - val_bag_output_acc: 0.6270 - val_footwear_output_acc: 0.6447 - val_pose_output_acc: 0.7818 - val_emotion_output_acc: 0.7061\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 7.30883\n",
            "\n",
            "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0004999999951665528.\n",
            "Epoch 23/50\n",
            "360/360 [==============================] - 53s 147ms/step - loss: 6.6520 - gender_output_loss: 0.1702 - image_quality_output_loss: 0.8658 - age_output_loss: 1.3216 - weight_output_loss: 0.8995 - bag_output_loss: 0.8096 - footwear_output_loss: 0.7294 - pose_output_loss: 0.4324 - emotion_output_loss: 0.8521 - gender_output_acc: 0.9328 - image_quality_output_acc: 0.5871 - age_output_acc: 0.4242 - weight_output_acc: 0.6432 - bag_output_acc: 0.6358 - footwear_output_acc: 0.6836 - pose_output_acc: 0.8326 - emotion_output_acc: 0.7125 - val_loss: 7.3370 - val_gender_output_loss: 0.4161 - val_image_quality_output_loss: 0.9134 - val_age_output_loss: 1.3753 - val_weight_output_loss: 0.9674 - val_bag_output_loss: 0.8414 - val_footwear_output_loss: 0.7836 - val_pose_output_loss: 0.5577 - val_emotion_output_loss: 0.9111 - val_gender_output_acc: 0.8644 - val_image_quality_output_acc: 0.5736 - val_age_output_acc: 0.3957 - val_weight_output_acc: 0.6164 - val_bag_output_acc: 0.6285 - val_footwear_output_acc: 0.6568 - val_pose_output_acc: 0.7908 - val_emotion_output_acc: 0.7056\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 7.30883\n",
            "Epoch 24/50\n",
            "360/360 [==============================] - 53s 147ms/step - loss: 6.6458 - gender_output_loss: 0.1748 - image_quality_output_loss: 0.8605 - age_output_loss: 1.3176 - weight_output_loss: 0.9023 - bag_output_loss: 0.8042 - footwear_output_loss: 0.7256 - pose_output_loss: 0.4386 - emotion_output_loss: 0.8513 - gender_output_acc: 0.9323 - image_quality_output_acc: 0.5918 - age_output_acc: 0.4238 - weight_output_acc: 0.6449 - bag_output_acc: 0.6393 - footwear_output_acc: 0.6834 - pose_output_acc: 0.8289 - emotion_output_acc: 0.7131 - val_loss: 7.3484 - val_gender_output_loss: 0.4129 - val_image_quality_output_loss: 0.8898 - val_age_output_loss: 1.3732 - val_weight_output_loss: 0.9562 - val_bag_output_loss: 0.8942 - val_footwear_output_loss: 0.7842 - val_pose_output_loss: 0.5580 - val_emotion_output_loss: 0.9090 - val_gender_output_acc: 0.8664 - val_image_quality_output_acc: 0.5857 - val_age_output_acc: 0.3952 - val_weight_output_acc: 0.6210 - val_bag_output_acc: 0.6114 - val_footwear_output_acc: 0.6573 - val_pose_output_acc: 0.7913 - val_emotion_output_acc: 0.7051\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 7.30883\n",
            "Epoch 25/50\n",
            "360/360 [==============================] - 53s 147ms/step - loss: 6.6261 - gender_output_loss: 0.1693 - image_quality_output_loss: 0.8609 - age_output_loss: 1.3149 - weight_output_loss: 0.8946 - bag_output_loss: 0.8050 - footwear_output_loss: 0.7252 - pose_output_loss: 0.4350 - emotion_output_loss: 0.8503 - gender_output_acc: 0.9328 - image_quality_output_acc: 0.5876 - age_output_acc: 0.4239 - weight_output_acc: 0.6451 - bag_output_acc: 0.6420 - footwear_output_acc: 0.6859 - pose_output_acc: 0.8287 - emotion_output_acc: 0.7134 - val_loss: 7.3061 - val_gender_output_loss: 0.4218 - val_image_quality_output_loss: 0.8967 - val_age_output_loss: 1.3725 - val_weight_output_loss: 0.9645 - val_bag_output_loss: 0.8402 - val_footwear_output_loss: 0.7803 - val_pose_output_loss: 0.5529 - val_emotion_output_loss: 0.9065 - val_gender_output_acc: 0.8624 - val_image_quality_output_acc: 0.5852 - val_age_output_acc: 0.3931 - val_weight_output_acc: 0.6210 - val_bag_output_acc: 0.6356 - val_footwear_output_acc: 0.6568 - val_pose_output_acc: 0.7944 - val_emotion_output_acc: 0.7061\n",
            "\n",
            "Epoch 00025: val_loss improved from 7.30883 to 7.30608, saving model to /content/gdrive/My Drive/eip4_assignment5_modelweights/29dec_finalmodel_submit/eip4a5_model_res20.025.h5\n",
            "\n",
            "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.00015811389051842542.\n",
            "Epoch 26/50\n",
            "360/360 [==============================] - 51s 143ms/step - loss: 6.6025 - gender_output_loss: 0.1677 - image_quality_output_loss: 0.8569 - age_output_loss: 1.3146 - weight_output_loss: 0.8967 - bag_output_loss: 0.8007 - footwear_output_loss: 0.7205 - pose_output_loss: 0.4266 - emotion_output_loss: 0.8482 - gender_output_acc: 0.9365 - image_quality_output_acc: 0.5905 - age_output_acc: 0.4241 - weight_output_acc: 0.6482 - bag_output_acc: 0.6484 - footwear_output_acc: 0.6881 - pose_output_acc: 0.8383 - emotion_output_acc: 0.7129 - val_loss: 7.3003 - val_gender_output_loss: 0.4123 - val_image_quality_output_loss: 0.9098 - val_age_output_loss: 1.3718 - val_weight_output_loss: 0.9660 - val_bag_output_loss: 0.8402 - val_footwear_output_loss: 0.7786 - val_pose_output_loss: 0.5439 - val_emotion_output_loss: 0.9071 - val_gender_output_acc: 0.8669 - val_image_quality_output_acc: 0.5726 - val_age_output_acc: 0.3901 - val_weight_output_acc: 0.6190 - val_bag_output_acc: 0.6316 - val_footwear_output_acc: 0.6492 - val_pose_output_acc: 0.7944 - val_emotion_output_acc: 0.7067\n",
            "\n",
            "Epoch 00026: val_loss improved from 7.30608 to 7.30027, saving model to /content/gdrive/My Drive/eip4_assignment5_modelweights/29dec_finalmodel_submit/eip4a5_model_res20.026.h5\n",
            "Epoch 27/50\n",
            "359/360 [============================>.] - ETA: 0s - loss: 6.6056 - gender_output_loss: 0.1711 - image_quality_output_loss: 0.8584 - age_output_loss: 1.3111 - weight_output_loss: 0.8975 - bag_output_loss: 0.8015 - footwear_output_loss: 0.7187 - pose_output_loss: 0.4283 - emotion_output_loss: 0.8485 - gender_output_acc: 0.9315 - image_quality_output_acc: 0.5864 - age_output_acc: 0.4219 - weight_output_acc: 0.6455 - bag_output_acc: 0.6463 - footwear_output_acc: 0.6924 - pose_output_acc: 0.8302 - emotion_output_acc: 0.7129\n",
            "360/360 [==============================] - 52s 144ms/step - loss: 6.6069 - gender_output_loss: 0.1712 - image_quality_output_loss: 0.8590 - age_output_loss: 1.3107 - weight_output_loss: 0.8979 - bag_output_loss: 0.8014 - footwear_output_loss: 0.7189 - pose_output_loss: 0.4282 - emotion_output_loss: 0.8490 - gender_output_acc: 0.9315 - image_quality_output_acc: 0.5862 - age_output_acc: 0.4219 - weight_output_acc: 0.6452 - bag_output_acc: 0.6463 - footwear_output_acc: 0.6921 - pose_output_acc: 0.8300 - emotion_output_acc: 0.7127 - val_loss: 7.2996 - val_gender_output_loss: 0.4118 - val_image_quality_output_loss: 0.8933 - val_age_output_loss: 1.3726 - val_weight_output_loss: 0.9683 - val_bag_output_loss: 0.8542 - val_footwear_output_loss: 0.7795 - val_pose_output_loss: 0.5422 - val_emotion_output_loss: 0.9072 - val_gender_output_acc: 0.8674 - val_image_quality_output_acc: 0.5902 - val_age_output_acc: 0.3942 - val_weight_output_acc: 0.6159 - val_bag_output_acc: 0.6275 - val_footwear_output_acc: 0.6512 - val_pose_output_acc: 0.7954 - val_emotion_output_acc: 0.7056\n",
            "\n",
            "Epoch 00027: val_loss improved from 7.30027 to 7.29963, saving model to /content/gdrive/My Drive/eip4_assignment5_modelweights/29dec_finalmodel_submit/eip4a5_model_res20.027.h5\n",
            "Epoch 28/50\n",
            "360/360 [==============================] - 52s 144ms/step - loss: 6.5887 - gender_output_loss: 0.1644 - image_quality_output_loss: 0.8583 - age_output_loss: 1.3110 - weight_output_loss: 0.8965 - bag_output_loss: 0.7980 - footwear_output_loss: 0.7171 - pose_output_loss: 0.4280 - emotion_output_loss: 0.8449 - gender_output_acc: 0.9349 - image_quality_output_acc: 0.5898 - age_output_acc: 0.4220 - weight_output_acc: 0.6452 - bag_output_acc: 0.6492 - footwear_output_acc: 0.6857 - pose_output_acc: 0.8319 - emotion_output_acc: 0.7127 - val_loss: 7.3027 - val_gender_output_loss: 0.4159 - val_image_quality_output_loss: 0.8914 - val_age_output_loss: 1.3734 - val_weight_output_loss: 0.9700 - val_bag_output_loss: 0.8407 - val_footwear_output_loss: 0.7909 - val_pose_output_loss: 0.5420 - val_emotion_output_loss: 0.9079 - val_gender_output_acc: 0.8654 - val_image_quality_output_acc: 0.5887 - val_age_output_acc: 0.3921 - val_weight_output_acc: 0.6139 - val_bag_output_acc: 0.6300 - val_footwear_output_acc: 0.6557 - val_pose_output_acc: 0.7949 - val_emotion_output_acc: 0.7061\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 7.29963\n",
            "\n",
            "Epoch 00028: ReduceLROnPlateau reducing learning rate to 5.0000003198030994e-05.\n",
            "Epoch 29/50\n",
            "360/360 [==============================] - 53s 147ms/step - loss: 6.5916 - gender_output_loss: 0.1648 - image_quality_output_loss: 0.8569 - age_output_loss: 1.3115 - weight_output_loss: 0.8973 - bag_output_loss: 0.7992 - footwear_output_loss: 0.7166 - pose_output_loss: 0.4312 - emotion_output_loss: 0.8436 - gender_output_acc: 0.9369 - image_quality_output_acc: 0.5905 - age_output_acc: 0.4252 - weight_output_acc: 0.6433 - bag_output_acc: 0.6463 - footwear_output_acc: 0.6885 - pose_output_acc: 0.8280 - emotion_output_acc: 0.7136 - val_loss: 7.3022 - val_gender_output_loss: 0.4182 - val_image_quality_output_loss: 0.8938 - val_age_output_loss: 1.3724 - val_weight_output_loss: 0.9711 - val_bag_output_loss: 0.8438 - val_footwear_output_loss: 0.7792 - val_pose_output_loss: 0.5450 - val_emotion_output_loss: 0.9082 - val_gender_output_acc: 0.8669 - val_image_quality_output_acc: 0.5882 - val_age_output_acc: 0.3926 - val_weight_output_acc: 0.6144 - val_bag_output_acc: 0.6316 - val_footwear_output_acc: 0.6557 - val_pose_output_acc: 0.7933 - val_emotion_output_acc: 0.7056\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 7.29963\n",
            "Epoch 30/50\n",
            "360/360 [==============================] - 52s 145ms/step - loss: 6.5710 - gender_output_loss: 0.1667 - image_quality_output_loss: 0.8543 - age_output_loss: 1.3073 - weight_output_loss: 0.8932 - bag_output_loss: 0.7980 - footwear_output_loss: 0.7167 - pose_output_loss: 0.4184 - emotion_output_loss: 0.8459 - gender_output_acc: 0.9342 - image_quality_output_acc: 0.5928 - age_output_acc: 0.4287 - weight_output_acc: 0.6448 - bag_output_acc: 0.6433 - footwear_output_acc: 0.6875 - pose_output_acc: 0.8366 - emotion_output_acc: 0.7129 - val_loss: 7.3009 - val_gender_output_loss: 0.4184 - val_image_quality_output_loss: 0.8946 - val_age_output_loss: 1.3728 - val_weight_output_loss: 0.9709 - val_bag_output_loss: 0.8426 - val_footwear_output_loss: 0.7796 - val_pose_output_loss: 0.5433 - val_emotion_output_loss: 0.9083 - val_gender_output_acc: 0.8669 - val_image_quality_output_acc: 0.5897 - val_age_output_acc: 0.3926 - val_weight_output_acc: 0.6119 - val_bag_output_acc: 0.6300 - val_footwear_output_acc: 0.6552 - val_pose_output_acc: 0.7949 - val_emotion_output_acc: 0.7061\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 7.29963\n",
            "Epoch 31/50\n",
            "359/360 [============================>.] - ETA: 0s - loss: 6.5789 - gender_output_loss: 0.1647 - image_quality_output_loss: 0.8558 - age_output_loss: 1.3112 - weight_output_loss: 0.8933 - bag_output_loss: 0.7968 - footwear_output_loss: 0.7190 - pose_output_loss: 0.4209 - emotion_output_loss: 0.8468 - gender_output_acc: 0.9364 - image_quality_output_acc: 0.5969 - age_output_acc: 0.4261 - weight_output_acc: 0.6458 - bag_output_acc: 0.6495 - footwear_output_acc: 0.6876 - pose_output_acc: 0.8324 - emotion_output_acc: 0.7129Epoch 31/50\n",
            "360/360 [==============================] - 53s 148ms/step - loss: 6.5809 - gender_output_loss: 0.1648 - image_quality_output_loss: 0.8557 - age_output_loss: 1.3116 - weight_output_loss: 0.8937 - bag_output_loss: 0.7974 - footwear_output_loss: 0.7189 - pose_output_loss: 0.4208 - emotion_output_loss: 0.8474 - gender_output_acc: 0.9364 - image_quality_output_acc: 0.5969 - age_output_acc: 0.4260 - weight_output_acc: 0.6457 - bag_output_acc: 0.6490 - footwear_output_acc: 0.6878 - pose_output_acc: 0.8324 - emotion_output_acc: 0.7127 - val_loss: 7.3010 - val_gender_output_loss: 0.4164 - val_image_quality_output_loss: 0.8938 - val_age_output_loss: 1.3729 - val_weight_output_loss: 0.9713 - val_bag_output_loss: 0.8438 - val_footwear_output_loss: 0.7798 - val_pose_output_loss: 0.5440 - val_emotion_output_loss: 0.9086 - val_gender_output_acc: 0.8674 - val_image_quality_output_acc: 0.5912 - val_age_output_acc: 0.3921 - val_weight_output_acc: 0.6114 - val_bag_output_acc: 0.6331 - val_footwear_output_acc: 0.6552 - val_pose_output_acc: 0.7954 - val_emotion_output_acc: 0.7056\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 7.29963\n",
            "\n",
            "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.5811389051842542e-05.\n",
            "Epoch 32/50\n",
            "360/360 [==============================] - 53s 146ms/step - loss: 6.5717 - gender_output_loss: 0.1657 - image_quality_output_loss: 0.8573 - age_output_loss: 1.3104 - weight_output_loss: 0.8925 - bag_output_loss: 0.7976 - footwear_output_loss: 0.7170 - pose_output_loss: 0.4144 - emotion_output_loss: 0.8463 - gender_output_acc: 0.9364 - image_quality_output_acc: 0.5911 - age_output_acc: 0.4286 - weight_output_acc: 0.6452 - bag_output_acc: 0.6450 - footwear_output_acc: 0.6859 - pose_output_acc: 0.8381 - emotion_output_acc: 0.7131 - val_loss: 7.3071 - val_gender_output_loss: 0.4179 - val_image_quality_output_loss: 0.8991 - val_age_output_loss: 1.3729 - val_weight_output_loss: 0.9714 - val_bag_output_loss: 0.8433 - val_footwear_output_loss: 0.7801 - val_pose_output_loss: 0.5435 - val_emotion_output_loss: 0.9084 - val_gender_output_acc: 0.8679 - val_image_quality_output_acc: 0.5827 - val_age_output_acc: 0.3911 - val_weight_output_acc: 0.6129 - val_bag_output_acc: 0.6310 - val_footwear_output_acc: 0.6542 - val_pose_output_acc: 0.7944 - val_emotion_output_acc: 0.7061\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 7.29963\n",
            "Epoch 33/50\n",
            "359/360 [============================>.] - ETA: 0s - loss: 6.5683 - gender_output_loss: 0.1696 - image_quality_output_loss: 0.8550 - age_output_loss: 1.3069 - weight_output_loss: 0.8947 - bag_output_loss: 0.7957 - footwear_output_loss: 0.7142 - pose_output_loss: 0.4160 - emotion_output_loss: 0.8455 - gender_output_acc: 0.9334 - image_quality_output_acc: 0.5905 - age_output_acc: 0.4273 - weight_output_acc: 0.6473 - bag_output_acc: 0.6441 - footwear_output_acc: 0.6900 - pose_output_acc: 0.8370 - emotion_output_acc: 0.7124Epoch 33/50\n",
            "360/360 [==============================] - 54s 149ms/step - loss: 6.5679 - gender_output_loss: 0.1696 - image_quality_output_loss: 0.8549 - age_output_loss: 1.3067 - weight_output_loss: 0.8943 - bag_output_loss: 0.7954 - footwear_output_loss: 0.7149 - pose_output_loss: 0.4163 - emotion_output_loss: 0.8453 - gender_output_acc: 0.9335 - image_quality_output_acc: 0.5906 - age_output_acc: 0.4274 - weight_output_acc: 0.6477 - bag_output_acc: 0.6444 - footwear_output_acc: 0.6898 - pose_output_acc: 0.8370 - emotion_output_acc: 0.7126 - val_loss: 7.3070 - val_gender_output_loss: 0.4180 - val_image_quality_output_loss: 0.8979 - val_age_output_loss: 1.3728 - val_weight_output_loss: 0.9714 - val_bag_output_loss: 0.8440 - val_footwear_output_loss: 0.7796 - val_pose_output_loss: 0.5447 - val_emotion_output_loss: 0.9082 - val_gender_output_acc: 0.8664 - val_image_quality_output_acc: 0.5837 - val_age_output_acc: 0.3911 - val_weight_output_acc: 0.6129 - val_bag_output_acc: 0.6326 - val_footwear_output_acc: 0.6547 - val_pose_output_acc: 0.7949 - val_emotion_output_acc: 0.7061\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 7.29963\n",
            "Epoch 34/50\n",
            "360/360 [==============================] - 53s 147ms/step - loss: 6.5732 - gender_output_loss: 0.1616 - image_quality_output_loss: 0.8569 - age_output_loss: 1.3103 - weight_output_loss: 0.8942 - bag_output_loss: 0.7966 - footwear_output_loss: 0.7159 - pose_output_loss: 0.4223 - emotion_output_loss: 0.8449 - gender_output_acc: 0.9378 - image_quality_output_acc: 0.5930 - age_output_acc: 0.4249 - weight_output_acc: 0.6463 - bag_output_acc: 0.6502 - footwear_output_acc: 0.6858 - pose_output_acc: 0.8350 - emotion_output_acc: 0.7130 - val_loss: 7.3083 - val_gender_output_loss: 0.4180 - val_image_quality_output_loss: 0.8992 - val_age_output_loss: 1.3729 - val_weight_output_loss: 0.9711 - val_bag_output_loss: 0.8429 - val_footwear_output_loss: 0.7801 - val_pose_output_loss: 0.5454 - val_emotion_output_loss: 0.9082 - val_gender_output_acc: 0.8674 - val_image_quality_output_acc: 0.5837 - val_age_output_acc: 0.3916 - val_weight_output_acc: 0.6124 - val_bag_output_acc: 0.6300 - val_footwear_output_acc: 0.6527 - val_pose_output_acc: 0.7954 - val_emotion_output_acc: 0.7061\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 7.29963\n",
            "\n",
            "Epoch 00034: ReduceLROnPlateau reducing learning rate to 5.000000204760109e-06.\n",
            "Epoch 35/50\n",
            "360/360 [==============================] - 53s 146ms/step - loss: 6.5569 - gender_output_loss: 0.1654 - image_quality_output_loss: 0.8539 - age_output_loss: 1.3075 - weight_output_loss: 0.8904 - bag_output_loss: 0.7948 - footwear_output_loss: 0.7094 - pose_output_loss: 0.4196 - emotion_output_loss: 0.8454 - gender_output_acc: 0.9377 - image_quality_output_acc: 0.5922 - age_output_acc: 0.4255 - weight_output_acc: 0.6457 - bag_output_acc: 0.6478 - footwear_output_acc: 0.6937 - pose_output_acc: 0.8344 - emotion_output_acc: 0.7132 - val_loss: 7.3054 - val_gender_output_loss: 0.4164 - val_image_quality_output_loss: 0.8992 - val_age_output_loss: 1.3728 - val_weight_output_loss: 0.9715 - val_bag_output_loss: 0.8435 - val_footwear_output_loss: 0.7800 - val_pose_output_loss: 0.5434 - val_emotion_output_loss: 0.9082 - val_gender_output_acc: 0.8669 - val_image_quality_output_acc: 0.5832 - val_age_output_acc: 0.3916 - val_weight_output_acc: 0.6124 - val_bag_output_acc: 0.6316 - val_footwear_output_acc: 0.6562 - val_pose_output_acc: 0.7954 - val_emotion_output_acc: 0.7061\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 7.29963\n",
            "Epoch 36/50\n",
            "360/360 [==============================] - 53s 147ms/step - loss: 6.5671 - gender_output_loss: 0.1659 - image_quality_output_loss: 0.8569 - age_output_loss: 1.3098 - weight_output_loss: 0.8926 - bag_output_loss: 0.7954 - footwear_output_loss: 0.7147 - pose_output_loss: 0.4179 - emotion_output_loss: 0.8435 - gender_output_acc: 0.9367 - image_quality_output_acc: 0.5910 - age_output_acc: 0.4258 - weight_output_acc: 0.6471 - bag_output_acc: 0.6490 - footwear_output_acc: 0.6871 - pose_output_acc: 0.8352 - emotion_output_acc: 0.7128 - val_loss: 7.3093 - val_gender_output_loss: 0.4170 - val_image_quality_output_loss: 0.8984 - val_age_output_loss: 1.3728 - val_weight_output_loss: 0.9718 - val_bag_output_loss: 0.8446 - val_footwear_output_loss: 0.7799 - val_pose_output_loss: 0.5461 - val_emotion_output_loss: 0.9083 - val_gender_output_acc: 0.8669 - val_image_quality_output_acc: 0.5847 - val_age_output_acc: 0.3906 - val_weight_output_acc: 0.6129 - val_bag_output_acc: 0.6310 - val_footwear_output_acc: 0.6552 - val_pose_output_acc: 0.7954 - val_emotion_output_acc: 0.7061\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 7.29963\n",
            "Epoch 37/50\n",
            "360/360 [==============================] - 52s 146ms/step - loss: 6.5691 - gender_output_loss: 0.1675 - image_quality_output_loss: 0.8547 - age_output_loss: 1.3062 - weight_output_loss: 0.8933 - bag_output_loss: 0.7945 - footwear_output_loss: 0.7157 - pose_output_loss: 0.4225 - emotion_output_loss: 0.8441 - gender_output_acc: 0.9338 - image_quality_output_acc: 0.5959 - age_output_acc: 0.4276 - weight_output_acc: 0.6477 - bag_output_acc: 0.6487 - footwear_output_acc: 0.6914 - pose_output_acc: 0.8372 - emotion_output_acc: 0.7126 - val_loss: 7.3090 - val_gender_output_loss: 0.4182 - val_image_quality_output_loss: 0.8983 - val_age_output_loss: 1.3729 - val_weight_output_loss: 0.9714 - val_bag_output_loss: 0.8445 - val_footwear_output_loss: 0.7800 - val_pose_output_loss: 0.5450 - val_emotion_output_loss: 0.9082 - val_gender_output_acc: 0.8669 - val_image_quality_output_acc: 0.5847 - val_age_output_acc: 0.3911 - val_weight_output_acc: 0.6119 - val_bag_output_acc: 0.6316 - val_footwear_output_acc: 0.6547 - val_pose_output_acc: 0.7954 - val_emotion_output_acc: 0.7061\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 7.29963\n",
            "\n",
            "Epoch 00037: ReduceLROnPlateau reducing learning rate to 1.5811389339450021e-06.\n",
            "Epoch 38/50\n",
            "359/360 [============================>.] - ETA: 0s - loss: 6.5854 - gender_output_loss: 0.1714 - image_quality_output_loss: 0.8561 - age_output_loss: 1.3080 - weight_output_loss: 0.8953 - bag_output_loss: 0.7946 - footwear_output_loss: 0.7175 - pose_output_loss: 0.4254 - emotion_output_loss: 0.8466 - gender_output_acc: 0.9338 - image_quality_output_acc: 0.5925 - age_output_acc: 0.4257 - weight_output_acc: 0.6471 - bag_output_acc: 0.6544 - footwear_output_acc: 0.6885 - pose_output_acc: 0.8318 - emotion_output_acc: 0.7127\n",
            "Epoch 00037: val_loss did not improve from 7.29963\n",
            "360/360 [==============================] - 53s 147ms/step - loss: 6.5861 - gender_output_loss: 0.1712 - image_quality_output_loss: 0.8559 - age_output_loss: 1.3085 - weight_output_loss: 0.8950 - bag_output_loss: 0.7950 - footwear_output_loss: 0.7178 - pose_output_loss: 0.4253 - emotion_output_loss: 0.8468 - gender_output_acc: 0.9338 - image_quality_output_acc: 0.5928 - age_output_acc: 0.4251 - weight_output_acc: 0.6472 - bag_output_acc: 0.6544 - footwear_output_acc: 0.6886 - pose_output_acc: 0.8319 - emotion_output_acc: 0.7126 - val_loss: 7.3063 - val_gender_output_loss: 0.4167 - val_image_quality_output_loss: 0.8982 - val_age_output_loss: 1.3729 - val_weight_output_loss: 0.9708 - val_bag_output_loss: 0.8444 - val_footwear_output_loss: 0.7800 - val_pose_output_loss: 0.5447 - val_emotion_output_loss: 0.9082 - val_gender_output_acc: 0.8669 - val_image_quality_output_acc: 0.5857 - val_age_output_acc: 0.3911 - val_weight_output_acc: 0.6119 - val_bag_output_acc: 0.6316 - val_footwear_output_acc: 0.6547 - val_pose_output_acc: 0.7959 - val_emotion_output_acc: 0.7061\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 7.29963\n",
            "Epoch 39/50\n",
            "360/360 [==============================] - 53s 147ms/step - loss: 6.5495 - gender_output_loss: 0.1576 - image_quality_output_loss: 0.8532 - age_output_loss: 1.3067 - weight_output_loss: 0.8920 - bag_output_loss: 0.7950 - footwear_output_loss: 0.7150 - pose_output_loss: 0.4155 - emotion_output_loss: 0.8440 - gender_output_acc: 0.9377 - image_quality_output_acc: 0.5927 - age_output_acc: 0.4232 - weight_output_acc: 0.6467 - bag_output_acc: 0.6447 - footwear_output_acc: 0.6897 - pose_output_acc: 0.8347 - emotion_output_acc: 0.7123 - val_loss: 7.3088 - val_gender_output_loss: 0.4187 - val_image_quality_output_loss: 0.8983 - val_age_output_loss: 1.3729 - val_weight_output_loss: 0.9714 - val_bag_output_loss: 0.8444 - val_footwear_output_loss: 0.7799 - val_pose_output_loss: 0.5444 - val_emotion_output_loss: 0.9083 - val_gender_output_acc: 0.8674 - val_image_quality_output_acc: 0.5842 - val_age_output_acc: 0.3906 - val_weight_output_acc: 0.6119 - val_bag_output_acc: 0.6321 - val_footwear_output_acc: 0.6552 - val_pose_output_acc: 0.7959 - val_emotion_output_acc: 0.7061\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 7.29963\n",
            "Epoch 40/50\n",
            "360/360 [==============================] - 53s 146ms/step - loss: 6.5649 - gender_output_loss: 0.1616 - image_quality_output_loss: 0.8544 - age_output_loss: 1.3094 - weight_output_loss: 0.8957 - bag_output_loss: 0.7951 - footwear_output_loss: 0.7135 - pose_output_loss: 0.4206 - emotion_output_loss: 0.8439 - gender_output_acc: 0.9385 - image_quality_output_acc: 0.5955 - age_output_acc: 0.4254 - weight_output_acc: 0.6441 - bag_output_acc: 0.6468 - footwear_output_acc: 0.6921 - pose_output_acc: 0.8306 - emotion_output_acc: 0.7128 - val_loss: 7.3076 - val_gender_output_loss: 0.4186 - val_image_quality_output_loss: 0.8983 - val_age_output_loss: 1.3730 - val_weight_output_loss: 0.9725 - val_bag_output_loss: 0.8442 - val_footwear_output_loss: 0.7799 - val_pose_output_loss: 0.5424 - val_emotion_output_loss: 0.9083 - val_gender_output_acc: 0.8684 - val_image_quality_output_acc: 0.5847 - val_age_output_acc: 0.3911 - val_weight_output_acc: 0.6099 - val_bag_output_acc: 0.6326 - val_footwear_output_acc: 0.6552 - val_pose_output_acc: 0.7964 - val_emotion_output_acc: 0.7061\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 7.29963\n",
            "\n",
            "Epoch 00040: ReduceLROnPlateau reducing learning rate to 5.000000276661978e-07.\n",
            "Epoch 41/50\n",
            "360/360 [==============================] - 52s 146ms/step - loss: 6.5626 - gender_output_loss: 0.1609 - image_quality_output_loss: 0.8550 - age_output_loss: 1.3077 - weight_output_loss: 0.8947 - bag_output_loss: 0.7959 - footwear_output_loss: 0.7094 - pose_output_loss: 0.4240 - emotion_output_loss: 0.8446 - gender_output_acc: 0.9387 - image_quality_output_acc: 0.5923 - age_output_acc: 0.4302 - weight_output_acc: 0.6474 - bag_output_acc: 0.6484 - footwear_output_acc: 0.6910 - pose_output_acc: 0.8365 - emotion_output_acc: 0.7131 - val_loss: 7.3073 - val_gender_output_loss: 0.4171 - val_image_quality_output_loss: 0.8984 - val_age_output_loss: 1.3730 - val_weight_output_loss: 0.9705 - val_bag_output_loss: 0.8440 - val_footwear_output_loss: 0.7800 - val_pose_output_loss: 0.5457 - val_emotion_output_loss: 0.9082 - val_gender_output_acc: 0.8674 - val_image_quality_output_acc: 0.5847 - val_age_output_acc: 0.3911 - val_weight_output_acc: 0.6129 - val_bag_output_acc: 0.6321 - val_footwear_output_acc: 0.6552 - val_pose_output_acc: 0.7964 - val_emotion_output_acc: 0.7061\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 7.29963\n",
            "Epoch 42/50\n",
            "359/360 [============================>.] - ETA: 0s - loss: 6.5697 - gender_output_loss: 0.1601 - image_quality_output_loss: 0.8561 - age_output_loss: 1.3099 - weight_output_loss: 0.8950 - bag_output_loss: 0.7962 - footwear_output_loss: 0.7139 - pose_output_loss: 0.4236 - emotion_output_loss: 0.8445 - gender_output_acc: 0.9359 - image_quality_output_acc: 0.5951 - age_output_acc: 0.4231 - weight_output_acc: 0.6435 - bag_output_acc: 0.6463 - footwear_output_acc: 0.6891 - pose_output_acc: 0.8345 - emotion_output_acc: 0.7128Epoch 42/50\n",
            "360/360 [==============================] - 53s 147ms/step - loss: 6.5690 - gender_output_loss: 0.1606 - image_quality_output_loss: 0.8561 - age_output_loss: 1.3098 - weight_output_loss: 0.8953 - bag_output_loss: 0.7955 - footwear_output_loss: 0.7134 - pose_output_loss: 0.4236 - emotion_output_loss: 0.8442 - gender_output_acc: 0.9359 - image_quality_output_acc: 0.5951 - age_output_acc: 0.4234 - weight_output_acc: 0.6435 - bag_output_acc: 0.6468 - footwear_output_acc: 0.6893 - pose_output_acc: 0.8346 - emotion_output_acc: 0.7131 - val_loss: 7.3014 - val_gender_output_loss: 0.4139 - val_image_quality_output_loss: 0.8978 - val_age_output_loss: 1.3729 - val_weight_output_loss: 0.9687 - val_bag_output_loss: 0.8440 - val_footwear_output_loss: 0.7802 - val_pose_output_loss: 0.5451 - val_emotion_output_loss: 0.9083 - val_gender_output_acc: 0.8684 - val_image_quality_output_acc: 0.5857 - val_age_output_acc: 0.3916 - val_weight_output_acc: 0.6154 - val_bag_output_acc: 0.6326 - val_footwear_output_acc: 0.6532 - val_pose_output_acc: 0.7964 - val_emotion_output_acc: 0.7061\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 7.29963\n",
            "Epoch 43/50\n",
            "360/360 [==============================] - 53s 147ms/step - loss: 6.5690 - gender_output_loss: 0.1606 - image_quality_output_loss: 0.8561 - age_output_loss: 1.3098 - weight_output_loss: 0.8953 - bag_output_loss: 0.7955 - footwear_output_loss: 0.7134 - pose_output_loss: 0.4236 - emotion_output_loss: 0.8442 - gender_output_acc: 0.9359 - image_quality_output_acc: 0.5951 - age_output_acc: 0.4234 - weight_output_acc: 0.6435 - bag_output_acc: 0.6468 - footwear_output_acc: 0.6893 - pose_output_acc: 0.8346 - emotion_output_acc: 0.7131 - val_loss: 7.3014 - val_gender_output_loss: 0.4139 - val_image_quality_output_loss: 0.8978 - val_age_output_loss: 1.3729 - val_weight_output_loss: 0.9687 - val_bag_output_loss: 0.8440 - val_footwear_output_loss: 0.7802 - val_pose_output_loss: 0.5451 - val_emotion_output_loss: 0.9083 - val_gender_output_acc: 0.8684 - val_image_quality_output_acc: 0.5857 - val_age_output_acc: 0.3916 - val_weight_output_acc: 0.6154 - val_bag_output_acc: 0.6326 - val_footwear_output_acc: 0.6532 - val_pose_output_acc: 0.7964 - val_emotion_output_acc: 0.7061\n",
            "360/360 [==============================] - 53s 146ms/step - loss: 6.5709 - gender_output_loss: 0.1677 - image_quality_output_loss: 0.8538 - age_output_loss: 1.3083 - weight_output_loss: 0.8950 - bag_output_loss: 0.7960 - footwear_output_loss: 0.7126 - pose_output_loss: 0.4213 - emotion_output_loss: 0.8457 - gender_output_acc: 0.9350 - image_quality_output_acc: 0.5942 - age_output_acc: 0.4265 - weight_output_acc: 0.6446 - bag_output_acc: 0.6510 - footwear_output_acc: 0.6905 - pose_output_acc: 0.8362 - emotion_output_acc: 0.7128 - val_loss: 7.3102 - val_gender_output_loss: 0.4183 - val_image_quality_output_loss: 0.8983 - val_age_output_loss: 1.3729 - val_weight_output_loss: 0.9727 - val_bag_output_loss: 0.8440 - val_footwear_output_loss: 0.7802 - val_pose_output_loss: 0.5451 - val_emotion_output_loss: 0.9082 - val_gender_output_acc: 0.8669 - val_image_quality_output_acc: 0.5852 - val_age_output_acc: 0.3916 - val_weight_output_acc: 0.6119 - val_bag_output_acc: 0.6326 - val_footwear_output_acc: 0.6542 - val_pose_output_acc: 0.7964 - val_emotion_output_acc: 0.7061\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 7.29963\n",
            "\n",
            "Epoch 00043: ReduceLROnPlateau reducing learning rate to 5e-07.\n",
            "Epoch 44/50\n",
            "360/360 [==============================] - 53s 148ms/step - loss: 6.5686 - gender_output_loss: 0.1712 - image_quality_output_loss: 0.8524 - age_output_loss: 1.3064 - weight_output_loss: 0.8901 - bag_output_loss: 0.7964 - footwear_output_loss: 0.7125 - pose_output_loss: 0.4225 - emotion_output_loss: 0.8467 - gender_output_acc: 0.9317 - image_quality_output_acc: 0.5935 - age_output_acc: 0.4282 - weight_output_acc: 0.6468 - bag_output_acc: 0.6466 - footwear_output_acc: 0.6889 - pose_output_acc: 0.8361 - emotion_output_acc: 0.7122 - val_loss: 7.3058 - val_gender_output_loss: 0.4166 - val_image_quality_output_loss: 0.8985 - val_age_output_loss: 1.3730 - val_weight_output_loss: 0.9713 - val_bag_output_loss: 0.8444 - val_footwear_output_loss: 0.7800 - val_pose_output_loss: 0.5433 - val_emotion_output_loss: 0.9083 - val_gender_output_acc: 0.8669 - val_image_quality_output_acc: 0.5837 - val_age_output_acc: 0.3911 - val_weight_output_acc: 0.6114 - val_bag_output_acc: 0.6316 - val_footwear_output_acc: 0.6552 - val_pose_output_acc: 0.7954 - val_emotion_output_acc: 0.7061\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 7.29963\n",
            "Epoch 45/50\n",
            "360/360 [==============================] - 53s 147ms/step - loss: 6.5776 - gender_output_loss: 0.1672 - image_quality_output_loss: 0.8557 - age_output_loss: 1.3087 - weight_output_loss: 0.8947 - bag_output_loss: 0.7951 - footwear_output_loss: 0.7138 - pose_output_loss: 0.4282 - emotion_output_loss: 0.8437 - gender_output_acc: 0.9332 - image_quality_output_acc: 0.5923 - age_output_acc: 0.4227 - weight_output_acc: 0.6439 - bag_output_acc: 0.6468 - footwear_output_acc: 0.6872 - pose_output_acc: 0.8343 - emotion_output_acc: 0.7127 - val_loss: 7.3051 - val_gender_output_loss: 0.4160 - val_image_quality_output_loss: 0.8987 - val_age_output_loss: 1.3729 - val_weight_output_loss: 0.9714 - val_bag_output_loss: 0.8443 - val_footwear_output_loss: 0.7800 - val_pose_output_loss: 0.5432 - val_emotion_output_loss: 0.9082 - val_gender_output_acc: 0.8679 - val_image_quality_output_acc: 0.5847 - val_age_output_acc: 0.3916 - val_weight_output_acc: 0.6129 - val_bag_output_acc: 0.6316 - val_footwear_output_acc: 0.6557 - val_pose_output_acc: 0.7954 - val_emotion_output_acc: 0.7061\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 7.29963\n",
            "Epoch 46/50\n",
            "360/360 [==============================] - 52s 145ms/step - loss: 6.5586 - gender_output_loss: 0.1656 - image_quality_output_loss: 0.8540 - age_output_loss: 1.3051 - weight_output_loss: 0.8941 - bag_output_loss: 0.7961 - footwear_output_loss: 0.7165 - pose_output_loss: 0.4131 - emotion_output_loss: 0.8436 - gender_output_acc: 0.9337 - image_quality_output_acc: 0.5935 - age_output_acc: 0.4230 - weight_output_acc: 0.6470 - bag_output_acc: 0.6440 - footwear_output_acc: 0.6876 - pose_output_acc: 0.8381 - emotion_output_acc: 0.7127 - val_loss: 7.3031 - val_gender_output_loss: 0.4159 - val_image_quality_output_loss: 0.8989 - val_age_output_loss: 1.3730 - val_weight_output_loss: 0.9709 - val_bag_output_loss: 0.8442 - val_footwear_output_loss: 0.7798 - val_pose_output_loss: 0.5418 - val_emotion_output_loss: 0.9082 - val_gender_output_acc: 0.8669 - val_image_quality_output_acc: 0.5837 - val_age_output_acc: 0.3916 - val_weight_output_acc: 0.6114 - val_bag_output_acc: 0.6321 - val_footwear_output_acc: 0.6537 - val_pose_output_acc: 0.7964 - val_emotion_output_acc: 0.7061\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 7.29963\n",
            "Epoch 47/50\n",
            "359/360 [============================>.] - ETA: 0s - loss: 6.5646 - gender_output_loss: 0.1661 - image_quality_output_loss: 0.8530 - age_output_loss: 1.3093 - weight_output_loss: 0.8925 - bag_output_loss: 0.7947 - footwear_output_loss: 0.7142 - pose_output_loss: 0.4188 - emotion_output_loss: 0.8454 - gender_output_acc: 0.9347 - image_quality_output_acc: 0.5980 - age_output_acc: 0.4246 - weight_output_acc: 0.6438 - bag_output_acc: 0.6481 - footwear_output_acc: 0.6930 - pose_output_acc: 0.8323 - emotion_output_acc: 0.7133\n",
            "Epoch 00046: val_loss did not improve from 7.29963\n",
            "360/360 [==============================] - 53s 147ms/step - loss: 6.5629 - gender_output_loss: 0.1659 - image_quality_output_loss: 0.8533 - age_output_loss: 1.3092 - weight_output_loss: 0.8923 - bag_output_loss: 0.7949 - footwear_output_loss: 0.7140 - pose_output_loss: 0.4184 - emotion_output_loss: 0.8445 - gender_output_acc: 0.9348 - image_quality_output_acc: 0.5979 - age_output_acc: 0.4247 - weight_output_acc: 0.6440 - bag_output_acc: 0.6481 - footwear_output_acc: 0.6933 - pose_output_acc: 0.8324 - emotion_output_acc: 0.7137 - val_loss: 7.3080 - val_gender_output_loss: 0.4160 - val_image_quality_output_loss: 0.8980 - val_age_output_loss: 1.3729 - val_weight_output_loss: 0.9716 - val_bag_output_loss: 0.8443 - val_footwear_output_loss: 0.7800 - val_pose_output_loss: 0.5464 - val_emotion_output_loss: 0.9083 - val_gender_output_acc: 0.8664 - val_image_quality_output_acc: 0.5847 - val_age_output_acc: 0.3906 - val_weight_output_acc: 0.6119 - val_bag_output_acc: 0.6316 - val_footwear_output_acc: 0.6552 - val_pose_output_acc: 0.7954 - val_emotion_output_acc: 0.7061\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 7.29963\n",
            "Epoch 48/50\n",
            "360/360 [==============================] - 53s 147ms/step - loss: 6.5596 - gender_output_loss: 0.1589 - image_quality_output_loss: 0.8544 - age_output_loss: 1.3080 - weight_output_loss: 0.8928 - bag_output_loss: 0.7928 - footwear_output_loss: 0.7169 - pose_output_loss: 0.4197 - emotion_output_loss: 0.8457 - gender_output_acc: 0.9381 - image_quality_output_acc: 0.5905 - age_output_acc: 0.4233 - weight_output_acc: 0.6446 - bag_output_acc: 0.6486 - footwear_output_acc: 0.6885 - pose_output_acc: 0.8354 - emotion_output_acc: 0.7127 - val_loss: 7.3054 - val_gender_output_loss: 0.4163 - val_image_quality_output_loss: 0.8988 - val_age_output_loss: 1.3730 - val_weight_output_loss: 0.9710 - val_bag_output_loss: 0.8441 - val_footwear_output_loss: 0.7802 - val_pose_output_loss: 0.5432 - val_emotion_output_loss: 0.9083 - val_gender_output_acc: 0.8669 - val_image_quality_output_acc: 0.5837 - val_age_output_acc: 0.3911 - val_weight_output_acc: 0.6119 - val_bag_output_acc: 0.6310 - val_footwear_output_acc: 0.6522 - val_pose_output_acc: 0.7959 - val_emotion_output_acc: 0.7061\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 7.29963\n",
            "Epoch 49/50\n",
            "360/360 [==============================] - 53s 147ms/step - loss: 6.5640 - gender_output_loss: 0.1707 - image_quality_output_loss: 0.8541 - age_output_loss: 1.3077 - weight_output_loss: 0.8929 - bag_output_loss: 0.7947 - footwear_output_loss: 0.7099 - pose_output_loss: 0.4201 - emotion_output_loss: 0.8434 - gender_output_acc: 0.9330 - image_quality_output_acc: 0.5962 - age_output_acc: 0.4235 - weight_output_acc: 0.6456 - bag_output_acc: 0.6498 - footwear_output_acc: 0.6914 - pose_output_acc: 0.8349 - emotion_output_acc: 0.7127 - val_loss: 7.3050 - val_gender_output_loss: 0.4152 - val_image_quality_output_loss: 0.8987 - val_age_output_loss: 1.3729 - val_weight_output_loss: 0.9697 - val_bag_output_loss: 0.8442 - val_footwear_output_loss: 0.7801 - val_pose_output_loss: 0.5457 - val_emotion_output_loss: 0.9082 - val_gender_output_acc: 0.8679 - val_image_quality_output_acc: 0.5852 - val_age_output_acc: 0.3916 - val_weight_output_acc: 0.6124 - val_bag_output_acc: 0.6316 - val_footwear_output_acc: 0.6547 - val_pose_output_acc: 0.7954 - val_emotion_output_acc: 0.7061\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 7.29963\n",
            "Epoch 50/50\n",
            "360/360 [==============================] - 53s 147ms/step - loss: 6.5706 - gender_output_loss: 0.1678 - image_quality_output_loss: 0.8523 - age_output_loss: 1.3088 - weight_output_loss: 0.8935 - bag_output_loss: 0.7966 - footwear_output_loss: 0.7152 - pose_output_loss: 0.4201 - emotion_output_loss: 0.8458 - gender_output_acc: 0.9340 - image_quality_output_acc: 0.5931 - age_output_acc: 0.4275 - weight_output_acc: 0.6444 - bag_output_acc: 0.6451 - footwear_output_acc: 0.6920 - pose_output_acc: 0.8357 - emotion_output_acc: 0.7119 - val_loss: 7.3057 - val_gender_output_loss: 0.4160 - val_image_quality_output_loss: 0.8983 - val_age_output_loss: 1.3730 - val_weight_output_loss: 0.9714 - val_bag_output_loss: 0.8443 - val_footwear_output_loss: 0.7798 - val_pose_output_loss: 0.5443 - val_emotion_output_loss: 0.9082 - val_gender_output_acc: 0.8674 - val_image_quality_output_acc: 0.5842 - val_age_output_acc: 0.3911 - val_weight_output_acc: 0.6114 - val_bag_output_acc: 0.6310 - val_footwear_output_acc: 0.6547 - val_pose_output_acc: 0.7959 - val_emotion_output_acc: 0.7061\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 7.29963\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fda1fdfe390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    }
  ]
}